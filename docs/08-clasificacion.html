<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 7 Otros Clasificadores | Notas Curso de Estadística II</title>
  <meta name="description" content="Capítulo 7 Otros Clasificadores | Notas Curso de Estadística II" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 7 Otros Clasificadores | Notas Curso de Estadística II" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 7 Otros Clasificadores | Notas Curso de Estadística II" />
  
  
  

<meta name="author" content="Maikol Solís Chacón y Luis Barboza Chinchilla" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="06-seleccion-de-variables.html"/>
<link rel="next" href="09-calculo-bayes.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/rglWebGL-binding-0.108.3/rglWebGL.js"></script>
<link href="libs/rglwidgetClass-0.108.3/rgl.css" rel="stylesheet" />
<script src="libs/rglwidgetClass-0.108.3/rglClass.min.js"></script>
<script src="libs/CanvasMatrix4-0.108.3/CanvasMatrix.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso de Estadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html"><i class="fa fa-check"></i><b>2</b> Estimación no-paramétrica de densidades</a>
<ul>
<li class="chapter" data-level="2.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#histograma"><i class="fa fa-check"></i><b>2.1</b> Histograma</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#construcción-estadística"><i class="fa fa-check"></i><b>2.1.1</b> Construcción Estadística</a></li>
<li class="chapter" data-level="2.1.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#construcción-probabilística"><i class="fa fa-check"></i><b>2.1.2</b> Construcción probabilística</a></li>
<li class="chapter" data-level="2.1.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas"><i class="fa fa-check"></i><b>2.1.3</b> Propiedades estadísticas</a></li>
<li class="chapter" data-level="2.1.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas-1"><i class="fa fa-check"></i><b>2.1.4</b> Propiedades estadísticas</a></li>
<li class="chapter" data-level="2.1.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#sesgo"><i class="fa fa-check"></i><b>2.1.5</b> Sesgo</a></li>
<li class="chapter" data-level="2.1.6" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#varianza"><i class="fa fa-check"></i><b>2.1.6</b> Varianza</a></li>
<li class="chapter" data-level="2.1.7" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio"><i class="fa fa-check"></i><b>2.1.7</b> Error cuadrático medio</a></li>
<li class="chapter" data-level="2.1.8" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio-integrado"><i class="fa fa-check"></i><b>2.1.8</b> Error cuadrático medio integrado</a></li>
<li class="chapter" data-level="2.1.9" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo-para-el-histograma"><i class="fa fa-check"></i><b>2.1.9</b> Ancho de banda óptimo para el histograma</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#estimación-de-densidades-basada-en-kernels."><i class="fa fa-check"></i><b>2.2</b> Estimación de densidades basada en kernels.</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#primera-construcción"><i class="fa fa-check"></i><b>2.2.1</b> Primera construcción</a></li>
<li class="chapter" data-level="2.2.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#otra-construcción"><i class="fa fa-check"></i><b>2.2.2</b> Otra construcción</a></li>
<li class="chapter" data-level="2.2.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas-2"><i class="fa fa-check"></i><b>2.2.3</b> Propiedades Estadísticas</a></li>
<li class="chapter" data-level="2.2.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#sesgo-1"><i class="fa fa-check"></i><b>2.2.4</b> Sesgo</a></li>
<li class="chapter" data-level="2.2.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio-y-error-cuadrático-medio-integrado"><i class="fa fa-check"></i><b>2.2.5</b> Error cuadrático medio y Error cuadrático medio integrado</a></li>
<li class="chapter" data-level="2.2.6" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo"><i class="fa fa-check"></i><b>2.2.6</b> Ancho de banda óptimo</a></li>
<li class="chapter" data-level="2.2.7" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#intervalos-de-confianza-para-estimadores-de-densidad-no-paramétricos"><i class="fa fa-check"></i><b>2.2.7</b> Intervalos de confianza para estimadores de densidad no paramétricos</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#laboratorio"><i class="fa fa-check"></i><b>2.3</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#efecto-de-distintos-kernels-en-la-estimación"><i class="fa fa-check"></i><b>2.3.1</b> Efecto de distintos Kernels en la estimación</a></li>
<li class="chapter" data-level="2.3.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#efecto-del-ancho-de-banda-en-la-estimación"><i class="fa fa-check"></i><b>2.3.2</b> Efecto del ancho de banda en la estimación</a></li>
<li class="chapter" data-level="2.3.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo-1"><i class="fa fa-check"></i><b>2.3.3</b> Ancho de banda óptimo</a></li>
<li class="chapter" data-level="2.3.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#validación-cruzada-1"><i class="fa fa-check"></i><b>2.3.4</b> Validación cruzada</a></li>
<li class="chapter" data-level="2.3.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#temas-adicionales"><i class="fa fa-check"></i><b>2.3.5</b> Temas adicionales</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ejercicios"><i class="fa fa-check"></i><b>2.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html"><i class="fa fa-check"></i><b>3</b> Jackknife y Bootstrap</a>
<ul>
<li class="chapter" data-level="3.1" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#caso-concreto"><i class="fa fa-check"></i><b>3.1</b> Caso concreto</a></li>
<li class="chapter" data-level="3.2" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#jackknife"><i class="fa fa-check"></i><b>3.2</b> Jackknife</a></li>
<li class="chapter" data-level="3.3" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#bootstrap"><i class="fa fa-check"></i><b>3.3</b> Bootstrap</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>3.3.1</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="3.3.2" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#resumiendo"><i class="fa fa-check"></i><b>3.3.2</b> Resumiendo</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#ejercicios-1"><i class="fa fa-check"></i><b>3.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html"><i class="fa fa-check"></i><b>4</b> Métodos lineales de regresión</a>
<ul>
<li class="chapter" data-level="4.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#introducción-al-aprendizaje-estadístico."><i class="fa fa-check"></i><b>4.1</b> Introducción al Aprendizaje Estadístico.</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#formas-de-estimar-f"><i class="fa fa-check"></i><b>4.1.1</b> Formas de estimar <span class="math inline">\(f\)</span></a></li>
<li class="chapter" data-level="4.1.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#medidas-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>4.1.2</b> Medidas de bondad de ajuste</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#regresión-lineal"><i class="fa fa-check"></i><b>4.2</b> Regresión lineal</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#forma-matricial"><i class="fa fa-check"></i><b>4.2.1</b> Forma matricial</a></li>
<li class="chapter" data-level="4.2.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-1"><i class="fa fa-check"></i><b>4.2.2</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#propiedades-estadísticas-3"><i class="fa fa-check"></i><b>4.3</b> Propiedades estadísticas</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#prueba-t"><i class="fa fa-check"></i><b>4.3.1</b> Prueba <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="4.3.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#prueba-f"><i class="fa fa-check"></i><b>4.3.2</b> Prueba <span class="math inline">\(F\)</span></a></li>
<li class="chapter" data-level="4.3.3" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-2"><i class="fa fa-check"></i><b>4.3.3</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#medida-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>4.4</b> Medida de bondad de ajuste</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-3"><i class="fa fa-check"></i><b>4.4.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#predicción"><i class="fa fa-check"></i><b>4.5</b> Predicción</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-4"><i class="fa fa-check"></i><b>4.5.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#interacciones"><i class="fa fa-check"></i><b>4.6</b> Interacciones</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-5"><i class="fa fa-check"></i><b>4.6.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#supuestos"><i class="fa fa-check"></i><b>4.7</b> Supuestos</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#chequeos-básicos-de-las-hipótesis-de-regresión-lineal"><i class="fa fa-check"></i><b>4.7.1</b> Chequeos básicos de las hipótesis de regresión lineal</a></li>
<li class="chapter" data-level="4.7.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#otros-chequeos-importantes"><i class="fa fa-check"></i><b>4.7.2</b> Otros chequeos importantes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#ejercicios-2"><i class="fa fa-check"></i><b>4.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html"><i class="fa fa-check"></i><b>5</b> Regresión Logística</a>
<ul>
<li class="chapter" data-level="5.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#preliminares"><i class="fa fa-check"></i><b>5.1</b> Preliminares</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#oportunidad-relativa-odds-ratio"><i class="fa fa-check"></i><b>5.1.1</b> Oportunidad relativa (Odds Ratio)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#máxima-verosimilitud"><i class="fa fa-check"></i><b>5.2</b> Máxima verosimilitud</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#resultados-adicionales"><i class="fa fa-check"></i><b>5.2.1</b> Resultados adicionales</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#diágnosticos-del-modelo"><i class="fa fa-check"></i><b>5.3</b> Diágnosticos del modelo</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#supuesto-de-linealidad"><i class="fa fa-check"></i><b>5.3.1</b> Supuesto de linealidad</a></li>
<li class="chapter" data-level="5.3.2" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#valores-de-gran-influencia"><i class="fa fa-check"></i><b>5.3.2</b> Valores de gran influencia</a></li>
<li class="chapter" data-level="5.3.3" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#multicolinealidad-1"><i class="fa fa-check"></i><b>5.3.3</b> Multicolinealidad</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#predicción-y-poder-de-clasificación"><i class="fa fa-check"></i><b>5.4</b> Predicción y poder de clasificación</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#curva-roc"><i class="fa fa-check"></i><b>5.4.1</b> Curva ROC</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#ejercicios-3"><i class="fa fa-check"></i><b>5.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html"><i class="fa fa-check"></i><b>6</b> Métodos de selección de variables y regularización.</a>
<ul>
<li class="chapter" data-level="6.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#estimación-del-error-de-prueba"><i class="fa fa-check"></i><b>6.1</b> Estimación del error de prueba</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#técnica-de-conjunto-de-validación"><i class="fa fa-check"></i><b>6.1.1</b> Técnica de conjunto de validación</a></li>
<li class="chapter" data-level="6.1.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-leave-one-out-loocv"><i class="fa fa-check"></i><b>6.1.2</b> Validación cruzada “Leave-One-Out” (LOOCV)</a></li>
<li class="chapter" data-level="6.1.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-k-veces"><i class="fa fa-check"></i><b>6.1.3</b> Validación cruzada <span class="math inline">\(k-\)</span>veces</a></li>
<li class="chapter" data-level="6.1.4" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-para-clasificación"><i class="fa fa-check"></i><b>6.1.4</b> Validación cruzada para clasificación</a></li>
<li class="chapter" data-level="6.1.5" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#otras-medidas-de-error-de-prueba"><i class="fa fa-check"></i><b>6.1.5</b> Otras medidas de error de prueba</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-variables"><i class="fa fa-check"></i><b>6.2</b> Selección de variables</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-del-mejor-subconjunto."><i class="fa fa-check"></i><b>6.2.1</b> Selección del mejor subconjunto.</a></li>
<li class="chapter" data-level="6.2.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-modelos-hacia-adelante-forward-stepwise-selection"><i class="fa fa-check"></i><b>6.2.2</b> Selección de modelos hacia adelante (<strong>Forward Stepwise Selection</strong>)</a></li>
<li class="chapter" data-level="6.2.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-modelos-hacia-atrás-backward-stepwise-selection"><i class="fa fa-check"></i><b>6.2.3</b> Selección de modelos hacia atrás (<strong>Backward Stepwise Selection</strong>)</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#métodos-de-regularización"><i class="fa fa-check"></i><b>6.3</b> Métodos de regularización</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-ridge"><i class="fa fa-check"></i><b>6.3.1</b> Regresión Ridge</a></li>
<li class="chapter" data-level="6.3.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-lasso"><i class="fa fa-check"></i><b>6.3.2</b> Regresión Lasso</a></li>
<li class="chapter" data-level="6.3.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#explicación-gráfica"><i class="fa fa-check"></i><b>6.3.3</b> Explicación gráfica</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#laboratorio-6"><i class="fa fa-check"></i><b>6.4</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#cross-validation"><i class="fa fa-check"></i><b>6.4.1</b> Cross-Validation</a></li>
<li class="chapter" data-level="6.4.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-lasso-1"><i class="fa fa-check"></i><b>6.4.2</b> Regresión Lasso</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#ejercicios-4"><i class="fa fa-check"></i><b>6.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="08-clasificacion.html"><a href="08-clasificacion.html"><i class="fa fa-check"></i><b>7</b> Otros Clasificadores</a>
<ul>
<li class="chapter" data-level="7.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#clasificador-bayesiano"><i class="fa fa-check"></i><b>7.1</b> Clasificador Bayesiano</a></li>
<li class="chapter" data-level="7.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#método-de-k-vecinos-más-cercanos-knn"><i class="fa fa-check"></i><b>7.2</b> Método de k vecinos más cercanos (KNN)</a></li>
<li class="chapter" data-level="7.3" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante"><i class="fa fa-check"></i><b>7.3</b> Análisis Discriminante</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-lineal"><i class="fa fa-check"></i><b>7.3.1</b> Análisis discriminante lineal</a></li>
<li class="chapter" data-level="7.3.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-cuadrático"><i class="fa fa-check"></i><b>7.3.2</b> Análisis discriminante cuadrático</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="08-clasificacion.html"><a href="08-clasificacion.html#laboratorio-7"><i class="fa fa-check"></i><b>7.4</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#clasificador-logístico"><i class="fa fa-check"></i><b>7.4.1</b> Clasificador logístico</a></li>
<li class="chapter" data-level="7.4.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-lineal-1"><i class="fa fa-check"></i><b>7.4.2</b> Análisis Discriminante Lineal</a></li>
<li class="chapter" data-level="7.4.3" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-cuadrático-1"><i class="fa fa-check"></i><b>7.4.3</b> Análisis Discriminante Cuadrático</a></li>
<li class="chapter" data-level="7.4.4" data-path="08-clasificacion.html"><a href="08-clasificacion.html#k-vecinos-más-cercanos"><i class="fa fa-check"></i><b>7.4.4</b> K vecinos más cercanos</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="08-clasificacion.html"><a href="08-clasificacion.html#ejercicios-5"><i class="fa fa-check"></i><b>7.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html"><i class="fa fa-check"></i><b>8</b> Cálculo Bayesiano Computacional</a>
<ul>
<li class="chapter" data-level="8.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#repaso-de-estadística-bayesiana"><i class="fa fa-check"></i><b>8.1</b> Repaso de Estadística Bayesiana</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#modelo-de-un-parámetro"><i class="fa fa-check"></i><b>8.1.1</b> Modelo de un parámetro</a></li>
<li class="chapter" data-level="8.1.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#modelo-de-más-de-un-parámetro"><i class="fa fa-check"></i><b>8.1.2</b> Modelo de más de un parámetro</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#motivación-cálculo-de-integrales"><i class="fa fa-check"></i><b>8.2</b> Motivación: Cálculo de Integrales</a></li>
<li class="chapter" data-level="8.3" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejemplo-base-modelo-beta-binomial."><i class="fa fa-check"></i><b>8.3</b> Ejemplo base: modelo beta-binomial.</a></li>
<li class="chapter" data-level="8.4" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#aproximación-de-laplace"><i class="fa fa-check"></i><b>8.4</b> Aproximación de Laplace</a></li>
<li class="chapter" data-level="8.5" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#simulación"><i class="fa fa-check"></i><b>8.5</b> Simulación</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#simulación-monte-carlo"><i class="fa fa-check"></i><b>8.5.1</b> Simulación Monte Carlo</a></li>
<li class="chapter" data-level="8.5.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#muestreo-por-rechazo"><i class="fa fa-check"></i><b>8.5.2</b> Muestreo por rechazo</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#muestreo-por-importancia"><i class="fa fa-check"></i><b>8.6</b> Muestreo por importancia</a></li>
<li class="chapter" data-level="8.7" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#remuestreo-por-importancia"><i class="fa fa-check"></i><b>8.7</b> Remuestreo por importancia</a></li>
<li class="chapter" data-level="8.8" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#algoritmo-de-metropolis-hastings"><i class="fa fa-check"></i><b>8.8</b> Algoritmo de Metropolis-Hastings</a></li>
<li class="chapter" data-level="8.9" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#algoritmo-de-gibbs"><i class="fa fa-check"></i><b>8.9</b> Algoritmo de Gibbs</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#diagnósticos-de-convergencia-de-mcmc"><i class="fa fa-check"></i><b>8.9.1</b> Diagnósticos de convergencia de MCMC</a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejemplos"><i class="fa fa-check"></i><b>8.10</b> Ejemplos</a>
<ul>
<li class="chapter" data-level="8.10.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#datos-agrupados-bajo-una-población-normal"><i class="fa fa-check"></i><b>8.10.1</b> Datos agrupados bajo una población normal</a></li>
</ul></li>
<li class="chapter" data-level="8.11" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejercicios-6"><i class="fa fa-check"></i><b>8.11</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html"><i class="fa fa-check"></i><b>9</b> Análisis en componentes principales</a>
<ul>
<li class="chapter" data-level="9.1" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#aprendizaje-no-supervisado"><i class="fa fa-check"></i><b>9.1</b> Aprendizaje no-supervisado</a></li>
<li class="chapter" data-level="9.2" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#representación-gráfica"><i class="fa fa-check"></i><b>9.2</b> Representación gráfica</a></li>
<li class="chapter" data-level="9.3" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#primer-componente-principal"><i class="fa fa-check"></i><b>9.3</b> Primer componente principal</a></li>
<li class="chapter" data-level="9.4" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#segunda-componente-principal"><i class="fa fa-check"></i><b>9.4</b> Segunda componente principal</a></li>
<li class="chapter" data-level="9.5" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#circulo-de-correlaciones"><i class="fa fa-check"></i><b>9.5</b> Circulo de correlaciones</a></li>
<li class="chapter" data-level="9.6" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#volvamos-a-nuestro-ejemplo"><i class="fa fa-check"></i><b>9.6</b> Volvamos a nuestro ejemplo</a></li>
<li class="chapter" data-level="9.7" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#cuántos-componentes-usar"><i class="fa fa-check"></i><b>9.7</b> ¿Cuántos componentes usar?</a></li>
<li class="chapter" data-level="9.8" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#laboratorio-8"><i class="fa fa-check"></i><b>9.8</b> Laboratorio</a></li>
<li class="chapter" data-level="9.9" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#ejercicios-7"><i class="fa fa-check"></i><b>9.9</b> Ejercicios</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notas Curso de Estadística II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="otros-clasificadores" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Capítulo 7</span> Otros Clasificadores<a href="08-clasificacion.html#otros-clasificadores" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="clasificador-bayesiano" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Clasificador Bayesiano<a href="08-clasificacion.html#clasificador-bayesiano" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Bajo el modelo de aprendizaje estadístico, suponga que se quiere estimar <span class="math inline">\(f\)</span> usando el conjunto de entrenamiento <span class="math inline">\(\{(x_1,y_1),\ldots,(x_n,y_n)\}\)</span> donde <span class="math inline">\(y_1,\ldots,y_n\)</span> es categórica. Para evaluar la precisión del clasificador <span class="math inline">\(\hat f\)</span> podemos usar la tasa de error:</p>
<p><span class="math display">\[\frac 1 n \sum_{i=1}^nI(y_i\neq \hat y_i)\]</span></p>
<p>donde <span class="math inline">\(\hat y_i\)</span> es el nivel predecido de la variable categórica para el individuo <span class="math inline">\(i\)</span>-ésimo. La tasa de error mide la proporción de observaciones mal clasificadas por <span class="math inline">\(\hat f\)</span> dentro del conjunto de entrenamiento. El mismo concepto se puede aplicar en el conjunto de prueba, es decir si <span class="math inline">\(Z_0\)</span> es el conjunto de índices de datos de prueba con tamaño <span class="math inline">\(m\)</span>:</p>
<p><span class="math display" id="eq:cerror">\[\begin{align}
\frac 1 m \sum_{i \in Z_0}I(y_i\neq \hat y_i)
\tag{7.1}
\end{align}\]</span></p>
<p>Decimos que un clasificador es bueno cuando el error de prueba en <a href="08-clasificacion.html#eq:cerror">(7.1)</a> es el más pequeño.</p>
<p>Es posible demostrar que el error de prueba se minimiza cuando <span class="math inline">\(\hat f\)</span> asigna a cada observación el nivel con la probabilidad más alta dados los predictores, es decir se asigna la clase <span class="math inline">\(j\)</span> a la observación <span class="math inline">\(x_0\)</span> en donde
<span class="math display">\[P(Y=j|X=x_0)\]</span></p>
<p>es máximo. A este clasificador se le llama <em>clasificador bayesiano</em>. En el caso en que el número de niveles o categorías de la variable dependiente es 2 (<span class="math inline">\(j=1,2\)</span>), entonces se selecciona el nivel <span class="math inline">\(j\)</span>-ésimo si:
<span class="math display">\[P(Y=j|X=x_0)&gt;0.5\]</span></p>
<p>Al conjunto <span class="math inline">\(\{x_0: P(Y=j|X=x_0)=0.5\}\)</span> se le llama frontera de decisión de Bayes.</p>
<p>La <em>tasa bayesiana de error</em> del clasificador para un conjunto de datos fijos es:
<span class="math inline">\(1-\max_j P(Y=j|X=x_0)\)</span>. En general la tasa de error bayesiana sería:
<span class="math display">\[1-E\left[\max_j P(Y=j|X)\right]\]</span></p>
<p>Para el caso de clasificación la tasa de error bayesiana es equivalente al error irreducible.</p>
<p>Inconveniente: en datos reales no conocemos <span class="math inline">\(P(Y=j|X=x_0)\)</span>.</p>
</div>
<div id="método-de-k-vecinos-más-cercanos-knn" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Método de k vecinos más cercanos (KNN)<a href="08-clasificacion.html#método-de-k-vecinos-más-cercanos-knn" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este método aproxima la probabilidad condicional del clasificador bayesiano. Dado un entero <span class="math inline">\(K\)</span> y una observación de prueba <span class="math inline">\(x_0\)</span>, el clasificador primero identifica el conjunto de observaciones que son más cercanas a <span class="math inline">\(x_0\)</span>: <span class="math inline">\(\mathcal N_0\)</span>. Entonces:
<span class="math display">\[P(Y=j|X=x_0) := \frac{1}{K}\sum_{i \in \mathcal N_0}I(y_i=j)\]</span>
y siguiendo la regla de bayes se selecciona la categoría con probabilidad condicional máxima.</p>
<div class="figure">
<img src="manual_figures/KNN.png" alt="" />
<p class="caption">Clasificación según K vecinos más cercanos (Wikimedia Commons)</p>
</div>
</div>
<div id="análisis-discriminante" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Análisis Discriminante<a href="08-clasificacion.html#análisis-discriminante" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Recuerden que en el caso del modelo logístico, se tiene que:
<span class="math display">\[P(Y=1|X=x)=\frac{e^{\beta_0+\beta_1X_1+\cdots+\beta_pX_p}}{1+e^{\beta_0+\beta_1X_1+\cdots+\beta_pX_p}}\]</span>
donde <span class="math inline">\(X_1,\ldots,X_p\)</span> son los predictores. Para el modelo logístico tenemos los siguientes inconvenientes:</p>
<ul>
<li><p>Cuando las clases están muy separadas, los parámetros del modelo logístico tienden a ser muy inestables.</p></li>
<li><p>Cuando la distribución de los predictores es aproximadamente normal en cada una de las clases, entonces el modelo discriminante lineal es más estable que el logístico.</p></li>
<li><p>El modelo logístico aplica solamente en el caso de 2 clases.</p></li>
</ul>
<p>Suponga que se quiere clasificar una observación en <span class="math inline">\(K\geq 2\)</span> clases. Sea <span class="math inline">\(\pi_k\)</span> la probabilidad previa de que la observación provenga de la clase <span class="math inline">\(k\)</span>-ésima. Sea
<span class="math display">\[f_k(x)=P(X=x|Y=k)\]</span>
por el teorema de Bayes:
<span class="math display">\[P_k(x):=P(Y=k|X=x)=\frac{\pi_kf_k(x)}{\sum_{l=1}^K \pi_lf_l(x)}\]</span></p>
<p>Estimación de los componentes:</p>
<ul>
<li><span class="math inline">\(\pi_k\)</span>: proporción de observaciones en el conjunto de entrenamiento que pertenecen a la clase <span class="math inline">\(k\)</span>-ésima.</li>
<li><span class="math inline">\(f_k(x)\)</span>: supuesto paramétrico que define el tipo de análisis discriminante.</li>
</ul>
<div id="análisis-discriminante-lineal" class="section level3 hasAnchor" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Análisis discriminante lineal<a href="08-clasificacion.html#análisis-discriminante-lineal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="caso-p1" class="section level4 hasAnchor" number="7.3.1.1">
<h4><span class="header-section-number">7.3.1.1</span> Caso p=1<a href="08-clasificacion.html#caso-p1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Asuma que
<span class="math display">\[f_k(x)=\frac{1}{\sqrt{2\pi}\sigma_k}\exp\left(-\frac{1}{2\sigma_k^2}(x-\mu_k)^2\right)\]</span>
donde <span class="math inline">\(\mu_k\)</span> y <span class="math inline">\(\sigma_k\)</span> son la media y desviación estándar para cada clase en la variable dependiente. Asumiendo que <span class="math inline">\(\sigma^2=\sigma_1^2=\cdots=\sigma_K^2\)</span> se puede comprobar que el clasificador bayesiano asigna la clase <span class="math inline">\(k\)</span> si</p>
<p><span class="math display" id="eq:LDA">\[\begin{align}
\delta_k(x)=x\frac{\mu_k}{\sigma^2}-\frac{\mu_k^2}{2\sigma^2}+\log(\pi_k)
\tag{7.2}
\end{align}\]</span></p>
<p>es el máximo entre los valores correspondientes a cada clase. A esta función se le llama <em>función discriminante</em>.</p>
<p>El método de análisis discriminante lineal (LDA) asume que:
<span class="math display">\[\begin{align*}
\hat \mu_k&amp;=\frac{1}{n_k}\sum_{i:y_i=k}x_i\\
\hat \sigma^2&amp;=\frac{1}{n-K}\sum_{k=1}^K\sum_{i:y_i=k}(x_i-\hat \mu_k)^2\\
\hat \pi_k &amp;=\frac{n_k}{n}
\end{align*}\]</span></p>
<p>como estimadores plug-in en <a href="08-clasificacion.html#eq:LDA">(7.2)</a>.</p>
</div>
<div id="caso-p1-1" class="section level4 hasAnchor" number="7.3.1.2">
<h4><span class="header-section-number">7.3.1.2</span> Caso p&gt;1<a href="08-clasificacion.html#caso-p1-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Generalizando la sección anterior, podemos asumir que <span class="math inline">\(X=(X_1,\ldots,X_p)\)</span> proviene de una distribución Gaussiana multivariada. Es decir, asuma que las observaciones en la clase <span class="math inline">\(k\)</span> tienen distribución <span class="math inline">\(N(\mu_k,\Sigma)\)</span> donde <span class="math inline">\(\mu_k\)</span>: vector de medias para la clase <span class="math inline">\(k\)</span> y <span class="math inline">\(\Sigma\)</span> es la matriz de varianza-covarianza para todas las <span class="math inline">\(K\)</span> clases.</p>
<p>La función discriminante en este caso sería:
<span class="math display">\[\delta_k(x)=x^T\Sigma^{-1} \mu_k-\frac 1 2\mu_k^T \Sigma^{-1}\mu_k+\log \pi_k\]</span>
El método LDA sustituye los parámetros en la fórmula anterior con estimadores empíricos, tal y como se hizo para <span class="math inline">\(p=1\)</span>. La escogencia de la clase estimada sigue el mismo criterio.</p>
<div class="figure">
<img src="manual_figures/LDA.png" alt="" />
<p class="caption">Simulación de Análisis Discriminante Lineal <span class="citation">(James et al. 2013)</span></p>
</div>
</div>
</div>
<div id="análisis-discriminante-cuadrático" class="section level3 hasAnchor" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Análisis discriminante cuadrático<a href="08-clasificacion.html#análisis-discriminante-cuadrático" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Bajo los supuestos del LDA, asuma que <span class="math inline">\(\Sigma_k\)</span> es la matriz de covarianza para la clase <span class="math inline">\(k\)</span>. En este caso las funciones discriminantes tendrían la forma:
<span class="math display">\[\delta_k(x)=-\frac 1 2 (x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k)-\frac 1 2 \log |\Sigma_k|+\log \pi_k\]</span>
Al uso de las funciones anteriores como herramientas de clasificación se le llama Análisis Discriminante Cuadrático (QDA).</p>
<p>Relación LDA vs QDA:</p>
<ul>
<li>LDA es menos flexible que QDA, por la diferencia en el número de parámetros. Por lo tanto LDA tiene menos varianza que QDA.</li>
<li>Si el supuesto de varianzas constantes en LDA no es adecuado, entonces el sesgo es alto.</li>
<li>QDA es más adecuado que LDA cuando el número de observaciones es relativamente alto, debido a que el supuesto de varianzas constantes es más difícil de alcanzar.</li>
</ul>
<p>Comparación de métodos:</p>
<ul>
<li>LDA y regresión logística producen fronteras de decisión lineales.</li>
<li>LDA asume más sobre el comportamiento de los datos, con respecto a la regresión logística.</li>
<li>KNN es no paramétrico, por lo tanto produce fronteras de decisión más flexibles que LDA o QDA. El grado de suavidad del clasificador (en términos de sus fronteras) depende del parámetro <span class="math inline">\(K\)</span>.</li>
<li>QDA ofrece fronteras de decisión más flexibles que LDA o logística.</li>
<li>KNN no tiene la misma capacidad de interpretabilidad que la regresión logística.</li>
<li>Como KNN depende de la distancia entre observaciones, entonces la escala de las covariables importa.</li>
</ul>
</div>
</div>
<div id="laboratorio-7" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Laboratorio<a href="08-clasificacion.html#laboratorio-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Datos sociodemográficos y de productos de aseguramiento de 5822 clientes. La variable dependiente es si cada cliente adquirió un seguro de remolques (<a href="https://liacs.leidenuniv.nl/~puttenpwhvander/library/cc2000/data.html" class="uri">https://liacs.leidenuniv.nl/~puttenpwhvander/library/cc2000/data.html</a>).</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="08-clasificacion.html#cb401-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb401-2"><a href="08-clasificacion.html#cb401-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Caravan)</span>
<span id="cb401-3"><a href="08-clasificacion.html#cb401-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(Caravan)</span></code></pre></div>
<pre><code>## [1] 5822   86</code></pre>
<p>Vamos a usar las herramientas en el paquete <em>tidymodels</em> para efectuar una comparación entre los métodos de clasificación que hemos visto en clase. El objetivo es clasificar a los clientes entre compradores/no compradores del seguro (variable dependiente: Purchase, covariables: el resto)</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="08-clasificacion.html#cb403-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb403-2"><a href="08-clasificacion.html#cb403-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<p>El primer paso es construir una separación de conjunto de entrenamiento y de conjunto de prueba:</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="08-clasificacion.html#cb404-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb404-2"><a href="08-clasificacion.html#cb404-2" aria-hidden="true" tabindex="-1"></a>Caravan.split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(Caravan, <span class="at">prop =</span> <span class="fl">0.8</span>,</span>
<span id="cb404-3"><a href="08-clasificacion.html#cb404-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">strata =</span> Purchase)</span>
<span id="cb404-4"><a href="08-clasificacion.html#cb404-4" aria-hidden="true" tabindex="-1"></a>Caravan.training <span class="ot">&lt;-</span> Caravan.split <span class="sc">%&gt;%</span></span>
<span id="cb404-5"><a href="08-clasificacion.html#cb404-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">training</span>()</span>
<span id="cb404-6"><a href="08-clasificacion.html#cb404-6" aria-hidden="true" tabindex="-1"></a>Caravan.testing <span class="ot">&lt;-</span> Caravan.split <span class="sc">%&gt;%</span></span>
<span id="cb404-7"><a href="08-clasificacion.html#cb404-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">testing</span>()</span></code></pre></div>
<p>Como vamos a usar el método KNN, lo conveniente es estandarizar todas las covariables:</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="08-clasificacion.html#cb405-1" aria-hidden="true" tabindex="-1"></a>Caravan.recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Purchase <span class="sc">~</span> ., <span class="at">data =</span> Caravan.training) <span class="sc">%&gt;%</span></span>
<span id="cb405-2"><a href="08-clasificacion.html#cb405-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">step_normalize</span>(<span class="fu">all_predictors</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>())</span></code></pre></div>
<p>y aplicamos la receta sobre el conjunto de prueba para verificar que la receta funciona bien:</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="08-clasificacion.html#cb406-1" aria-hidden="true" tabindex="-1"></a>Caravan.recipe <span class="sc">%&gt;%</span></span>
<span id="cb406-2"><a href="08-clasificacion.html#cb406-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">prep</span>() <span class="sc">%&gt;%</span></span>
<span id="cb406-3"><a href="08-clasificacion.html#cb406-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bake</span>(<span class="at">new_data =</span> Caravan.testing)</span></code></pre></div>
<pre><code>## # A tibble: 1,165 x 86
##    MOSTYPE MAANTHUI MGEMOMV MGEMLEEF MOSHOOFD MGODRK MGODPR  MGODOV MGODGE
##      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
##  1  -0.101   -0.275  -0.856  -2.45     -0.274 -0.695  0.225 -1.05    1.08 
##  2   0.680   -0.275  -0.856   0.0258    0.779 -0.695  1.39  -1.05   -0.792
##  3  -1.19    -0.275   0.401   0.0258   -0.977  0.288 -0.936  0.917   0.457
##  4   0.680    2.27    0.401   0.0258    0.779 -0.695 -0.356  0.917  -0.168
##  5  -0.881    2.27    1.66    0.0258   -0.977 -0.695 -0.356  0.917   0.457
##  6   1.23    -0.275   0.401   0.0258    1.48  -0.695 -0.936 -1.05    1.71 
##  7   0.680   -0.275   1.66    0.0258    0.779  0.288 -0.356 -0.0652  1.08 
##  8  -1.35    -0.275   0.401  -1.21     -1.33  -0.695  1.39   0.917  -2.04 
##  9  -1.66    -0.275   0.401   0.0258   -1.68   1.27   1.39  -1.05   -2.04 
## 10   1.07    -0.275   0.401   0.0258    1.13  -0.695  0.225 -0.0652 -0.168
## # ... with 1,155 more rows, and 77 more variables: MRELGE &lt;dbl&gt;, MRELSA &lt;dbl&gt;,
## #   MRELOV &lt;dbl&gt;, MFALLEEN &lt;dbl&gt;, MFGEKIND &lt;dbl&gt;, MFWEKIND &lt;dbl&gt;,
## #   MOPLHOOG &lt;dbl&gt;, MOPLMIDD &lt;dbl&gt;, MOPLLAAG &lt;dbl&gt;, MBERHOOG &lt;dbl&gt;,
## #   MBERZELF &lt;dbl&gt;, MBERBOER &lt;dbl&gt;, MBERMIDD &lt;dbl&gt;, MBERARBG &lt;dbl&gt;,
## #   MBERARBO &lt;dbl&gt;, MSKA &lt;dbl&gt;, MSKB1 &lt;dbl&gt;, MSKB2 &lt;dbl&gt;, MSKC &lt;dbl&gt;,
## #   MSKD &lt;dbl&gt;, MHHUUR &lt;dbl&gt;, MHKOOP &lt;dbl&gt;, MAUT1 &lt;dbl&gt;, MAUT2 &lt;dbl&gt;,
## #   MAUT0 &lt;dbl&gt;, MZFONDS &lt;dbl&gt;, MZPART &lt;dbl&gt;, MINKM30 &lt;dbl&gt;, ...</code></pre>
<div id="clasificador-logístico" class="section level3 hasAnchor" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Clasificador logístico<a href="08-clasificacion.html#clasificador-logístico" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Vamos a ajustar un modelo logístico a los datos. Primero especificamos el modelo:</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="08-clasificacion.html#cb408-1" aria-hidden="true" tabindex="-1"></a>modelo_logistico <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>() <span class="sc">%&gt;%</span></span>
<span id="cb408-2"><a href="08-clasificacion.html#cb408-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_engine</span>(<span class="st">&quot;glm&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb408-3"><a href="08-clasificacion.html#cb408-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span></code></pre></div>
<p>y después definimos un objeto tipo <em>workflow</em> para unir el tratamiento de datos (recipe) con el modelo:</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="08-clasificacion.html#cb409-1" aria-hidden="true" tabindex="-1"></a>logistico_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb409-2"><a href="08-clasificacion.html#cb409-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_model</span>(modelo_logistico) <span class="sc">%&gt;%</span></span>
<span id="cb409-3"><a href="08-clasificacion.html#cb409-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_recipe</span>(Caravan.recipe)</span></code></pre></div>
<p>y ajustamos el modelo:</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="08-clasificacion.html#cb410-1" aria-hidden="true" tabindex="-1"></a>logistico_ajuste <span class="ot">&lt;-</span> logistico_wf <span class="sc">%&gt;%</span></span>
<span id="cb410-2"><a href="08-clasificacion.html#cb410-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">fit</span>(<span class="at">data =</span> Caravan.training)</span></code></pre></div>
<p>Obtenemos predicciones en el conjunto de prueba:</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="08-clasificacion.html#cb411-1" aria-hidden="true" tabindex="-1"></a>predicciones_probs <span class="ot">&lt;-</span> <span class="fu">predict</span>(logistico_ajuste, <span class="at">new_data =</span> Caravan.testing,</span>
<span id="cb411-2"><a href="08-clasificacion.html#cb411-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb411-3"><a href="08-clasificacion.html#cb411-3" aria-hidden="true" tabindex="-1"></a>predicciones_categ <span class="ot">&lt;-</span> <span class="fu">predict</span>(logistico_ajuste, <span class="at">new_data =</span> Caravan.testing)</span>
<span id="cb411-4"><a href="08-clasificacion.html#cb411-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(predicciones_probs)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   .pred_No .pred_Yes
##      &lt;dbl&gt;     &lt;dbl&gt;
## 1    0.981   0.0189 
## 2    0.990   0.0100 
## 3    0.880   0.120  
## 4    0.921   0.0787 
## 5    0.967   0.0329 
## 6    0.994   0.00628</code></pre>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="08-clasificacion.html#cb413-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(predicciones_categ)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 1
##   .pred_class
##   &lt;fct&gt;      
## 1 No         
## 2 No         
## 3 No         
## 4 No         
## 5 No         
## 6 No</code></pre>
<p>Unimos todos los resultados en un solo arreglo:</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="08-clasificacion.html#cb415-1" aria-hidden="true" tabindex="-1"></a>resultados_logistico <span class="ot">&lt;-</span> Caravan.testing <span class="sc">%&gt;%</span></span>
<span id="cb415-2"><a href="08-clasificacion.html#cb415-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(Purchase) <span class="sc">%&gt;%</span></span>
<span id="cb415-3"><a href="08-clasificacion.html#cb415-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(predicciones_categ) <span class="sc">%&gt;%</span></span>
<span id="cb415-4"><a href="08-clasificacion.html#cb415-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(predicciones_probs)</span></code></pre></div>
<p>y podemos calcular la matriz de confusión:</p>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb416-1"><a href="08-clasificacion.html#cb416-1" aria-hidden="true" tabindex="-1"></a><span class="fu">conf_mat</span>(resultados_logistico, <span class="at">truth =</span> Purchase, <span class="at">estimate =</span> .pred_class)</span></code></pre></div>
<pre><code>##           Truth
## Prediction   No  Yes
##        No  1095   64
##        Yes    4    2</code></pre>
<p>curva ROC:</p>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="08-clasificacion.html#cb418-1" aria-hidden="true" tabindex="-1"></a><span class="fu">roc_curve</span>(resultados_logistico, <span class="at">truth =</span> Purchase, <span class="at">estimate =</span> .pred_No) <span class="sc">%&gt;%</span></span>
<span id="cb418-2"><a href="08-clasificacion.html#cb418-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">autoplot</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-253-1.svg" width="100%" style="display: block; margin: auto;" />
y finalmente el área bajo la curva ROC:</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="08-clasificacion.html#cb419-1" aria-hidden="true" tabindex="-1"></a><span class="fu">roc_auc</span>(resultados_logistico, <span class="at">truth =</span> Purchase, <span class="at">estimate =</span> .pred_No)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.728</code></pre>
<p>Existe otra alternativa de ajuste con el comando <em>last_fit</em> que automatiza el proceso:</p>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="08-clasificacion.html#cb421-1" aria-hidden="true" tabindex="-1"></a>last_fit_logistica <span class="ot">&lt;-</span> logistico_wf <span class="sc">%&gt;%</span></span>
<span id="cb421-2"><a href="08-clasificacion.html#cb421-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">last_fit</span>(<span class="at">split =</span> Caravan.split)</span></code></pre></div>
<p>Obtenemos métricas:</p>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="08-clasificacion.html#cb422-1" aria-hidden="true" tabindex="-1"></a>last_fit_logistica <span class="sc">%&gt;%</span></span>
<span id="cb422-2"><a href="08-clasificacion.html#cb422-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">collect_metrics</span>()</span></code></pre></div>
<pre><code>## # A tibble: 2 x 4
##   .metric  .estimator .estimate .config             
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy binary         0.942 Preprocessor1_Model1
## 2 roc_auc  binary         0.728 Preprocessor1_Model1</code></pre>
<p>y predicciones:</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="08-clasificacion.html#cb424-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(last_fit_logistica <span class="sc">%&gt;%</span></span>
<span id="cb424-2"><a href="08-clasificacion.html#cb424-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">collect_predictions</span>())</span></code></pre></div>
<pre><code>## # A tibble: 6 x 7
##   id               .pred_No .pred_Yes  .row .pred_class Purchase .config        
##   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;       &lt;fct&gt;    &lt;chr&gt;          
## 1 train/test split    0.981   0.0189      6 No          No       Preprocessor1_~
## 2 train/test split    0.990   0.0100      8 No          No       Preprocessor1_~
## 3 train/test split    0.880   0.120      12 No          No       Preprocessor1_~
## 4 train/test split    0.921   0.0787     22 No          No       Preprocessor1_~
## 5 train/test split    0.967   0.0329     25 No          No       Preprocessor1_~
## 6 train/test split    0.994   0.00628    28 No          No       Preprocessor1_~</code></pre>
</div>
<div id="análisis-discriminante-lineal-1" class="section level3 hasAnchor" number="7.4.2">
<h3><span class="header-section-number">7.4.2</span> Análisis Discriminante Lineal<a href="08-clasificacion.html#análisis-discriminante-lineal-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Usando el mismo procedimiento de datos anterior, definimos el modelo LDA:</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="08-clasificacion.html#cb426-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(discrim)</span></code></pre></div>
<pre><code>## Error in library(discrim): there is no package called &#39;discrim&#39;</code></pre>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="08-clasificacion.html#cb428-1" aria-hidden="true" tabindex="-1"></a>modelo_lda <span class="ot">&lt;-</span> <span class="fu">discrim_linear</span>() <span class="sc">%&gt;%</span></span>
<span id="cb428-2"><a href="08-clasificacion.html#cb428-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_engine</span>(<span class="st">&quot;MASS&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb428-3"><a href="08-clasificacion.html#cb428-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span></code></pre></div>
<p>flujo de trabajo:</p>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="08-clasificacion.html#cb429-1" aria-hidden="true" tabindex="-1"></a>lda_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb429-2"><a href="08-clasificacion.html#cb429-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_model</span>(modelo_lda) <span class="sc">%&gt;%</span></span>
<span id="cb429-3"><a href="08-clasificacion.html#cb429-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_recipe</span>(Caravan.recipe)</span></code></pre></div>
<p>ajuste del modelo:</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="08-clasificacion.html#cb430-1" aria-hidden="true" tabindex="-1"></a>last_fit_lda <span class="ot">&lt;-</span> lda_wf <span class="sc">%&gt;%</span></span>
<span id="cb430-2"><a href="08-clasificacion.html#cb430-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">last_fit</span>(<span class="at">split =</span> Caravan.split)</span></code></pre></div>
<pre><code>## Error in pkgs$pkg[[1]]: subscript out of bounds</code></pre>
<p>Métricas de LDA:</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="08-clasificacion.html#cb432-1" aria-hidden="true" tabindex="-1"></a>last_fit_lda <span class="sc">%&gt;%</span></span>
<span id="cb432-2"><a href="08-clasificacion.html#cb432-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">collect_metrics</span>()</span></code></pre></div>
<pre><code>## Error in collect_metrics(.): object &#39;last_fit_lda&#39; not found</code></pre>
<p>curva ROC:</p>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="08-clasificacion.html#cb434-1" aria-hidden="true" tabindex="-1"></a>lda_predicciones <span class="ot">&lt;-</span> last_fit_lda <span class="sc">%&gt;%</span></span>
<span id="cb434-2"><a href="08-clasificacion.html#cb434-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">collect_predictions</span>()</span></code></pre></div>
<pre><code>## Error in collect_predictions(.): object &#39;last_fit_lda&#39; not found</code></pre>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="08-clasificacion.html#cb436-1" aria-hidden="true" tabindex="-1"></a>lda_predicciones <span class="sc">%&gt;%</span></span>
<span id="cb436-2"><a href="08-clasificacion.html#cb436-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">roc_curve</span>(<span class="at">truth =</span> Purchase, <span class="at">estimate =</span> .pred_No) <span class="sc">%&gt;%</span></span>
<span id="cb436-3"><a href="08-clasificacion.html#cb436-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">autoplot</span>()</span></code></pre></div>
<pre><code>## Error in roc_curve(., truth = Purchase, estimate = .pred_No): object &#39;lda_predicciones&#39; not found</code></pre>
<p>y matriz de confusión:</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="08-clasificacion.html#cb438-1" aria-hidden="true" tabindex="-1"></a>lda_predicciones <span class="sc">%&gt;%</span></span>
<span id="cb438-2"><a href="08-clasificacion.html#cb438-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">conf_mat</span>(<span class="at">truth =</span> Purchase, <span class="at">estimate =</span> .pred_class)</span></code></pre></div>
<pre><code>## Error in conf_mat(., truth = Purchase, estimate = .pred_class): object &#39;lda_predicciones&#39; not found</code></pre>
</div>
<div id="análisis-discriminante-cuadrático-1" class="section level3 hasAnchor" number="7.4.3">
<h3><span class="header-section-number">7.4.3</span> Análisis Discriminante Cuadrático<a href="08-clasificacion.html#análisis-discriminante-cuadrático-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este caso usaremos otro generador (<em>klaR</em>).</p>
<p>Nota: El argumento <em>frac_common_cov=1</em> permite hacer LDA en lugar de QDA.</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="08-clasificacion.html#cb440-1" aria-hidden="true" tabindex="-1"></a>modelo_qda <span class="ot">&lt;-</span> <span class="fu">discrim_regularized</span>(<span class="at">frac_common_cov =</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb440-2"><a href="08-clasificacion.html#cb440-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_engine</span>(<span class="st">&quot;klaR&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb440-3"><a href="08-clasificacion.html#cb440-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="08-clasificacion.html#cb441-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(klaR)</span></code></pre></div>
<pre><code>## Error in library(klaR): there is no package called &#39;klaR&#39;</code></pre>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb443-1"><a href="08-clasificacion.html#cb443-1" aria-hidden="true" tabindex="-1"></a>qda_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb443-2"><a href="08-clasificacion.html#cb443-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_model</span>(modelo_qda) <span class="sc">%&gt;%</span></span>
<span id="cb443-3"><a href="08-clasificacion.html#cb443-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_recipe</span>(Caravan.recipe)</span>
<span id="cb443-4"><a href="08-clasificacion.html#cb443-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb443-5"><a href="08-clasificacion.html#cb443-5" aria-hidden="true" tabindex="-1"></a>last_fit_qda <span class="ot">&lt;-</span> qda_wf <span class="sc">%&gt;%</span></span>
<span id="cb443-6"><a href="08-clasificacion.html#cb443-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">last_fit</span>(<span class="at">split =</span> Caravan.split)</span></code></pre></div>
<pre><code>## Error in pkgs$pkg[[1]]: subscript out of bounds</code></pre>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb445-1"><a href="08-clasificacion.html#cb445-1" aria-hidden="true" tabindex="-1"></a>last_fit_qda <span class="sc">%&gt;%</span></span>
<span id="cb445-2"><a href="08-clasificacion.html#cb445-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">collect_metrics</span>()</span></code></pre></div>
<pre><code>## Error in collect_metrics(.): object &#39;last_fit_qda&#39; not found</code></pre>
<div class="sourceCode" id="cb447"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb447-1"><a href="08-clasificacion.html#cb447-1" aria-hidden="true" tabindex="-1"></a>qda_predicciones <span class="ot">&lt;-</span> last_fit_qda <span class="sc">%&gt;%</span></span>
<span id="cb447-2"><a href="08-clasificacion.html#cb447-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">collect_predictions</span>()</span></code></pre></div>
<pre><code>## Error in collect_predictions(.): object &#39;last_fit_qda&#39; not found</code></pre>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb449-1"><a href="08-clasificacion.html#cb449-1" aria-hidden="true" tabindex="-1"></a>qda_predicciones <span class="sc">%&gt;%</span></span>
<span id="cb449-2"><a href="08-clasificacion.html#cb449-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">roc_curve</span>(<span class="at">truth =</span> Purchase, <span class="at">estimate =</span> .pred_No) <span class="sc">%&gt;%</span></span>
<span id="cb449-3"><a href="08-clasificacion.html#cb449-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">autoplot</span>()</span></code></pre></div>
<pre><code>## Error in roc_curve(., truth = Purchase, estimate = .pred_No): object &#39;qda_predicciones&#39; not found</code></pre>
<div class="sourceCode" id="cb451"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb451-1"><a href="08-clasificacion.html#cb451-1" aria-hidden="true" tabindex="-1"></a>qda_predicciones <span class="sc">%&gt;%</span></span>
<span id="cb451-2"><a href="08-clasificacion.html#cb451-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">conf_mat</span>(<span class="at">truth =</span> Purchase, <span class="at">estimate =</span> .pred_class)</span></code></pre></div>
<pre><code>## Error in conf_mat(., truth = Purchase, estimate = .pred_class): object &#39;qda_predicciones&#39; not found</code></pre>
</div>
<div id="k-vecinos-más-cercanos" class="section level3 hasAnchor" number="7.4.4">
<h3><span class="header-section-number">7.4.4</span> K vecinos más cercanos<a href="08-clasificacion.html#k-vecinos-más-cercanos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el caso del KNN se va a seleccionar el número de vecinos a través de validación cruzada, usando como métrica el AUC. Primero definimos los conjuntos bajo el k-fold:</p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb453-1"><a href="08-clasificacion.html#cb453-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">178</span>)</span>
<span id="cb453-2"><a href="08-clasificacion.html#cb453-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb453-3"><a href="08-clasificacion.html#cb453-3" aria-hidden="true" tabindex="-1"></a>Caravan.folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(Caravan.training, <span class="at">v =</span> <span class="dv">5</span>,</span>
<span id="cb453-4"><a href="08-clasificacion.html#cb453-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">strata =</span> Purchase)</span></code></pre></div>
<p>y definimos el modelo KNN y el flujo de trabajo:</p>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb454-1"><a href="08-clasificacion.html#cb454-1" aria-hidden="true" tabindex="-1"></a>modelo_knn <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">neighbors =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb454-2"><a href="08-clasificacion.html#cb454-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb454-3"><a href="08-clasificacion.html#cb454-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb454-4"><a href="08-clasificacion.html#cb454-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb454-5"><a href="08-clasificacion.html#cb454-5" aria-hidden="true" tabindex="-1"></a>knn_wf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb454-6"><a href="08-clasificacion.html#cb454-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_model</span>(modelo_knn) <span class="sc">%&gt;%</span></span>
<span id="cb454-7"><a href="08-clasificacion.html#cb454-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_recipe</span>(Caravan.recipe)</span></code></pre></div>
<p>Definimos una grilla de posibles valores de # de vecinos que usaremos en el k-fold:</p>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb455-1"><a href="08-clasificacion.html#cb455-1" aria-hidden="true" tabindex="-1"></a>k_grid <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">neighbors =</span> <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">75</span>, <span class="dv">100</span>, <span class="dv">125</span>, <span class="dv">150</span>,</span>
<span id="cb455-2"><a href="08-clasificacion.html#cb455-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">175</span>, <span class="dv">200</span>, <span class="dv">225</span>))</span>
<span id="cb455-3"><a href="08-clasificacion.html#cb455-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb455-4"><a href="08-clasificacion.html#cb455-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">178</span>)</span>
<span id="cb455-5"><a href="08-clasificacion.html#cb455-5" aria-hidden="true" tabindex="-1"></a>knn_tuning <span class="ot">&lt;-</span> knn_wf <span class="sc">%&gt;%</span></span>
<span id="cb455-6"><a href="08-clasificacion.html#cb455-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(<span class="at">resamples =</span> Caravan.folds, <span class="at">grid =</span> k_grid)</span></code></pre></div>
<pre><code>## Error in `check_installs()`:
## ! Some package installs are required: 
## * &#39;kknn&#39;, &#39;kknn&#39;</code></pre>
<p>y se selecciona el modelo con el mejor AUC:</p>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="08-clasificacion.html#cb457-1" aria-hidden="true" tabindex="-1"></a>knn_tuning <span class="sc">%&gt;%</span></span>
<span id="cb457-2"><a href="08-clasificacion.html#cb457-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">show_best</span>(<span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
<pre><code>## Error in show_best(., &quot;roc_auc&quot;): object &#39;knn_tuning&#39; not found</code></pre>
<p>mejor modelo y actualización del flujo de trabajo:</p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb459-1"><a href="08-clasificacion.html#cb459-1" aria-hidden="true" tabindex="-1"></a>mejor_knn <span class="ot">&lt;-</span> knn_tuning <span class="sc">%&gt;%</span></span>
<span id="cb459-2"><a href="08-clasificacion.html#cb459-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select_best</span>(<span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
<pre><code>## Error in show_best(x, metric = metric, n = 1): object &#39;knn_tuning&#39; not found</code></pre>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="08-clasificacion.html#cb461-1" aria-hidden="true" tabindex="-1"></a>final_knn_wf <span class="ot">&lt;-</span> knn_wf <span class="sc">%&gt;%</span></span>
<span id="cb461-2"><a href="08-clasificacion.html#cb461-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">finalize_workflow</span>(mejor_knn)</span></code></pre></div>
<pre><code>## Error in check_final_param(parameters): object &#39;mejor_knn&#39; not found</code></pre>
<p>Ahora ajustamos el modelo y analizamos su rendimiento con los conjuntos de entrenamiento y prueba iniciales:</p>
<div class="sourceCode" id="cb463"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb463-1"><a href="08-clasificacion.html#cb463-1" aria-hidden="true" tabindex="-1"></a>last_fit_knn <span class="ot">&lt;-</span> final_knn_wf <span class="sc">%&gt;%</span></span>
<span id="cb463-2"><a href="08-clasificacion.html#cb463-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">last_fit</span>(<span class="at">split =</span> Caravan.split)</span></code></pre></div>
<pre><code>## Error in last_fit(., split = Caravan.split): object &#39;final_knn_wf&#39; not found</code></pre>
<div class="sourceCode" id="cb465"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb465-1"><a href="08-clasificacion.html#cb465-1" aria-hidden="true" tabindex="-1"></a>last_fit_knn <span class="sc">%&gt;%</span></span>
<span id="cb465-2"><a href="08-clasificacion.html#cb465-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">collect_metrics</span>()</span></code></pre></div>
<pre><code>## Error in collect_metrics(.): object &#39;last_fit_knn&#39; not found</code></pre>
<div class="sourceCode" id="cb467"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb467-1"><a href="08-clasificacion.html#cb467-1" aria-hidden="true" tabindex="-1"></a>knn_predicciones <span class="ot">&lt;-</span> last_fit_knn <span class="sc">%&gt;%</span></span>
<span id="cb467-2"><a href="08-clasificacion.html#cb467-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">collect_predictions</span>()</span></code></pre></div>
<pre><code>## Error in collect_predictions(.): object &#39;last_fit_knn&#39; not found</code></pre>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb469-1"><a href="08-clasificacion.html#cb469-1" aria-hidden="true" tabindex="-1"></a>knn_predicciones <span class="sc">%&gt;%</span></span>
<span id="cb469-2"><a href="08-clasificacion.html#cb469-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">roc_curve</span>(<span class="at">truth =</span> Purchase, <span class="at">estimate =</span> .pred_No) <span class="sc">%&gt;%</span></span>
<span id="cb469-3"><a href="08-clasificacion.html#cb469-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">autoplot</span>()</span></code></pre></div>
<pre><code>## Error in roc_curve(., truth = Purchase, estimate = .pred_No): object &#39;knn_predicciones&#39; not found</code></pre>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="08-clasificacion.html#cb471-1" aria-hidden="true" tabindex="-1"></a>knn_predicciones <span class="sc">%&gt;%</span></span>
<span id="cb471-2"><a href="08-clasificacion.html#cb471-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">conf_mat</span>(<span class="at">truth =</span> Purchase, <span class="at">estimate =</span> .pred_class)</span></code></pre></div>
<pre><code>## Error in conf_mat(., truth = Purchase, estimate = .pred_class): object &#39;knn_predicciones&#39; not found</code></pre>
</div>
</div>
<div id="ejercicios-5" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> Ejercicios<a href="08-clasificacion.html#ejercicios-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Del libro <span class="citation">(James et al. 2013)</span>
<ul>
<li>Capítulo 4: 10, 11, 13.</li>
</ul></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="06-seleccion-de-variables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="09-calculo-bayes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica/edit/master/08-clasificacion.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica/blob/master/08-clasificacion.Rmd",
"text": null
},
"download": ["Notas-Curso-Estadistica.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"toc_depth": 5
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
