<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 9 Cálculo Bayesiano Computacional | Notas Curso de Estadística II</title>
  <meta name="description" content="Capítulo 9 Cálculo Bayesiano Computacional | Notas Curso de Estadística II" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 9 Cálculo Bayesiano Computacional | Notas Curso de Estadística II" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 9 Cálculo Bayesiano Computacional | Notas Curso de Estadística II" />
  
  
  

<meta name="author" content="Maikol Solís Chacón y Luis Barboza Chinchilla" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="07-componentes-principales.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso de Estadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html"><i class="fa fa-check"></i><b>2</b> Estimación no-paramétrica de densidades</a>
<ul>
<li class="chapter" data-level="2.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#histograma"><i class="fa fa-check"></i><b>2.1</b> Histograma</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#construcción-estadística"><i class="fa fa-check"></i><b>2.1.1</b> Construcción Estadística</a></li>
<li class="chapter" data-level="2.1.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#construcción-probabilística"><i class="fa fa-check"></i><b>2.1.2</b> Construcción probabilística</a></li>
<li class="chapter" data-level="2.1.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas"><i class="fa fa-check"></i><b>2.1.3</b> Propiedades estadísticas</a></li>
<li class="chapter" data-level="2.1.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas-1"><i class="fa fa-check"></i><b>2.1.4</b> Propiedades estadísticas</a></li>
<li class="chapter" data-level="2.1.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#sesgo"><i class="fa fa-check"></i><b>2.1.5</b> Sesgo</a></li>
<li class="chapter" data-level="2.1.6" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#varianza"><i class="fa fa-check"></i><b>2.1.6</b> Varianza</a></li>
<li class="chapter" data-level="2.1.7" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio"><i class="fa fa-check"></i><b>2.1.7</b> Error cuadrático medio</a></li>
<li class="chapter" data-level="2.1.8" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio-integrado"><i class="fa fa-check"></i><b>2.1.8</b> Error cuadrático medio integrado</a></li>
<li class="chapter" data-level="2.1.9" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo-para-el-histograma"><i class="fa fa-check"></i><b>2.1.9</b> Ancho de banda óptimo para el histograma</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#estimación-de-densidades-basada-en-kernels."><i class="fa fa-check"></i><b>2.2</b> Estimación de densidades basada en kernels.</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#primera-construcción"><i class="fa fa-check"></i><b>2.2.1</b> Primera construcción</a></li>
<li class="chapter" data-level="2.2.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#otra-construcción"><i class="fa fa-check"></i><b>2.2.2</b> Otra construcción</a></li>
<li class="chapter" data-level="2.2.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas-2"><i class="fa fa-check"></i><b>2.2.3</b> Propiedades Estadísticas</a></li>
<li class="chapter" data-level="2.2.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#sesgo-1"><i class="fa fa-check"></i><b>2.2.4</b> Sesgo</a></li>
<li class="chapter" data-level="2.2.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio-y-error-cuadrático-medio-integrado"><i class="fa fa-check"></i><b>2.2.5</b> Error cuadrático medio y Error cuadrático medio integrado</a></li>
<li class="chapter" data-level="2.2.6" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo"><i class="fa fa-check"></i><b>2.2.6</b> Ancho de banda óptimo</a></li>
<li class="chapter" data-level="2.2.7" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#intervalos-de-confianza-para-estimadores-de-densidad-no-paramétricos"><i class="fa fa-check"></i><b>2.2.7</b> Intervalos de confianza para estimadores de densidad no paramétricos</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#laboratorio"><i class="fa fa-check"></i><b>2.3</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#efecto-de-distintos-kernels-en-la-estimación"><i class="fa fa-check"></i><b>2.3.1</b> Efecto de distintos Kernels en la estimación</a></li>
<li class="chapter" data-level="2.3.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#efecto-del-ancho-de-banda-en-la-estimación"><i class="fa fa-check"></i><b>2.3.2</b> Efecto del ancho de banda en la estimación</a></li>
<li class="chapter" data-level="2.3.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo-1"><i class="fa fa-check"></i><b>2.3.3</b> Ancho de banda óptimo</a></li>
<li class="chapter" data-level="2.3.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#validación-cruzada-1"><i class="fa fa-check"></i><b>2.3.4</b> Validación cruzada</a></li>
<li class="chapter" data-level="2.3.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#temas-adicionales"><i class="fa fa-check"></i><b>2.3.5</b> Temas adicionales</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ejercicios"><i class="fa fa-check"></i><b>2.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html"><i class="fa fa-check"></i><b>3</b> Jackknife y Bootstrap</a>
<ul>
<li class="chapter" data-level="3.1" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#caso-concreto"><i class="fa fa-check"></i><b>3.1</b> Caso concreto</a></li>
<li class="chapter" data-level="3.2" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#jackknife"><i class="fa fa-check"></i><b>3.2</b> Jackknife</a></li>
<li class="chapter" data-level="3.3" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#bootstrap"><i class="fa fa-check"></i><b>3.3</b> Bootstrap</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>3.3.1</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="3.3.2" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#resumiendo"><i class="fa fa-check"></i><b>3.3.2</b> Resumiendo</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#ejercicios-1"><i class="fa fa-check"></i><b>3.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html"><i class="fa fa-check"></i><b>4</b> Métodos lineales de regresión</a>
<ul>
<li class="chapter" data-level="4.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#introducción-al-aprendizaje-estadístico."><i class="fa fa-check"></i><b>4.1</b> Introducción al Aprendizaje Estadístico.</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#formas-de-estimar-f"><i class="fa fa-check"></i><b>4.1.1</b> Formas de estimar <span class="math inline">\(f\)</span></a></li>
<li class="chapter" data-level="4.1.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#medidas-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>4.1.2</b> Medidas de bondad de ajuste</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#regresión-lineal"><i class="fa fa-check"></i><b>4.2</b> Regresión lineal</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#forma-matricial"><i class="fa fa-check"></i><b>4.2.1</b> Forma matricial</a></li>
<li class="chapter" data-level="4.2.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-1"><i class="fa fa-check"></i><b>4.2.2</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#propiedades-estadísticas-3"><i class="fa fa-check"></i><b>4.3</b> Propiedades estadísticas</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#prueba-t"><i class="fa fa-check"></i><b>4.3.1</b> Prueba <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="4.3.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#prueba-f"><i class="fa fa-check"></i><b>4.3.2</b> Prueba <span class="math inline">\(F\)</span></a></li>
<li class="chapter" data-level="4.3.3" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-2"><i class="fa fa-check"></i><b>4.3.3</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#medida-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>4.4</b> Medida de bondad de ajuste</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-3"><i class="fa fa-check"></i><b>4.4.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#predicción"><i class="fa fa-check"></i><b>4.5</b> Predicción</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-4"><i class="fa fa-check"></i><b>4.5.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#interacciones"><i class="fa fa-check"></i><b>4.6</b> Interacciones</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-5"><i class="fa fa-check"></i><b>4.6.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#supuestos"><i class="fa fa-check"></i><b>4.7</b> Supuestos</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#chequeos-básicos-de-las-hipótesis-de-regresión-lineal"><i class="fa fa-check"></i><b>4.7.1</b> Chequeos básicos de las hipótesis de regresión lineal</a></li>
<li class="chapter" data-level="4.7.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#otros-chequeos-importantes"><i class="fa fa-check"></i><b>4.7.2</b> Otros chequeos importantes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#ejercicios-2"><i class="fa fa-check"></i><b>4.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html"><i class="fa fa-check"></i><b>5</b> Regresión Logística</a>
<ul>
<li class="chapter" data-level="5.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#preliminares"><i class="fa fa-check"></i><b>5.1</b> Preliminares</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#oportunidad-relativa-odds-ratio"><i class="fa fa-check"></i><b>5.1.1</b> Oportunidad relativa (Odds Ratio)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#máxima-verosimilitud"><i class="fa fa-check"></i><b>5.2</b> Máxima verosimilitud</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#resultados-adicionales"><i class="fa fa-check"></i><b>5.2.1</b> Resultados adicionales</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#diágnosticos-del-modelo"><i class="fa fa-check"></i><b>5.3</b> Diágnosticos del modelo</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#supuesto-de-linealidad"><i class="fa fa-check"></i><b>5.3.1</b> Supuesto de linealidad</a></li>
<li class="chapter" data-level="5.3.2" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#valores-de-gran-influencia"><i class="fa fa-check"></i><b>5.3.2</b> Valores de gran influencia</a></li>
<li class="chapter" data-level="5.3.3" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#multicolinealidad-1"><i class="fa fa-check"></i><b>5.3.3</b> Multicolinealidad</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#predicción-y-poder-de-clasificación"><i class="fa fa-check"></i><b>5.4</b> Predicción y poder de clasificación</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#curva-roc"><i class="fa fa-check"></i><b>5.4.1</b> Curva ROC</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#ejercicios-3"><i class="fa fa-check"></i><b>5.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html"><i class="fa fa-check"></i><b>6</b> Métodos de selección de variables y regularización</a>
<ul>
<li class="chapter" data-level="6.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#estimación-del-error-de-prueba"><i class="fa fa-check"></i><b>6.1</b> Estimación del error de prueba</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#técnica-de-conjunto-de-validación"><i class="fa fa-check"></i><b>6.1.1</b> Técnica de conjunto de validación</a></li>
<li class="chapter" data-level="6.1.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-leave-one-out-loocv"><i class="fa fa-check"></i><b>6.1.2</b> Validación cruzada “Leave-One-Out” (LOOCV)</a></li>
<li class="chapter" data-level="6.1.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-k-veces"><i class="fa fa-check"></i><b>6.1.3</b> Validación cruzada <span class="math inline">\(k-\)</span>veces</a></li>
<li class="chapter" data-level="6.1.4" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-para-clasificación"><i class="fa fa-check"></i><b>6.1.4</b> Validación cruzada para clasificación</a></li>
<li class="chapter" data-level="6.1.5" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#otras-medidas-de-error-de-prueba"><i class="fa fa-check"></i><b>6.1.5</b> Otras medidas de error de prueba</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-variables"><i class="fa fa-check"></i><b>6.2</b> Selección de variables</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-del-mejor-subconjunto."><i class="fa fa-check"></i><b>6.2.1</b> Selección del mejor subconjunto.</a></li>
<li class="chapter" data-level="6.2.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-modelos-hacia-adelante-forward-stepwise-selection"><i class="fa fa-check"></i><b>6.2.2</b> Selección de modelos hacia adelante (<strong>Forward Stepwise Selection</strong>)</a></li>
<li class="chapter" data-level="6.2.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-modelos-hacia-atrás-backward-stepwise-selection"><i class="fa fa-check"></i><b>6.2.3</b> Selección de modelos hacia atrás (<strong>Backward Stepwise Selection</strong>)</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#métodos-de-regularización"><i class="fa fa-check"></i><b>6.3</b> Métodos de regularización</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-ridge"><i class="fa fa-check"></i><b>6.3.1</b> Regresión Ridge</a></li>
<li class="chapter" data-level="6.3.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-lasso"><i class="fa fa-check"></i><b>6.3.2</b> Regresión Lasso</a></li>
<li class="chapter" data-level="6.3.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#explicación-gráfica"><i class="fa fa-check"></i><b>6.3.3</b> Explicación gráfica</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#laboratorio-6"><i class="fa fa-check"></i><b>6.4</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#cross-validation"><i class="fa fa-check"></i><b>6.4.1</b> Cross-Validation</a></li>
<li class="chapter" data-level="6.4.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-lasso-1"><i class="fa fa-check"></i><b>6.4.2</b> Regresión Lasso</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#ejercicios-4"><i class="fa fa-check"></i><b>6.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="08-clasificacion.html"><a href="08-clasificacion.html"><i class="fa fa-check"></i><b>7</b> Otros Clasificadores</a>
<ul>
<li class="chapter" data-level="7.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#clasificador-bayesiano"><i class="fa fa-check"></i><b>7.1</b> Clasificador Bayesiano</a></li>
<li class="chapter" data-level="7.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#método-de-k-vecinos-más-cercanos-knn"><i class="fa fa-check"></i><b>7.2</b> Método de k vecinos más cercanos (KNN)</a></li>
<li class="chapter" data-level="7.3" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante"><i class="fa fa-check"></i><b>7.3</b> Análisis Discriminante</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-lineal"><i class="fa fa-check"></i><b>7.3.1</b> Análisis discriminante lineal</a></li>
<li class="chapter" data-level="7.3.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-cuadrático"><i class="fa fa-check"></i><b>7.3.2</b> Análisis discriminante cuadrático</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="08-clasificacion.html"><a href="08-clasificacion.html#laboratorio-7"><i class="fa fa-check"></i><b>7.4</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#clasificador-logístico"><i class="fa fa-check"></i><b>7.4.1</b> Clasificador logístico</a></li>
<li class="chapter" data-level="7.4.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-lineal-1"><i class="fa fa-check"></i><b>7.4.2</b> Análisis Discriminante Lineal</a></li>
<li class="chapter" data-level="7.4.3" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-cuadrático-1"><i class="fa fa-check"></i><b>7.4.3</b> Análisis Discriminante Cuadrático</a></li>
<li class="chapter" data-level="7.4.4" data-path="08-clasificacion.html"><a href="08-clasificacion.html#k-vecinos-más-cercanos"><i class="fa fa-check"></i><b>7.4.4</b> K vecinos más cercanos</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="08-clasificacion.html"><a href="08-clasificacion.html#ejercicios-5"><i class="fa fa-check"></i><b>7.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html"><i class="fa fa-check"></i><b>8</b> Análisis en componentes principales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#representación-gráfica"><i class="fa fa-check"></i><b>8.1</b> Representación gráfica</a></li>
<li class="chapter" data-level="8.2" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#aprendizaje-no-supervisado"><i class="fa fa-check"></i><b>8.2</b> Aprendizaje no-supervisado</a></li>
<li class="chapter" data-level="8.3" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#primer-componente-principal"><i class="fa fa-check"></i><b>8.3</b> Primer componente principal</a></li>
<li class="chapter" data-level="8.4" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#segunda-componente-principal"><i class="fa fa-check"></i><b>8.4</b> Segunda componente principal</a></li>
<li class="chapter" data-level="8.5" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#circulo-de-correlaciones"><i class="fa fa-check"></i><b>8.5</b> Circulo de correlaciones</a></li>
<li class="chapter" data-level="8.6" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#volvamos-a-nuestro-ejemplo"><i class="fa fa-check"></i><b>8.6</b> Volvamos a nuestro ejemplo</a></li>
<li class="chapter" data-level="8.7" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#cuántos-componentes-usar"><i class="fa fa-check"></i><b>8.7</b> ¿Cuántos componentes usar?</a></li>
<li class="chapter" data-level="8.8" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#laboratorio-8"><i class="fa fa-check"></i><b>8.8</b> Laboratorio</a></li>
<li class="chapter" data-level="8.9" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#ejercicios-6"><i class="fa fa-check"></i><b>8.9</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html"><i class="fa fa-check"></i><b>9</b> Cálculo Bayesiano Computacional</a>
<ul>
<li class="chapter" data-level="9.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#repaso-de-estadística-bayesiana"><i class="fa fa-check"></i><b>9.1</b> Repaso de Estadística Bayesiana</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#modelo-de-un-parámetro"><i class="fa fa-check"></i><b>9.1.1</b> Modelo de un parámetro</a></li>
<li class="chapter" data-level="9.1.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#modelo-de-más-de-un-parámetro"><i class="fa fa-check"></i><b>9.1.2</b> Modelo de más de un parámetro</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#motivación-cálculo-de-integrales"><i class="fa fa-check"></i><b>9.2</b> Motivación: Cálculo de Integrales</a></li>
<li class="chapter" data-level="9.3" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejemplo-base-modelo-beta-binomial."><i class="fa fa-check"></i><b>9.3</b> Ejemplo base: modelo beta-binomial.</a></li>
<li class="chapter" data-level="9.4" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#aproximación-de-laplace"><i class="fa fa-check"></i><b>9.4</b> Aproximación de Laplace</a></li>
<li class="chapter" data-level="9.5" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#simulación"><i class="fa fa-check"></i><b>9.5</b> Simulación</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#simulación-monte-carlo"><i class="fa fa-check"></i><b>9.5.1</b> Simulación Monte Carlo</a></li>
<li class="chapter" data-level="9.5.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#muestreo-por-rechazo"><i class="fa fa-check"></i><b>9.5.2</b> Muestreo por rechazo</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#muestreo-por-importancia"><i class="fa fa-check"></i><b>9.6</b> Muestreo por importancia</a></li>
<li class="chapter" data-level="9.7" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#remuestreo-por-importancia"><i class="fa fa-check"></i><b>9.7</b> Remuestreo por importancia</a></li>
<li class="chapter" data-level="9.8" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#métodos-monte-carlo"><i class="fa fa-check"></i><b>9.8</b> Métodos Monte Carlo</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejemplo-del-viajero-con-una-moneda"><i class="fa fa-check"></i><b>9.8.1</b> Ejemplo del viajero con una moneda</a></li>
<li class="chapter" data-level="9.8.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#cadenas-de-markov"><i class="fa fa-check"></i><b>9.8.2</b> Cadenas de Markov</a></li>
<li class="chapter" data-level="9.8.3" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#el-algoritmo-de-metropolis-hasting"><i class="fa fa-check"></i><b>9.8.3</b> El algoritmo de Metropolis-Hasting</a></li>
<li class="chapter" data-level="9.8.4" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#por-qué-el-algoritmo-de-metropolis-hasting-funciona"><i class="fa fa-check"></i><b>9.8.4</b> ¿Por qué el algoritmo de Metropolis Hasting funciona?</a></li>
<li class="chapter" data-level="9.8.5" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#extensión-al-caso-del-viajero"><i class="fa fa-check"></i><b>9.8.5</b> Extensión al caso del viajero</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#el-problema-del-viajero-con-dos-monedas"><i class="fa fa-check"></i><b>9.9</b> El problema del viajero con dos monedas</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#muestreo-de-gibbs"><i class="fa fa-check"></i><b>9.9.1</b> Muestreo de Gibbs</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#uso-de-jags"><i class="fa fa-check"></i><b>9.10</b> Uso de JAGS</a></li>
<li class="chapter" data-level="9.11" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#uso-de-stan"><i class="fa fa-check"></i><b>9.11</b> Uso de STAN</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notas Curso de Estadística II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="cálculo-bayesiano-computacional" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Capítulo 9</span> Cálculo Bayesiano Computacional<a href="09-calculo-bayes.html#cálculo-bayesiano-computacional" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="repaso-de-estadística-bayesiana" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Repaso de Estadística Bayesiana<a href="09-calculo-bayes.html#repaso-de-estadística-bayesiana" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="modelo-de-un-parámetro" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> Modelo de un parámetro<a href="09-calculo-bayes.html#modelo-de-un-parámetro" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Vamos a considerar el ejemplo en la sección 3.3 del <span class="citation">(Albert et al. 2009)</span>. En este caso se quiere estimar la tasa de éxito en transplantes de corazón en un hospital de EEUU. Suponga que en ese hospital hay <span class="math inline">\(n\)</span> transplantes e <span class="math inline">\(y\)</span> es el número de muertes en el transcurso de 30 días del transplante. Si se sabe el número esperado de muertes <span class="math inline">\(e\)</span> a través de un modelo auxiliar, entonces un modelo sencillo para <span class="math inline">\(y\)</span> es asumir que:
<span class="math display">\[y\sim \text{Poisson}(e\lambda)\]</span>
donde <span class="math inline">\(\lambda\)</span> es la tasa de mortalidad por unidad de exposición y tiempo.</p>
<dl>
<dt><strong>Solución clásica:</strong></dt>
<dd>
<p>Estimar <span class="math inline">\(\hat \lambda=y/e\)</span>, pero el estimador es malo si hay pocas muertes observadas <span class="math inline">\(y\)</span>.</p>
</dd>
<dt><strong>Solución bayesiana:</strong></dt>
<dd>
<p>Considere una previa conjugada (gamma) para <span class="math inline">\(\lambda\)</span> de la forma,</p>
</dd>
</dl>
<p><span class="math display">\[p(\lambda)\propto \lambda^{\alpha-1}\exp(-\beta \lambda).\]</span></p>
<p>La ventaja de los modelos bayesianos es que se pueden integrar información externa al modelo. Supongamos que se cuenta con información externa de un grupo pequeño de hospitales con condiciones similares a la del hospital de interés, es decir se cuenta con muertes <span class="math inline">\(z_j\)</span> y exposición <span class="math inline">\(o_j\)</span> para diez hospitales (<span class="math inline">\(j=1,\ldots,10\)</span>). Asumamos que cada hospital tiene el la distribución de sus muertes de la forma,</p>
<p><span class="math display">\[z_j\sim \text{Poisson}(o_j\lambda).\]</span></p>
<p>Entonces, asignamos una previa no-informativa a <span class="math inline">\(p(\lambda)\propto \lambda^{-1}\)</span> (cuando <span class="math inline">\(\alpha=0\)</span> y <span class="math inline">\(\lambda=0\)</span>) y se obtiene un previa actualiza con todos los hospitales para <span class="math inline">\(\lambda\)</span> de la forma,</p>
<p><span class="math display">\[p(\lambda)\propto \lambda^{\sum_{j=1}^{10}z_j-1}\exp{\left(-\lambda\sum_{j=1}^{10} o_j\right)}\]</span></p>
<p>Suponga que <span class="math inline">\(\alpha:=\sum z_j=16\)</span> y <span class="math inline">\(\beta:=\sum o_j=15174\)</span>. Si para el hospital de interés <span class="math inline">\(y_{obs}\)</span> es el número observado de muertes y <span class="math inline">\(e\)</span> es la exposición entonces la distribución posterior de <span class="math inline">\(\lambda\)</span> es:
<span class="math display">\[g(\lambda|y_{obs})\sim \Gamma(\alpha+y_{obs},\beta+e)\]</span>
y la densidad predictiva de <span class="math inline">\(y\)</span> es (Ejercicio):
<span class="math display">\[f(y)=\frac{f(y|\lambda)p(\lambda)}{g(\lambda|y_{obs})}\]</span></p>
<p>donde <span class="math inline">\(f(y|\lambda)\sim \text{Poisson}(e\lambda)\)</span> (verosimilitud).</p>
<p>Supongamos que existen dos posibles hospitales:</p>
<ul>
<li>Hospital A: Se observa una muerte con 66 personas expuestas. Cálculo de la densidad posterior y densidad predictiva con <span class="math inline">\(\lambda = \alpha/\beta\)</span>:</li>
</ul>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb543-1"><a href="09-calculo-bayes.html#cb543-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">16</span></span>
<span id="cb543-2"><a href="09-calculo-bayes.html#cb543-2" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="dv">15174</span></span>
<span id="cb543-3"><a href="09-calculo-bayes.html#cb543-3" aria-hidden="true" tabindex="-1"></a>yobs <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb543-4"><a href="09-calculo-bayes.html#cb543-4" aria-hidden="true" tabindex="-1"></a>ex <span class="ot">&lt;-</span> <span class="dv">66</span></span>
<span id="cb543-5"><a href="09-calculo-bayes.html#cb543-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">10</span></span>
<span id="cb543-6"><a href="09-calculo-bayes.html#cb543-6" aria-hidden="true" tabindex="-1"></a>lam <span class="ot">&lt;-</span> alpha<span class="sc">/</span>beta</span>
<span id="cb543-7"><a href="09-calculo-bayes.html#cb543-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb543-8"><a href="09-calculo-bayes.html#cb543-8" aria-hidden="true" tabindex="-1"></a><span class="do">## f(y|lambda) p(lambda) / g(lambda|y_obs)</span></span>
<span id="cb543-9"><a href="09-calculo-bayes.html#cb543-9" aria-hidden="true" tabindex="-1"></a>fy <span class="ot">&lt;-</span> <span class="fu">dpois</span>(y, lam <span class="sc">*</span> ex) <span class="sc">*</span> <span class="fu">dgamma</span>(lam, <span class="at">shape =</span> alpha,</span>
<span id="cb543-10"><a href="09-calculo-bayes.html#cb543-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">rate =</span> beta)<span class="sc">/</span><span class="fu">dgamma</span>(lam, <span class="at">shape =</span> alpha <span class="sc">+</span> y, <span class="at">rate =</span> beta <span class="sc">+</span></span>
<span id="cb543-11"><a href="09-calculo-bayes.html#cb543-11" aria-hidden="true" tabindex="-1"></a>    ex)</span>
<span id="cb543-12"><a href="09-calculo-bayes.html#cb543-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb543-13"><a href="09-calculo-bayes.html#cb543-13" aria-hidden="true" tabindex="-1"></a>dpred <span class="ot">&lt;-</span> <span class="fu">tibble</span>(y, fy)</span>
<span id="cb543-14"><a href="09-calculo-bayes.html#cb543-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb543-15"><a href="09-calculo-bayes.html#cb543-15" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dpred) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> y, <span class="at">y =</span> fy)) <span class="sc">+</span></span>
<span id="cb543-16"><a href="09-calculo-bayes.html#cb543-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> yobs, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-315-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>por lo tanto una muerte no es un valor inusual en el comportamiento de muertes bajo transplantes. La comparación de las densidades posterior y previa de lambda:</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="09-calculo-bayes.html#cb544-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb544-2"><a href="09-calculo-bayes.html#cb544-2" aria-hidden="true" tabindex="-1"></a>lambda_prev <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">1000</span>, <span class="at">shape =</span> alpha, <span class="at">rate =</span> beta)</span>
<span id="cb544-3"><a href="09-calculo-bayes.html#cb544-3" aria-hidden="true" tabindex="-1"></a>lambda_post <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">1000</span>, <span class="at">shape =</span> alpha <span class="sc">+</span> yobs, <span class="at">rate =</span> beta <span class="sc">+</span></span>
<span id="cb544-4"><a href="09-calculo-bayes.html#cb544-4" aria-hidden="true" tabindex="-1"></a>    ex)</span>
<span id="cb544-5"><a href="09-calculo-bayes.html#cb544-5" aria-hidden="true" tabindex="-1"></a>datoslambda <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">Previa =</span> lambda_prev, <span class="at">Posterior =</span> lambda_post) <span class="sc">%&gt;%</span></span>
<span id="cb544-6"><a href="09-calculo-bayes.html#cb544-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">everything</span>())</span>
<span id="cb544-7"><a href="09-calculo-bayes.html#cb544-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb544-8"><a href="09-calculo-bayes.html#cb544-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> datoslambda) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> value,</span>
<span id="cb544-9"><a href="09-calculo-bayes.html#cb544-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> name)) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-316-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<ul>
<li>Hospital B: 4 muertes en 1767 expuestos. Mismos cálculos:</li>
</ul>
<div class="sourceCode" id="cb545"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb545-1"><a href="09-calculo-bayes.html#cb545-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">16</span></span>
<span id="cb545-2"><a href="09-calculo-bayes.html#cb545-2" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="dv">15174</span></span>
<span id="cb545-3"><a href="09-calculo-bayes.html#cb545-3" aria-hidden="true" tabindex="-1"></a>yobs <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb545-4"><a href="09-calculo-bayes.html#cb545-4" aria-hidden="true" tabindex="-1"></a>ex <span class="ot">&lt;-</span> <span class="dv">1767</span></span>
<span id="cb545-5"><a href="09-calculo-bayes.html#cb545-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">10</span></span>
<span id="cb545-6"><a href="09-calculo-bayes.html#cb545-6" aria-hidden="true" tabindex="-1"></a>lam <span class="ot">&lt;-</span> alpha<span class="sc">/</span>beta</span>
<span id="cb545-7"><a href="09-calculo-bayes.html#cb545-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb545-8"><a href="09-calculo-bayes.html#cb545-8" aria-hidden="true" tabindex="-1"></a>fy <span class="ot">&lt;-</span> <span class="fu">dpois</span>(y, lam <span class="sc">*</span> ex) <span class="sc">*</span> <span class="fu">dgamma</span>(lam, <span class="at">shape =</span> alpha,</span>
<span id="cb545-9"><a href="09-calculo-bayes.html#cb545-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">rate =</span> beta)<span class="sc">/</span><span class="fu">dgamma</span>(lam, <span class="at">shape =</span> alpha <span class="sc">+</span> y, <span class="at">rate =</span> beta <span class="sc">+</span></span>
<span id="cb545-10"><a href="09-calculo-bayes.html#cb545-10" aria-hidden="true" tabindex="-1"></a>    ex)</span>
<span id="cb545-11"><a href="09-calculo-bayes.html#cb545-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb545-12"><a href="09-calculo-bayes.html#cb545-12" aria-hidden="true" tabindex="-1"></a>dpred <span class="ot">&lt;-</span> <span class="fu">tibble</span>(y, fy)</span>
<span id="cb545-13"><a href="09-calculo-bayes.html#cb545-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb545-14"><a href="09-calculo-bayes.html#cb545-14" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dpred) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> y, <span class="at">y =</span> fy)) <span class="sc">+</span></span>
<span id="cb545-15"><a href="09-calculo-bayes.html#cb545-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> yobs, <span class="at">col =</span> <span class="dv">2</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-317-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="09-calculo-bayes.html#cb546-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb546-2"><a href="09-calculo-bayes.html#cb546-2" aria-hidden="true" tabindex="-1"></a>lambda_prev <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">1000</span>, <span class="at">shape =</span> alpha, <span class="at">rate =</span> beta)</span>
<span id="cb546-3"><a href="09-calculo-bayes.html#cb546-3" aria-hidden="true" tabindex="-1"></a>lambda_post <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">1000</span>, <span class="at">shape =</span> alpha <span class="sc">+</span> yobs, <span class="at">rate =</span> beta <span class="sc">+</span></span>
<span id="cb546-4"><a href="09-calculo-bayes.html#cb546-4" aria-hidden="true" tabindex="-1"></a>    ex)</span>
<span id="cb546-5"><a href="09-calculo-bayes.html#cb546-5" aria-hidden="true" tabindex="-1"></a>datoslambda <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">Previa =</span> lambda_prev, <span class="at">Posterior =</span> lambda_post) <span class="sc">%&gt;%</span></span>
<span id="cb546-6"><a href="09-calculo-bayes.html#cb546-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">everything</span>())</span>
<span id="cb546-7"><a href="09-calculo-bayes.html#cb546-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb546-8"><a href="09-calculo-bayes.html#cb546-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> datoslambda) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> value,</span>
<span id="cb546-9"><a href="09-calculo-bayes.html#cb546-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> name)) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-318-1.svg" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="modelo-de-más-de-un-parámetro" class="section level3 hasAnchor" number="9.1.2">
<h3><span class="header-section-number">9.1.2</span> Modelo de más de un parámetro<a href="09-calculo-bayes.html#modelo-de-más-de-un-parámetro" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Se usará el ejemplo de la sección 4.2 del <span class="citation">(Albert et al. 2009)</span> para ilustrar la inferencia bayesiana conjugada en el caso de más un parámetro. Suponga que se tiene datos del tiempo en completar la maratón de Nueva York para 20 atletas entre 20 y 29 años y asumimos que la muestra proviene de una <span class="math inline">\(N(\mu,\sigma^2)\)</span>. Si asumimos la previa no informativa:</p>
<p><span class="math display">\[g(\mu,\sigma^2) \propto 1/\sigma^2\]</span></p>
<p>entonces la distribución posterior de <span class="math inline">\((\mu,\sigma^2)\)</span> es:
<span class="math display">\[g(\mu,\sigma^2|y)\propto \frac{1}{(\sigma^2)^{n/2+1}}\exp{\left(-\frac{1}{2\sigma^2}\left(S+n(\mu-\bar y)^2\right)\right)}\]</span></p>
<p>donde <span class="math inline">\(n\)</span> es el tamaño de muestra, <span class="math inline">\(\bar y\)</span> es la media empírica y <span class="math inline">\(S=\sum_{i=1}^n(y_i-\bar y)^2\)</span>. Recuerden que la distribución posterior conjunta satisface:</p>
<ul>
<li>La distribución posterior de <span class="math inline">\(\mu\)</span> condicional en <span class="math inline">\(\sigma^2\)</span> se distribuye como <span class="math inline">\(N(\bar y,\sigma/\sqrt{n})\)</span>.</li>
<li>La distribución posterior marginal de <span class="math inline">\(\sigma^2\)</span> se distribuye según <span class="math inline">\(S\chi_{n-1}^{-2}\)</span> (<span class="math inline">\(S\)</span> veces una chi-cuadrada inversa con <span class="math inline">\(n-1\)</span> grados de libertad).</li>
</ul>
<p>Cargamos los datos de los 20 atletas:</p>
<div class="sourceCode" id="cb547"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb547-1"><a href="09-calculo-bayes.html#cb547-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(LearnBayes)</span>
<span id="cb547-2"><a href="09-calculo-bayes.html#cb547-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(marathontimes)</span></code></pre></div>
<pre><code>##   time
## 1  182
## 2  201
## 3  221
## 4  234
## 5  237
## 6  251</code></pre>
<p>y graficamos un diagrama de contorno de la distribución posterior de <span class="math inline">\(\mu,\sigma^2\)</span>:</p>
<div class="sourceCode" id="cb549"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb549-1"><a href="09-calculo-bayes.html#cb549-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(marathontimes)</span>
<span id="cb549-2"><a href="09-calculo-bayes.html#cb549-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(<span class="at">logf =</span> normchi2post, <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">220</span>, <span class="dv">330</span>,</span>
<span id="cb549-3"><a href="09-calculo-bayes.html#cb549-3" aria-hidden="true" tabindex="-1"></a>    <span class="dv">500</span>, <span class="dv">9000</span>), <span class="at">data =</span> time, <span class="at">xlab =</span> <span class="st">&quot;media&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;varianza&quot;</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-320-1.svg" width="100%" style="display: block; margin: auto;" />
y les agregamos una muestra aleatoria de tamaño 1000 de la distribución posterior conjunta, generada a través de las distribuciones marginales:</p>
<div class="sourceCode" id="cb550"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb550-1"><a href="09-calculo-bayes.html#cb550-1" aria-hidden="true" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="fu">sum</span>((time <span class="sc">-</span> <span class="fu">mean</span>(time))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb550-2"><a href="09-calculo-bayes.html#cb550-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(time)</span>
<span id="cb550-3"><a href="09-calculo-bayes.html#cb550-3" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> S<span class="sc">/</span><span class="fu">rchisq</span>(<span class="dv">1000</span>, n <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb550-4"><a href="09-calculo-bayes.html#cb550-4" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="at">mean =</span> <span class="fu">mean</span>(time), <span class="at">sd =</span> <span class="fu">sqrt</span>(sigma2)<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb550-5"><a href="09-calculo-bayes.html#cb550-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb550-6"><a href="09-calculo-bayes.html#cb550-6" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(normchi2post, <span class="fu">c</span>(<span class="dv">220</span>, <span class="dv">330</span>, <span class="dv">500</span>, <span class="dv">9000</span>), time,</span>
<span id="cb550-7"><a href="09-calculo-bayes.html#cb550-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;media&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;varianza&quot;</span>)</span>
<span id="cb550-8"><a href="09-calculo-bayes.html#cb550-8" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(mu, sigma2)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-321-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>Si estamos interesados en hacer inferencia de <span class="math inline">\(\mu\)</span>, podemos calcular un intervalo de credibilidad al 95%, usando la muestra marginal:</p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb551-1"><a href="09-calculo-bayes.html#cb551-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(mu, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 255.1484 301.2853</code></pre>
<p>y también inferencia sobre <span class="math inline">\(\sigma\)</span>:</p>
<div class="sourceCode" id="cb553"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb553-1"><a href="09-calculo-bayes.html#cb553-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(<span class="fu">sqrt</span>(sigma2), <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 37.66930 72.69096</code></pre>
<p>o aún sobre otros parámetros, por ejemplo el coeficiente de variación (<span class="math inline">\(CV=\sigma/\mu\)</span>):</p>
<div class="sourceCode" id="cb555"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb555-1"><a href="09-calculo-bayes.html#cb555-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(<span class="fu">sqrt</span>(sigma2)<span class="sc">/</span>mu, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##      2.5%     97.5% 
## 0.1334257 0.2677118</code></pre>
</div>
</div>
<div id="motivación-cálculo-de-integrales" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Motivación: Cálculo de Integrales<a href="09-calculo-bayes.html#motivación-cálculo-de-integrales" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Recuerden que según el teorema de Bayes, si observamos datos <span class="math inline">\(y\)</span> a partir de una verosimilitud <span class="math inline">\(f(y|\theta)\)</span> y se le asigna al parámetro <span class="math inline">\(\theta\)</span> una previa <span class="math inline">\(g(\theta)\)</span>, entonces:</p>
<p><span class="math display">\[g(\theta|y)\propto g(\theta)f(y|\theta)\]</span></p>
<p><strong>Problema</strong>: tratar de manejar la distribución posterior de <span class="math inline">\(\theta\)</span> desde un punto de vista computacional con el fin de hacer inferencia.</p>
<p>Los procesos de inferencia requieren el cálculo o aproximación de integrales, por ejemplo:</p>
<ul>
<li>Valor esperado de una función de <span class="math inline">\(\theta\)</span>:</li>
</ul>
<p><span class="math display">\[E(h(\theta)|y)=\frac{\int h(\theta)g(\theta)f(y|\theta) d\theta}{\int g(\theta)f(y|\theta) d\theta}\]</span></p>
<ul>
<li>Probabilidad posterior de que <span class="math inline">\(h(\theta) \in A\)</span>:</li>
</ul>
<p><span class="math display">\[P(h(\theta) \in A|y)=\frac{\int_{h(\theta) \in A} g(\theta)f(y|\theta) d\theta}{\int g(\theta)f(y|\theta) d\theta}\]</span>
- Densidades marginales. Si <span class="math inline">\(\theta=(\theta_1,\theta_2)\)</span> y se quiere obtener la distribución para <span class="math inline">\(\theta_1\)</span>, entonces se integra con respecto a <span class="math inline">\(\theta_2\)</span>.</p>
<p><span class="math display">\[g(\theta_1|y)\propto \int g(\theta_1,\theta_2|y)d\theta_2\]</span></p>
</div>
<div id="ejemplo-base-modelo-beta-binomial." class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Ejemplo base: modelo beta-binomial.<a href="09-calculo-bayes.html#ejemplo-base-modelo-beta-binomial." class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En este ejemplo se estimará las tasas de muerte por cáncer gástrico en una población de hombres entre 45 y 64 años. Para ello se tiene datos de muertes <span class="math inline">\(y_j\)</span> y exposición <span class="math inline">\(n_j\)</span> para 20 ciudades en Missouri:</p>
<div class="sourceCode" id="cb557"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb557-1"><a href="09-calculo-bayes.html#cb557-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;cancermortality&quot;</span>)</span>
<span id="cb557-2"><a href="09-calculo-bayes.html#cb557-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(cancermortality)</span></code></pre></div>
<pre><code>##   y    n
## 1 0 1083
## 2 0  855
## 3 2 3461
## 4 0  657
## 5 1 1208
## 6 1 1025</code></pre>
<p>Un primer intento de modelación podría considerar <span class="math inline">\(y_j\sim \text{Binomial}(p,n_j)\)</span>. Es decir que existe una probabilidad común <span class="math inline">\(p\)</span> para toda la población.</p>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb559-1"><a href="09-calculo-bayes.html#cb559-1" aria-hidden="true" tabindex="-1"></a>(p_emp <span class="ot">&lt;-</span> <span class="fu">sum</span>(cancermortality<span class="sc">$</span>y)<span class="sc">/</span>(<span class="fu">sum</span>(cancermortality<span class="sc">$</span>n)))</span></code></pre></div>
<pre><code>## [1] 0.0009933126</code></pre>
<div class="sourceCode" id="cb561"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb561-1"><a href="09-calculo-bayes.html#cb561-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(cancermortality<span class="sc">$</span>y)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-327-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb562-1"><a href="09-calculo-bayes.html#cb562-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(cancermortality<span class="sc">$</span>n)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-327-2.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>En este caso se puede comprobar que el modelo binomial no logra captar la variabilidad de las muertes totalmente.</p>
<p>Otro intento de modelación que no tiene ese problema es un modelo beta-binomial con media <span class="math inline">\(\eta\)</span> y precisión <span class="math inline">\(K\)</span>:
<span class="math display">\[f(y_j|\eta,K)={n_j \choose y_j}\frac{B(K\eta+y_j,K(1-\eta)+n_j-y_j)}{B(K\eta,K(1-\eta))}\]</span>
con previa no informativa:
<span class="math display">\[g(\eta,K)\propto \frac{1}{\eta(1-\eta)}\frac{1}{(1+K)^2}\]</span>
entonces la densidad posterior de los parámetros sería:
<span class="math display">\[g(\eta,K|\text{datos})\propto \frac{1}{\eta(1-\eta)}\frac{1}{(1+K)^2} \prod_{j=1}^{20}\frac{B(K\eta+y_j,K(1-\eta)+n_j-y_j)}{B(K\eta,K(1-\eta))}\]</span>
donde <span class="math inline">\(0&lt;\eta&lt;1\)</span>, <span class="math inline">\(K&gt;0\)</span> y <span class="math inline">\(B(\cdot,\cdot)\)</span> es la función beta. La función <em>betabinexch0</em> contiene la implementación de la log-densidad posterior de <span class="math inline">\(\eta,K\)</span>:</p>
<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb563-1"><a href="09-calculo-bayes.html#cb563-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(betabinexch0, <span class="fu">c</span>(<span class="fl">1e-04</span>, <span class="fl">0.003</span>, <span class="dv">1</span>, <span class="dv">20000</span>),</span>
<span id="cb563-2"><a href="09-calculo-bayes.html#cb563-2" aria-hidden="true" tabindex="-1"></a>    cancermortality, <span class="at">xlab =</span> <span class="st">&quot;eta&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;K&quot;</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-328-1.svg" width="100%" style="display: block; margin: auto;" />
y note la gran asimetría en el comportamiento de la densidad conjunta, especialmente en la dirección de la variable <span class="math inline">\(K\)</span>. Por el dominio de las variables <span class="math inline">\(K\)</span> y <span class="math inline">\(\eta\)</span>, entonces se transforman según:
<span class="math display">\[\theta_1=\text{logit}(\eta)=\log\left(\frac{\eta}{1-\eta}\right),\quad  \theta_2=\log(K)\]</span>
y usando el teorema de cambio de variable en densidades:
<span class="math display">\[g_1(\theta_1,\theta_2|\text{datos})=g\left(\frac{e^{\theta_1}}{1+e^{\theta_2}},e^{\theta_2}\right)\frac{e^{\theta_1+\theta_2}}{(1+e^{\theta_2})^2}\]</span>
<span class="math inline">\(g_1\)</span> está implementada en la función <em>betabinexch</em> y el gráfico de contorno es más manejable ahora desde el punto de vista computacional:</p>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb564-1"><a href="09-calculo-bayes.html#cb564-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(betabinexch, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">8</span>, <span class="sc">-</span><span class="fl">4.5</span>, <span class="dv">3</span>, <span class="fl">16.5</span>), cancermortality,</span>
<span id="cb564-2"><a href="09-calculo-bayes.html#cb564-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;logit eta&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;log K&quot;</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-329-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>Definitivamente esta es una distribución posterior a la que no se le puede aplicar las técnicas usuales para hacer inferencia (caso no conjugado). Se va a considerar dos formas de realizar inferencia:</p>
<ul>
<li>Aproximación de Laplace.</li>
<li>Simulación Monte Carlo.</li>
</ul>
</div>
<div id="aproximación-de-laplace" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Aproximación de Laplace<a href="09-calculo-bayes.html#aproximación-de-laplace" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Un forma de resumir el comportamiento de la posterior, es a través del comportamiento de la moda de la densidad.</p>
<p>Considere el logaritmo de la densidad posterior conjunta de <span class="math inline">\(\theta\)</span> e <span class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[h(\theta,y)=\log(g(\theta)f(y|\theta))\]</span></p>
<p>Suponga que <span class="math inline">\(\hat \theta\)</span> es la moda de <span class="math inline">\(\theta\)</span>. Un desarrollo de Taylor alrededor de <span class="math inline">\(\hat \theta\)</span> para <span class="math inline">\(h(\theta)\)</span> da la siguiente aproximación:</p>
<p><span class="math display">\[h(\theta)\approx h(\hat \theta)+ (\theta - \hat{\theta})^{\top}h^{\prime}(\theta) + \frac{1}{2}(\theta-\hat \theta)^\top h^{\prime\prime}(\hat \theta)(\theta-\hat \theta)\]</span></p>
<p>Ahora dado que <span class="math inline">\(h^{\prime}(\hat{\theta})=0\)</span> dado que es la moda, entonces la expresión se simplifica a:</p>
<p><span class="math display">\[h(\theta)\approx h(\hat \theta) + \frac{1}{2}(\theta-\hat \theta)^\top h^{\prime\prime}(\hat \theta)(\theta-\hat \theta)\]</span></p>
<p>Para estimar el comportamiento de <span class="math inline">\(\theta\)</span> note que</p>
<p><span class="math display">\[\begin{align*}
g(\theta)f(y\mid \theta)
&amp;= \exp\left(h(\theta)\right)\\
&amp;= \exp \left(h(\hat \theta) + \frac{1}{2}(\theta-\hat \theta)^\top h^{\prime\prime}(\hat \theta)(\theta-\hat \theta \right) \\
&amp;= \exp \left(h(\hat \theta)\right) \exp\left(\frac{1}{2}(\theta-\hat \theta)^\top h^{\prime\prime}(\hat \theta)(\theta-\hat \theta \right) \\
&amp;= \exp \left(h(\hat \theta)\right) \exp\left(-\frac{1}{2}(\theta-\hat \theta)^\top (-h^{\prime\prime}(\hat \theta))^{-1}(\theta-\hat \theta \right) \\
\end{align*}\]</span></p>
<p>Por lo tanto podemos aproximar el comportamiento en distribución de <span class="math inline">\(\theta\)</span> como:</p>
<p><span class="math display">\[\theta \sim N(\hat \theta,V)\]</span></p>
<p>donde <span class="math inline">\(V=(-h^{\prime\prime}(\hat \theta))^{-1}\)</span>.</p>
<p>Se podría encontrar una solución analítica del problema integrando <span class="math inline">\(\exp(h(\theta,y))\)</span> con respecto a <span class="math inline">\(\theta\)</span> y obteniendo la posterior predictiva de la siguiente forma,</p>
<p><span class="math display">\[
f(y) \approx(2 \pi)^{d / 2} g(\hat{\theta}) f(y \mid \hat{\theta})\left|-h^{\prime \prime}(\hat{\theta})\right|^{1 / 2}.
\]</span></p>
<p>Con el fin de encontrar la moda <span class="math inline">\(\hat \theta\)</span> se puede usar algún algoritmo para encontrar máximos en funciones de varias variables, por ejemplo el método de Newton o el de Nelder-Mead (default en <em>optim</em>). El caso de método de Newton, este usa información de las derivadas para encontrar las direcciones de más bajo decrecimiento.</p>
<p><span class="math display">\[
\theta^{t}=\theta^{t-1}-\left[h^{\prime \prime}\left(\theta^{t-1}\right)\right]^{-1} h^{\prime}\left(\theta^{t-1}\right)
\]</span></p>
<p>El método de Nelder-Mead usa el método simplex, junto con reflecciones, simetrías, contracciones, expansiones para encontrar el punto mínimo en una superficie. En el caso no convexo, podría caer en mínimos locales.</p>
<p>La función <em>laplace</em> tiene el método de optimización implementado tomando como argumentos la log-densidad posterior, un valor inicial de los parámetros y el conjunto de datos.</p>
<p>Por ejemplo, en el caso anterior podemos tomar <span class="math inline">\(\mathrm{logit}(\eta),l\log K = (-7,6)\)</span> como puntos iniciales para el algoritmo de Nelder-Mead. Estos se pueden inferir a través del gráfico de un gráfico de contorno. Por lo tanto podemos aproximar la densidad posterior conjunta de <span class="math inline">\((\text{logit}(\eta),\log K)\)</span> se puede aproximar como una normal multivariada con media <em>fit$mode</em> y varianza <em>fit.var</em>.</p>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb565-1"><a href="09-calculo-bayes.html#cb565-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">laplace</span>(betabinexch, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">7</span>, <span class="dv">6</span>), cancermortality)</span>
<span id="cb565-2"><a href="09-calculo-bayes.html#cb565-2" aria-hidden="true" tabindex="-1"></a>fit</span></code></pre></div>
<pre><code>## $mode
## [1] -6.819793  7.576111
## 
## $var
##             [,1]       [,2]
## [1,]  0.07896568 -0.1485087
## [2,] -0.14850874  1.3483208
## 
## $int
## [1] -570.7743
## 
## $converge
## [1] TRUE</code></pre>
<p>Un gráfico de contorno de la aproximación es:</p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="09-calculo-bayes.html#cb567-1" aria-hidden="true" tabindex="-1"></a>npar <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">m =</span> fit<span class="sc">$</span>mode, <span class="at">v =</span> fit<span class="sc">$</span>var)</span>
<span id="cb567-2"><a href="09-calculo-bayes.html#cb567-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(lbinorm, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">8</span>, <span class="sc">-</span><span class="fl">4.5</span>, <span class="dv">3</span>, <span class="fl">16.5</span>), npar, <span class="at">xlab =</span> <span class="st">&quot;logit eta&quot;</span>,</span>
<span id="cb567-3"><a href="09-calculo-bayes.html#cb567-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;log K&quot;</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-331-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>También podemos hacer inferencia de los parámetros:</p>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb568-1"><a href="09-calculo-bayes.html#cb568-1" aria-hidden="true" tabindex="-1"></a>se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(fit<span class="sc">$</span>var))</span>
<span id="cb568-2"><a href="09-calculo-bayes.html#cb568-2" aria-hidden="true" tabindex="-1"></a>lb <span class="ot">&lt;-</span> fit<span class="sc">$</span>mode <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> se</span>
<span id="cb568-3"><a href="09-calculo-bayes.html#cb568-3" aria-hidden="true" tabindex="-1"></a>ub <span class="ot">&lt;-</span> fit<span class="sc">$</span>mode <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> se</span>
<span id="cb568-4"><a href="09-calculo-bayes.html#cb568-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb568-5"><a href="09-calculo-bayes.html#cb568-5" aria-hidden="true" tabindex="-1"></a>etainv <span class="ot">&lt;-</span> <span class="fu">c</span>(lb[<span class="dv">1</span>], ub[<span class="dv">1</span>])</span>
<span id="cb568-6"><a href="09-calculo-bayes.html#cb568-6" aria-hidden="true" tabindex="-1"></a>Kinv <span class="ot">&lt;-</span> <span class="fu">c</span>(lb[<span class="dv">2</span>], ub[<span class="dv">2</span>])</span>
<span id="cb568-7"><a href="09-calculo-bayes.html#cb568-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb568-8"><a href="09-calculo-bayes.html#cb568-8" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(etainv)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(etainv))</span></code></pre></div>
<pre><code>## [1] 0.0006291199 0.0018904899</code></pre>
<div class="sourceCode" id="cb570"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb570-1"><a href="09-calculo-bayes.html#cb570-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(Kinv)</span></code></pre></div>
<pre><code>## [1]   200.3879 18995.6680</code></pre>
<p>son intervalos de predicción al 95% para <span class="math inline">\(\eta\)</span> y <span class="math inline">\(K\)</span> respectivamente.</p>
</div>
<div id="simulación" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> Simulación<a href="09-calculo-bayes.html#simulación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="simulación-monte-carlo" class="section level3 hasAnchor" number="9.5.1">
<h3><span class="header-section-number">9.5.1</span> Simulación Monte Carlo<a href="09-calculo-bayes.html#simulación-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suponga que <span class="math inline">\(g(\theta|y)\)</span> es la densidad posterior de <span class="math inline">\(\theta\)</span> y queremos estimar una característica de <span class="math inline">\(\theta\)</span>, a través de la función <span class="math inline">\(h(\theta)\)</span>. La media posterior de <span class="math inline">\(h(\theta)\)</span> es:
<span class="math display">\[E(h(\theta)|y)=\int h(\theta)g(\theta|y)d\theta\]</span>
y suponga que podemos simular una muestra independiente <span class="math inline">\(\theta^1,\ldots,\theta^m\)</span> de <span class="math inline">\(g(\theta|y)\)</span>. El estimador Monte Carlo del valor esperado es:
<span class="math display">\[\bar h =\frac 1 m\sum_{j=1}^mh(\theta^j) \]</span>
con su error estándar:
<span class="math display">\[se_{\bar h}=\sqrt{\frac{1}{m(m-1)}\sum_{j=1}^m\left(h(\theta^j)-\bar h\right)^2}\]</span>
En el caso en que no es posible obtener muestras de la densidad posterior, entonces se pueden definir algoritmos que aproximan la generación de muestras.</p>
<p>Por ejemplo, en el caso de los hospitales, supongamos que queremos saber que pasaría si la tasa de mortalidad se vuelve 2 veces más rápida. Entonces caso tenemos que</p>
<div class="sourceCode" id="cb572"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb572-1"><a href="09-calculo-bayes.html#cb572-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(lambda_post)</span></code></pre></div>
<pre><code>## [1] 0.0014598268 0.0011440068 0.0012703128 0.0012821699 0.0009823593
## [6] 0.0009834807</code></pre>
<div class="sourceCode" id="cb574"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb574-1"><a href="09-calculo-bayes.html#cb574-1" aria-hidden="true" tabindex="-1"></a>est <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="dv">2</span> <span class="sc">*</span> lambda_post)</span>
<span id="cb574-2"><a href="09-calculo-bayes.html#cb574-2" aria-hidden="true" tabindex="-1"></a>se <span class="ot">&lt;-</span> <span class="fu">sd</span>(<span class="dv">2</span> <span class="sc">*</span> lambda_post)<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">1000</span>)</span>
<span id="cb574-3"><a href="09-calculo-bayes.html#cb574-3" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(est, se)</span></code></pre></div>
<pre><code>## [1] 2.361136e-03 1.715134e-05</code></pre>
</div>
<div id="muestreo-por-rechazo" class="section level3 hasAnchor" number="9.5.2">
<h3><span class="header-section-number">9.5.2</span> Muestreo por rechazo<a href="09-calculo-bayes.html#muestreo-por-rechazo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suponga que queremos obtener una muestra de <span class="math inline">\(g(\theta|y)\)</span> donde la constante de normalización no es conocida. Suponga que conocemos una densidad <span class="math inline">\(p(\theta)\)</span> que satisface:</p>
<ul>
<li>Fácil de obtener muestras.</li>
<li><span class="math inline">\(p\)</span> aproxima <span class="math inline">\(g\)</span> en términos de localización y escala.</li>
<li>Para todo <span class="math inline">\(\theta\)</span>: <span class="math inline">\(g(\theta|y)\leq cp(\theta)\)</span>, para una constante <span class="math inline">\(c\)</span>.</li>
</ul>
<p>Algoritmo:</p>
<ol style="list-style-type: decimal">
<li>Simule una realización independiente de <span class="math inline">\(\theta \sim p\)</span> y <span class="math inline">\(U\sim Unif(0,1)\)</span>.</li>
<li>Si <span class="math inline">\(U\leq g(\theta|y)/(cp(\theta))\)</span> entonces acepte <span class="math inline">\(\theta\)</span>, caso contrario rechace la muestra propuesta.</li>
<li>Continue 1 y 2 hasta que se haya generado un número deseado de muestras.</li>
</ol>
<p>Para este algoritmo se necesita definir y estimar:
- La distribución propuesta <span class="math inline">\(p\)</span>.
- La constante <span class="math inline">\(c\)</span>.</p>
<p>Note que en el paso 2, la probabilidad de aceptar candidatos es dado por <span class="math inline">\(g\frac{\theta\mid y}{cp(\theta)}\)</span>. Se puede revisar este valor y ver la efectividad de la distribución propuesta. Si es bien escogida, estos valores deberían ser altos.</p>
<p>Apliquemos este método en el ejemplo de la mortalidad por cancer de los adultos en Missouri.</p>
<p>Primero, debemos encontrar una distribución que al multiplicarla por <span class="math inline">\(c\)</span>, cubra efectivamente toda la distribución <span class="math inline">\(g(\theta\mid y)\)</span>. Una opción sería la Gaussiana bivariada. El problema es que las colas de la normal son ligeras, por lo que <span class="math inline">\(g\frac{\theta\mid y}{cp(\theta)}\)</span> podría ser no acotado.</p>
<p>Una opción mejor para <span class="math inline">\(p(\theta)\)</span> es una distribución <span class="math inline">\(t\)</span> multivariada de modo que la media y escala sean compatibles con las posterior.</p>
<p>Suponga que usamos el parámetro de locación igual a la media aproximada del método de Laplace, matriz de escala igual a 2 veces la matriz de varianza aproximada según Laplace y 4 grados de libertad. De esta forma nos aseguramos que <span class="math inline">\(g(\theta|y)/p(\theta)\)</span> está acotado superiormente.</p>
<p>Con el fin de encontrar <span class="math inline">\(c\)</span>, dado que estamos en la log escala debemos encontrar una constante</p>
<p><span class="math display">\[\begin{equation*}
\log g(\theta\mid y) - \log p(\theta) \leq d
\end{equation*}\]</span></p>
<p>Esto se logra maximimizando <span class="math inline">\(\log g(\theta\mid y) - \log p(\theta)\)</span>.</p>
<p>Podemos usar la función <strong>laplace</strong> para lograr esto.</p>
<div class="sourceCode" id="cb576"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb576-1"><a href="09-calculo-bayes.html#cb576-1" aria-hidden="true" tabindex="-1"></a>betabinT <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, datapar) {</span>
<span id="cb576-2"><a href="09-calculo-bayes.html#cb576-2" aria-hidden="true" tabindex="-1"></a>    data <span class="ot">&lt;-</span> datapar<span class="sc">$</span>data</span>
<span id="cb576-3"><a href="09-calculo-bayes.html#cb576-3" aria-hidden="true" tabindex="-1"></a>    tpar <span class="ot">&lt;-</span> datapar<span class="sc">$</span>par</span>
<span id="cb576-4"><a href="09-calculo-bayes.html#cb576-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb576-5"><a href="09-calculo-bayes.html#cb576-5" aria-hidden="true" tabindex="-1"></a>    d <span class="ot">&lt;-</span> <span class="fu">betabinexch</span>(theta, data) <span class="sc">-</span> <span class="fu">dmt</span>(theta, <span class="at">mean =</span> <span class="fu">c</span>(tpar<span class="sc">$</span>m),</span>
<span id="cb576-6"><a href="09-calculo-bayes.html#cb576-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">S =</span> tpar<span class="sc">$</span>var, <span class="at">df =</span> tpar<span class="sc">$</span>df, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb576-7"><a href="09-calculo-bayes.html#cb576-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(d)</span>
<span id="cb576-8"><a href="09-calculo-bayes.html#cb576-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>definimos parámetros:</p>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb577-1"><a href="09-calculo-bayes.html#cb577-1" aria-hidden="true" tabindex="-1"></a>tpar <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">m =</span> fit<span class="sc">$</span>mode, <span class="at">var =</span> <span class="dv">2</span> <span class="sc">*</span> fit<span class="sc">$</span>var, <span class="at">df =</span> <span class="dv">4</span>)</span>
<span id="cb577-2"><a href="09-calculo-bayes.html#cb577-2" aria-hidden="true" tabindex="-1"></a>datapar <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">data =</span> cancermortality, <span class="at">par =</span> tpar)</span></code></pre></div>
<p>y resolvemos:</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb578-1"><a href="09-calculo-bayes.html#cb578-1" aria-hidden="true" tabindex="-1"></a>start <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">6.9</span>, <span class="fl">12.4</span>)</span>
<span id="cb578-2"><a href="09-calculo-bayes.html#cb578-2" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">laplace</span>(betabinT, start, datapar)</span>
<span id="cb578-3"><a href="09-calculo-bayes.html#cb578-3" aria-hidden="true" tabindex="-1"></a>fit1<span class="sc">$</span>mode</span></code></pre></div>
<pre><code>## [1] -6.888963 12.421993</code></pre>
<p>y el valor máximo de las diferencias de logaritmos es:</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb580-1"><a href="09-calculo-bayes.html#cb580-1" aria-hidden="true" tabindex="-1"></a>dmax <span class="ot">&lt;-</span> <span class="fu">betabinT</span>(fit1<span class="sc">$</span>mode, datapar)</span>
<span id="cb580-2"><a href="09-calculo-bayes.html#cb580-2" aria-hidden="true" tabindex="-1"></a>dmax</span></code></pre></div>
<pre><code>## [1] -569.2829</code></pre>
<p>el algoritmo sería:</p>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb582-1"><a href="09-calculo-bayes.html#cb582-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb582-2"><a href="09-calculo-bayes.html#cb582-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb582-3"><a href="09-calculo-bayes.html#cb582-3" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">rmt</span>(n, <span class="at">mean =</span> <span class="fu">c</span>(tpar<span class="sc">$</span>m), <span class="at">S =</span> tpar<span class="sc">$</span>var, <span class="at">df =</span> tpar<span class="sc">$</span>df)</span>
<span id="cb582-4"><a href="09-calculo-bayes.html#cb582-4" aria-hidden="true" tabindex="-1"></a>lf <span class="ot">&lt;-</span> <span class="fu">map_dbl</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>, <span class="sc">~</span><span class="fu">betabinexch</span>(theta[., ], cancermortality))</span>
<span id="cb582-5"><a href="09-calculo-bayes.html#cb582-5" aria-hidden="true" tabindex="-1"></a>lg <span class="ot">&lt;-</span> <span class="fu">dmt</span>(theta, <span class="at">mean =</span> <span class="fu">c</span>(tpar<span class="sc">$</span>m), <span class="at">S =</span> tpar<span class="sc">$</span>var, <span class="at">df =</span> tpar<span class="sc">$</span>df,</span>
<span id="cb582-6"><a href="09-calculo-bayes.html#cb582-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb582-7"><a href="09-calculo-bayes.html#cb582-7" aria-hidden="true" tabindex="-1"></a>prob <span class="ot">&lt;-</span> <span class="fu">exp</span>(lf <span class="sc">-</span> lg <span class="sc">-</span> dmax)</span>
<span id="cb582-8"><a href="09-calculo-bayes.html#cb582-8" aria-hidden="true" tabindex="-1"></a>thetaRS <span class="ot">&lt;-</span> theta[<span class="fu">runif</span>(n) <span class="sc">&lt;</span> prob, ]</span></code></pre></div>
<p>la tasa de aceptación es:</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="09-calculo-bayes.html#cb583-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(thetaRS)[<span class="dv">1</span>]<span class="sc">/</span><span class="dv">10000</span></span></code></pre></div>
<pre><code>## [1] 0.2447</code></pre>
<p>y dibujamos el gráfico de contorno con la muestra obtenida:</p>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb585-1"><a href="09-calculo-bayes.html#cb585-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(betabinexch, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">8</span>, <span class="sc">-</span><span class="fl">4.5</span>, <span class="dv">3</span>, <span class="fl">16.5</span>), cancermortality,</span>
<span id="cb585-2"><a href="09-calculo-bayes.html#cb585-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;logit eta&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;log K&quot;</span>)</span>
<span id="cb585-3"><a href="09-calculo-bayes.html#cb585-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(thetaRS[, <span class="dv">1</span>], thetaRS[, <span class="dv">2</span>])</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-340-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>El mismo proceso se podría hacer con el siguiente código</p>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb586-1"><a href="09-calculo-bayes.html#cb586-1" aria-hidden="true" tabindex="-1"></a>thetaRS2 <span class="ot">&lt;-</span> <span class="fu">rejectsampling</span>(betabinexch, tpar, <span class="sc">-</span><span class="fl">569.2813</span>,</span>
<span id="cb586-2"><a href="09-calculo-bayes.html#cb586-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">10000</span>, cancermortality)</span>
<span id="cb586-3"><a href="09-calculo-bayes.html#cb586-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb586-4"><a href="09-calculo-bayes.html#cb586-4" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(thetaRS2)</span></code></pre></div>
<pre><code>## [1] 2408    2</code></pre>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb588-1"><a href="09-calculo-bayes.html#cb588-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(betabinexch, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">8</span>, <span class="sc">-</span><span class="fl">4.5</span>, <span class="dv">3</span>, <span class="fl">16.5</span>), cancermortality,</span>
<span id="cb588-2"><a href="09-calculo-bayes.html#cb588-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;logit eta&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;log K&quot;</span>)</span>
<span id="cb588-3"><a href="09-calculo-bayes.html#cb588-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(thetaRS2[, <span class="dv">1</span>], thetaRS2[, <span class="dv">2</span>])</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-342-1.svg" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="muestreo-por-importancia" class="section level2 hasAnchor" number="9.6">
<h2><span class="header-section-number">9.6</span> Muestreo por importancia<a href="09-calculo-bayes.html#muestreo-por-importancia" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suponga que queremos calcular el siguiente valor esperado posterior:
<span class="math display">\[E(h(\theta)|y)=\frac{\int h(\theta)g(\theta)f(y|\theta)d\theta}{\int g(\theta)f(y|\theta)d\theta}\]</span></p>
<p>en el caso en donde no se puede obtener una muestra directa de la distribución posterior y usar Monte Carlo por ejemplo. Usemos la densidad propuesta <span class="math inline">\(p(\theta)\)</span> que aproxima la posterior:</p>
<p><span class="math display">\[\begin{align*}
E(h(\theta)|y)&amp;=\frac{\int h(\theta)\frac{g(\theta)f(y|\theta)}{p(\theta)}p(\theta)d\theta}{\int \frac{g(\theta)f(y|\theta)}{p(\theta)}p(\theta)d\theta}\\
&amp;=\frac{\int h(\theta)w(\theta)p(\theta)d\theta}{\int w(\theta)p(\theta)d\theta}
\end{align*}\]</span></p>
<p>donde <span class="math inline">\(w(\theta)=\frac{g(\theta)f(y|\theta)}{p(\theta)}\)</span>. Si <span class="math inline">\(\theta^1,\ldots,\theta^{m}\sim p(\theta)\)</span> entonces el estimador de muestreo por importancia de la media posterior es:
<span class="math display">\[\bar h_{IS}=\frac{\sum_{j=1}^mh(\theta^j)w(\theta^j)}{\sum_{j=1}^mw(\theta^j)}\]</span>
con error estándar:
<span class="math display">\[se_{\bar h_{IS}}=\frac{\sqrt{\sum_{j=1}^m((h(\theta^j)-\bar h_{IS})w(\theta^j))^2}}{\sum_{j=1}^mw(\theta^j)}\]</span>
Nota: al igual que en el método anterior, la escogencia de <span class="math inline">\(p(\theta)\)</span> se basa en su facilidad de muestreo y en la acotación por arriba de los pesos <span class="math inline">\(w(\theta)\)</span>.</p>
<p>Ahora implementamos el algoritmo en el ejemplo (buena parte es una repetición del anterior), usando como propuesta la misma distribución t multivariada. Además graficamos un histograma de los pesos para comprobar que están acotados (en este caso por 1).</p>
<div class="sourceCode" id="cb589"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb589-1"><a href="09-calculo-bayes.html#cb589-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb589-2"><a href="09-calculo-bayes.html#cb589-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb589-3"><a href="09-calculo-bayes.html#cb589-3" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">rmt</span>(n, <span class="at">mean =</span> <span class="fu">c</span>(tpar<span class="sc">$</span>m), <span class="at">S =</span> tpar<span class="sc">$</span>var, <span class="at">df =</span> tpar<span class="sc">$</span>df)</span>
<span id="cb589-4"><a href="09-calculo-bayes.html#cb589-4" aria-hidden="true" tabindex="-1"></a>lf <span class="ot">&lt;-</span> <span class="fu">map_dbl</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>, <span class="sc">~</span><span class="fu">betabinexch</span>(theta[., ], cancermortality))</span>
<span id="cb589-5"><a href="09-calculo-bayes.html#cb589-5" aria-hidden="true" tabindex="-1"></a>lp <span class="ot">&lt;-</span> <span class="fu">dmt</span>(theta, <span class="at">mean =</span> <span class="fu">c</span>(tpar<span class="sc">$</span>m), <span class="at">S =</span> tpar<span class="sc">$</span>var, <span class="at">df =</span> tpar<span class="sc">$</span>df,</span>
<span id="cb589-6"><a href="09-calculo-bayes.html#cb589-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb589-7"><a href="09-calculo-bayes.html#cb589-7" aria-hidden="true" tabindex="-1"></a>md <span class="ot">&lt;-</span> <span class="fu">max</span>(lf <span class="sc">-</span> lp)</span>
<span id="cb589-8"><a href="09-calculo-bayes.html#cb589-8" aria-hidden="true" tabindex="-1"></a>wt <span class="ot">&lt;-</span> <span class="fu">exp</span>(lf <span class="sc">-</span> lp <span class="sc">-</span> md)</span>
<span id="cb589-9"><a href="09-calculo-bayes.html#cb589-9" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(wt)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-343-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>y calculamos el valor esperado de <span class="math inline">\(\log K\)</span> usando los pesos obtenidos del paso anterior:</p>
<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb590-1"><a href="09-calculo-bayes.html#cb590-1" aria-hidden="true" tabindex="-1"></a>est <span class="ot">&lt;-</span> <span class="fu">sum</span>(wt <span class="sc">*</span> theta[, <span class="dv">2</span>])<span class="sc">/</span><span class="fu">sum</span>(wt)</span>
<span id="cb590-2"><a href="09-calculo-bayes.html#cb590-2" aria-hidden="true" tabindex="-1"></a>SE_est <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((theta[, <span class="dv">2</span>] <span class="sc">-</span> est)<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> wt<span class="sc">^</span><span class="dv">2</span>))<span class="sc">/</span><span class="fu">sum</span>(wt)</span>
<span id="cb590-3"><a href="09-calculo-bayes.html#cb590-3" aria-hidden="true" tabindex="-1"></a><span class="fu">show</span>(<span class="fu">c</span>(est, SE_est))</span></code></pre></div>
<pre><code>## [1] 7.92445868 0.01905786</code></pre>
<p>La función para LearnBayes sería,</p>
<div class="sourceCode" id="cb592"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb592-1"><a href="09-calculo-bayes.html#cb592-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb592-2"><a href="09-calculo-bayes.html#cb592-2" aria-hidden="true" tabindex="-1"></a>tpar <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">m =</span> fit<span class="sc">$</span>mode, <span class="at">var =</span> <span class="dv">2</span> <span class="sc">*</span> fit<span class="sc">$</span>var, <span class="at">df =</span> <span class="dv">4</span>)</span>
<span id="cb592-3"><a href="09-calculo-bayes.html#cb592-3" aria-hidden="true" tabindex="-1"></a>myfunc <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {</span>
<span id="cb592-4"><a href="09-calculo-bayes.html#cb592-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(theta[<span class="dv">2</span>])</span>
<span id="cb592-5"><a href="09-calculo-bayes.html#cb592-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb592-6"><a href="09-calculo-bayes.html#cb592-6" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fu">impsampling</span>(betabinexch, tpar, myfunc, <span class="dv">10000</span>,</span>
<span id="cb592-7"><a href="09-calculo-bayes.html#cb592-7" aria-hidden="true" tabindex="-1"></a>    cancermortality)</span>
<span id="cb592-8"><a href="09-calculo-bayes.html#cb592-8" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(s<span class="sc">$</span>est, s<span class="sc">$</span>se)</span></code></pre></div>
<pre><code>##          [,1]       [,2]
## [1,] 7.924459 0.01905786</code></pre>
</div>
<div id="remuestreo-por-importancia" class="section level2 hasAnchor" number="9.7">
<h2><span class="header-section-number">9.7</span> Remuestreo por importancia<a href="09-calculo-bayes.html#remuestreo-por-importancia" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Al igual que en el caso anterior simulamos <span class="math inline">\(\theta^1,\ldots,\theta^m\sim p(\theta)\)</span> y calculamos los pesos <span class="math inline">\(\{w(\theta^j)=g(\theta^j|y)/p(\theta^j)\}\)</span>. Los pesos se convierten a probabilidades según:
<span class="math display">\[p^j=\frac{w(\theta^j)}{\sum_{k=1}^mw(\theta^k)}\]</span>
Tomamos una nueva muestra <span class="math inline">\(\theta^{*1},\ldots,\theta^{*m}\sim \{p^k\}\)</span> es decir se obtiene una nueva muestra con reemplazo a partir de la muestra original <span class="math inline">\(\theta^1,\ldots,\theta^m\)</span> con pesos <span class="math inline">\(\{p^k\}\)</span> (muestra bootstrap ponderada). A este método se le llama remuestreo por importancia.</p>
<p>Siguiendo con el ejemplo:</p>
<div class="sourceCode" id="cb594"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb594-1"><a href="09-calculo-bayes.html#cb594-1" aria-hidden="true" tabindex="-1"></a>probs <span class="ot">&lt;-</span> wt<span class="sc">/</span><span class="fu">sum</span>(wt)</span>
<span id="cb594-2"><a href="09-calculo-bayes.html#cb594-2" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="at">size =</span> n, <span class="at">prob =</span> probs, <span class="at">replace =</span> T)</span>
<span id="cb594-3"><a href="09-calculo-bayes.html#cb594-3" aria-hidden="true" tabindex="-1"></a>theta_SIR <span class="ot">&lt;-</span> theta[indices, ]</span></code></pre></div>
<p>y los intervalos de predicción al 95% para <span class="math inline">\(\text{logit}(\eta)\)</span> y <span class="math inline">\(log K\)</span> son:</p>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb595-1"><a href="09-calculo-bayes.html#cb595-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(theta_SIR[, <span class="dv">1</span>], <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##      2.5%     97.5% 
## -7.353821 -6.179805</code></pre>
<div class="sourceCode" id="cb597"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb597-1"><a href="09-calculo-bayes.html#cb597-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(theta_SIR[, <span class="dv">2</span>], <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##      2.5%     97.5% 
##  5.618474 11.198193</code></pre>
<p>Hay otra función que hace exactamente este procedimiento,</p>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb599-1"><a href="09-calculo-bayes.html#cb599-1" aria-hidden="true" tabindex="-1"></a>theta_SIR2 <span class="ot">=</span> <span class="fu">sir</span>(betabinexch, tpar, <span class="dv">10000</span>, cancermortality)</span></code></pre></div>
<div class="sourceCode" id="cb600"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb600-1"><a href="09-calculo-bayes.html#cb600-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(theta_SIR2[, <span class="dv">1</span>], <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##      2.5%     97.5% 
## -7.355285 -6.147236</code></pre>
<div class="sourceCode" id="cb602"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb602-1"><a href="09-calculo-bayes.html#cb602-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(theta_SIR2[, <span class="dv">2</span>], <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##      2.5%     97.5% 
##  5.638189 11.165893</code></pre>
</div>
<div id="métodos-monte-carlo" class="section level2 hasAnchor" number="9.8">
<h2><span class="header-section-number">9.8</span> Métodos Monte Carlo<a href="09-calculo-bayes.html#métodos-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El tratamiento clásico de la estimación de parámetros bayesiana nos dice que si tenemos una densidad previa y la ``combinamos’’ con la verosimilitud de los datos, estos nos dará una densidad con más información. Se podría repetir el proceso varias veces para tratar de ajustar mejor la densidad posterior.</p>
<p>Sin embargo, se podría usar potencia de los métodos Monte Carlo para que esta búsqueda sea muy efectiva para encontrar los parámetros adecuados.</p>
<div id="ejemplo-del-viajero-con-una-moneda" class="section level3 hasAnchor" number="9.8.1">
<h3><span class="header-section-number">9.8.1</span> Ejemplo del viajero con una moneda<a href="09-calculo-bayes.html#ejemplo-del-viajero-con-una-moneda" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suponga que tenemos un viajero que quiere estar en 7 lugares distintos (suponga que están en línea recta) y la probabilidad de pasar a un lugar a otro se decide tirando una moneda no sesgada (50% a la derecha y 50% a la izquierda).</p>
<p>Este caso sería una simple caminata aleatoria sin ningún interés en particular.</p>
<p>Suponga además, que el viajero quiere estar más tiempo donde haya una mayor cantidad de personas <span class="math inline">\(P\)</span> pero siguiendo ese patrón aleatorio. Entonces la forma de describir su decisión de moverse sería:</p>
<ul>
<li>Tira la moneda y decide si va a la izquierda o la derecha.
<ol style="list-style-type: decimal">
<li><p>Si el lugar nuevo tiene personas que el actual salta a ese lugar.</p></li>
<li><p>Si el lugar nuevo tiene personas entonces el viajero tiene que decidir si se queda o se mueve. | calcula la probabilidad de moverse como <span class="math inline">\(p_{moverse} = P_{nuevo}/P_{actual}\)</span>.</p>
<p><strong>Tira un número aleatorio entre 0 y 1</strong></p>
<ol style="list-style-type: decimal">
<li>Si <span class="math inline">\(p_{moverse}&gt;r\)</span> entonces se mueve.</li>
<li>Sino, se queda donde está.</li>
</ol></li>
</ol></li>
</ul>
<div class="sourceCode" id="cb604"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb604-1"><a href="09-calculo-bayes.html#cb604-1" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span></span>
<span id="cb604-2"><a href="09-calculo-bayes.html#cb604-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb604-3"><a href="09-calculo-bayes.html#cb604-3" aria-hidden="true" tabindex="-1"></a>pos_actual <span class="ot">&lt;-</span> <span class="fu">sample</span>(P, <span class="dv">1</span>)</span>
<span id="cb604-4"><a href="09-calculo-bayes.html#cb604-4" aria-hidden="true" tabindex="-1"></a>pos_nueva <span class="ot">&lt;-</span> pos_actual</span>
<span id="cb604-5"><a href="09-calculo-bayes.html#cb604-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb604-6"><a href="09-calculo-bayes.html#cb604-6" aria-hidden="true" tabindex="-1"></a>n_pasos <span class="ot">&lt;-</span> <span class="dv">50000</span></span>
<span id="cb604-7"><a href="09-calculo-bayes.html#cb604-7" aria-hidden="true" tabindex="-1"></a>trayectoria <span class="ot">&lt;-</span> <span class="fu">numeric</span>(n_pasos)</span>
<span id="cb604-8"><a href="09-calculo-bayes.html#cb604-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb604-9"><a href="09-calculo-bayes.html#cb604-9" aria-hidden="true" tabindex="-1"></a>trayectoria[<span class="dv">1</span>] <span class="ot">&lt;-</span> pos_actual</span>
<span id="cb604-10"><a href="09-calculo-bayes.html#cb604-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb604-11"><a href="09-calculo-bayes.html#cb604-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n_pasos) {</span>
<span id="cb604-12"><a href="09-calculo-bayes.html#cb604-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Tira la moneda para decidir</span></span>
<span id="cb604-13"><a href="09-calculo-bayes.html#cb604-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb604-14"><a href="09-calculo-bayes.html#cb604-14" aria-hidden="true" tabindex="-1"></a>    moneda <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.5</span>)</span>
<span id="cb604-15"><a href="09-calculo-bayes.html#cb604-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># moneda es 0 o 1</span></span>
<span id="cb604-16"><a href="09-calculo-bayes.html#cb604-16" aria-hidden="true" tabindex="-1"></a>    pos_nueva <span class="ot">&lt;-</span> pos_actual</span>
<span id="cb604-17"><a href="09-calculo-bayes.html#cb604-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (moneda <span class="sc">==</span> <span class="dv">1</span> <span class="sc">&amp;&amp;</span> (pos_actual <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">&lt;=</span> <span class="dv">7</span>) {</span>
<span id="cb604-18"><a href="09-calculo-bayes.html#cb604-18" aria-hidden="true" tabindex="-1"></a>        pos_nueva <span class="ot">&lt;-</span> pos_actual <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb604-19"><a href="09-calculo-bayes.html#cb604-19" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> <span class="cf">if</span> (moneda <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;&amp;</span> (pos_actual <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">&gt;=</span> <span class="dv">1</span>) {</span>
<span id="cb604-20"><a href="09-calculo-bayes.html#cb604-20" aria-hidden="true" tabindex="-1"></a>        pos_nueva <span class="ot">&lt;-</span> pos_actual <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb604-21"><a href="09-calculo-bayes.html#cb604-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb604-22"><a href="09-calculo-bayes.html#cb604-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb604-23"><a href="09-calculo-bayes.html#cb604-23" aria-hidden="true" tabindex="-1"></a>    p_moverse <span class="ot">&lt;-</span> <span class="fu">min</span>(pos_nueva<span class="sc">/</span>pos_actual, <span class="dv">1</span>)</span>
<span id="cb604-24"><a href="09-calculo-bayes.html#cb604-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb604-25"><a href="09-calculo-bayes.html#cb604-25" aria-hidden="true" tabindex="-1"></a>    hay_movimiento <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> p_moverse <span class="sc">&lt;=</span> <span class="fu">runif</span>(<span class="dv">1</span>)</span>
<span id="cb604-26"><a href="09-calculo-bayes.html#cb604-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb604-27"><a href="09-calculo-bayes.html#cb604-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (hay_movimiento) {</span>
<span id="cb604-28"><a href="09-calculo-bayes.html#cb604-28" aria-hidden="true" tabindex="-1"></a>        pos_actual <span class="ot">&lt;-</span> pos_nueva</span>
<span id="cb604-29"><a href="09-calculo-bayes.html#cb604-29" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb604-30"><a href="09-calculo-bayes.html#cb604-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb604-31"><a href="09-calculo-bayes.html#cb604-31" aria-hidden="true" tabindex="-1"></a>    trayectoria[k] <span class="ot">&lt;-</span> pos_nueva</span>
<span id="cb604-32"><a href="09-calculo-bayes.html#cb604-32" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb605"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb605-1"><a href="09-calculo-bayes.html#cb605-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>n_pasos, <span class="at">P =</span> trayectoria)</span>
<span id="cb605-2"><a href="09-calculo-bayes.html#cb605-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb605-3"><a href="09-calculo-bayes.html#cb605-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df[<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>, ]) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(x, P)) <span class="sc">+</span> <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb605-4"><a href="09-calculo-bayes.html#cb605-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">16</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-351-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb606"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb606-1"><a href="09-calculo-bayes.html#cb606-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(P), <span class="at">stat =</span> <span class="st">&quot;count&quot;</span>) <span class="sc">+</span></span>
<span id="cb606-2"><a href="09-calculo-bayes.html#cb606-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">16</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-351-2.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb607"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb607-1"><a href="09-calculo-bayes.html#cb607-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(trayectoria)</span></code></pre></div>
<pre><code>## [1] 4.90532</code></pre>
<div class="sourceCode" id="cb609"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb609-1"><a href="09-calculo-bayes.html#cb609-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(trayectoria)</span></code></pre></div>
<pre><code>## [1] 1.774739</code></pre>
</div>
<div id="cadenas-de-markov" class="section level3 hasAnchor" number="9.8.2">
<h3><span class="header-section-number">9.8.2</span> Cadenas de Markov<a href="09-calculo-bayes.html#cadenas-de-markov" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recuerde que estamos buscando el “camino” que el viajero tomará para pasar la mayor parte del tiempo de en los lugares más poblados (con mayor <span class="math inline">\(\theta\)</span>).</p>
<p><span class="math display">\[\begin{equation*}
\theta_{1} \curvearrowright \theta_{2} \curvearrowright \ldots \curvearrowright \theta_{50000}.
\end{equation*}\]</span></p>
<p>Denotamos <span class="math inline">\(\theta_{1}\to\theta_{2}\)</span> si el viajero pasó de <span class="math inline">\(\theta_{1}\)</span> hacia <span class="math inline">\(\theta_{2}\)</span>.</p>
<p>Entonces</p>
<ul>
<li><span class="math inline">\(\mathbb{P}\left(\theta \rightarrow \theta+1\right)=0.5 \min \left(\frac{P(\theta+1)}{P(\theta)} , 1\right)\)</span></li>
<li><span class="math inline">\(\mathbb{P}\left(\theta + 1 \rightarrow \theta\right)=0.5 \min \left(\frac{P(\theta)}{P(\theta+1)} , 1\right)\)</span></li>
</ul>
<p>Entonces la razón entre estas dos probabilidades es</p>
<p><span class="math display">\[\begin{align*}
\frac{\mathbb{P}\left(\theta \rightarrow \theta+1\right)}{\mathbb{P}\left(\theta +1 \rightarrow \theta\right)}
   &amp; =\frac{0.5 \min (P(\theta+1) / P(\theta), 1)}{0.5 \min (P(\theta) / P(\theta+1), 1)} \\
   &amp; =\left\{\begin{array}{ll}
  \frac{P(\theta+1)}{P(\theta) }
    &amp; \text { si } P(\theta+1)&gt;P(\theta) \\
  \frac{P(\theta+1) }{P(\theta)}
    &amp; \text { si } P(\theta+1)&lt;P(\theta)
\end{array}\right.                                             \\
\, &amp; =\frac{P(\theta+1)}{P(\theta)}.
\end{align*}\]</span></p>
<p>Es decir que la razón de las probabilidades es equivalente a la razón entre las proporción de las poblaciones. Por lo tanto la mayoría de las veces se estará en los lugares con mayor población.</p>
<p>Esta cadena se puede escribir usando una matriz de transición de la forma</p>
<p><span class="math display">\[\begin{equation*}
T= \left(\begin{array}{ccccc}
\ddots &amp; \mathbb{P}(\theta-2 \rightarrow \theta-1) &amp; 0 &amp; 0 &amp; 0 \\
\ddots &amp; \mathbb{P}(\theta-1 \rightarrow \theta-1) &amp; \mathbb{P}(\theta-1 \rightarrow \theta) &amp; 0 &amp; 0 \\
0 &amp; \mathbb{P}(\theta \rightarrow \theta-1) &amp; \mathbb{P}(\theta \rightarrow \theta) &amp; \mathbb{P}(\theta \rightarrow \theta+1) &amp; 0 \\
0 &amp; 0 &amp; \mathbb{P}(\theta+1 \rightarrow \theta) &amp; \mathbb{P}(\theta+1 \rightarrow \theta+1) &amp; \ddots \\
0 &amp; 0 &amp; 0 &amp; \mathbb{P}(\theta+2 \rightarrow \theta+1) &amp; \ddots
\end{array}\right)
\end{equation*}\]</span></p>
<p>La matriz <span class="math inline">\(T\)</span> tiene las propiedades</p>
<ol style="list-style-type: decimal">
<li>Existencia de una única distribución estacionaria (llamada <span class="math inline">\(f\)</span> más adelante).</li>
<li>Es ergódica, i.e., es aperíodica y positiva recurrente. Recuerde que una cadena de markov es érgodica si siempre se puede pasar de un estado a otro (no necesariamente en 1 paso). Otra forma de verlo es que la para alguna potencia de <span class="math inline">\(T\)</span> todos los sus elementos serán positivos estrictos.</li>
</ol>
</div>
<div id="el-algoritmo-de-metropolis-hasting" class="section level3 hasAnchor" number="9.8.3">
<h3><span class="header-section-number">9.8.3</span> El algoritmo de Metropolis-Hasting<a href="09-calculo-bayes.html#el-algoritmo-de-metropolis-hasting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El ejemplo anterior era bastante sencillo pero demuestra que se puede
encontrar el mejor estimador posible simplemente ejecutando una y otra
vez maximizando la estadía en los lugares más poblados.</p>
<p>En este ejemplo la función a maximizar es la cantidad de personas
<span class="math inline">\(P(\theta)=\theta\)</span>, pero en general nuestro objetivo será maximizar
la distribución posterior <span class="math inline">\(f(\theta| \text{ datos })\)</span>.</p>
<p>En palabras simples el algoritmo de Metropoli Hasting es</p>
<ol style="list-style-type: decimal">
<li>Simule un valor <span class="math inline">\(\theta^{*}\)</span> de una densidad de propuesta
<span class="math inline">\(p\left(\theta^{*} | \theta^{t-1}\right)\)</span></li>
<li>Estime la razón
<span class="math display">\[
R=\frac{f\left(\theta^{*}\right) L\left(\theta^{t-1} |
  \theta^{*}\right)}{f\left(\theta^{t-1}\right) L\left(\theta^{*} |
  \theta^{t-1}\right)}
\]</span></li>
<li>Estima la probabilidad de aceptación <span class="math inline">\(p_{\text {moverse }}=\min \{R, 1\}\)</span>.</li>
<li>Tome <span class="math inline">\(\theta^{t}\)</span> tal que <span class="math inline">\(\theta^{t}=\theta^{*}\)</span>
con probabilidad <span class="math inline">\(p_{\text {moverse }}\)</span>; en otro caso <span class="math inline">\(\theta^{t}=\)</span> <span class="math inline">\(\theta^{t-1}\)</span></li>
</ol>
<p>El algoritmo de Metropolis-Hastings se puede construir de muchas
formas, dependiendo de la densidad de proposición</p>
<p>Si esta es independiente de las elecciones anteriores entonces,
<span class="math display">\[
p\left(\theta^{*} | \theta^{t-1}\right)=p\left(\theta^{*}\right)
\]</span></p>
<p>Otras formas es escoger es usando
<span class="math display">\[
p\left(\theta^{*} |
\theta^{t-1}\right)=h\left(\theta^{*}-\theta^{t-1}\right)
\]</span>
donde <span class="math inline">\(h\)</span> es simétrica alrededor del origen. En este tipo de
cadenas, la razón <span class="math inline">\(R\)</span> tiene la forma
<span class="math display">\[
R=\frac{f\left(\theta^{*}\right)}{f\left(\theta^{t-1}\right)}
\]</span></p>
<p>Una última opción es simular solo el <em>salto</em> <span class="math inline">\(Z\)</span>
<span class="math display">\[
\theta^{*}=\theta^{t-1}+ Z
\]</span></p>
<p>donde <span class="math inline">\(Z\)</span> es una normal centrada con cierta estructura de varianza.</p>
</div>
<div id="por-qué-el-algoritmo-de-metropolis-hasting-funciona" class="section level3 hasAnchor" number="9.8.4">
<h3><span class="header-section-number">9.8.4</span> ¿Por qué el algoritmo de Metropolis Hasting funciona?<a href="09-calculo-bayes.html#por-qué-el-algoritmo-de-metropolis-hasting-funciona" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math display">\[\begin{equation}
\mathbb{P}\left(\theta^{\star} | \theta^{(t-1)}\right)=L\left(\theta^{\star} | \theta^{(t-1)}\right) \cdot \min \left\{1, \frac{f\left(\theta^{\star}\right) L\left(\theta^{(t-1)} | \theta^{\star}\right)}{f\left(\theta^{(t-1)}\right) L\left(\theta^{\star} | \theta^{(t-1)}\right)}\right\}
\end{equation}\]</span></p>
<p>Si se comienza en <span class="math inline">\(f\left(\theta^{(t-1)}\right)\)</span> entonces</p>
<p><span class="math display">\[\begin{align}
&amp;= f\left(\theta^{(t-1)}\right) \mathbb{P}\left(\theta^{\star} | \theta^{(t-1)}\right) \\
&amp;= f\left(\theta^{(t-1)}\right) L\left(\theta^{\star} | \theta^{(t-1)}\right) \min \left\{1, \frac{f\left(\theta^{\star}\right) L\left(\theta^{(t-1)} | \theta^{\star}\right)}{f\left(\theta^{(t-1)}\right) L\left(\theta^{\star} | \theta^{(t-1)}\right)}\right\} \\
&amp;=\min \left\{f\left(\theta^{(t-1)}\right) L\left(\theta^{\star} | \theta^{(t-1)}\right), f\left(\theta^{\star}\right) L\left(\theta^{(t-1)} | \theta^{\star}\right)\right\} \\
&amp;= f\left(\theta^{\star}\right) L\left(\theta^{(t-1)} | \theta^{\star}\right) \min \left\{\frac{f\left(\theta^{(t-1)}\right) L\left(\theta^{\star} | \theta^{(t-1)}\right)}{f\left(\theta^{\star}\right) L\left(\theta^{(t-1)} | \theta^{\star}\right)}, 1\right\} \\
&amp;=f\left(\theta^{\star}\right) \mathbb{P}\left(\theta^{(t-1)} | \theta^{\star}\right)
\end{align}\]</span></p>
<p>Asumiendo que existe una cantidad finita de estados <span class="math inline">\(\theta_{1}, \ldots, \theta_{M}\)</span>, entonces.</p>
<p><span class="math display">\[\begin{equation*}
f\left(\theta_{j}\right) = \underbrace{\sum_{i=1}^{M} f\left(\theta_{i}\right) \mathbb{P} \left(\theta_{j} | \theta_{i}\right)}_{\text {Probabilidad total  }}=\sum_{i=1}^{M} f\left(\theta_{j}\right) \mathbb{P} \left(\theta_{i} | \theta_{j}\right)
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation}
f(\boldsymbol{\theta})^\top T =   f(\boldsymbol{\theta})
\end{equation}\]</span></p>
<p>Cual indica que no importa donde empecemos siempre llegaremos a la densidad estacionaria <span class="math inline">\(f\)</span>.</p>
<!-- [https://www.ece.iastate.edu/~namrata/EE527_Spring08/l4c.pdf#page=32](https://www.ece.iastate.edu/~namrata/EE527_Spring08/l4c.pdf#page=32) -->
</div>
<div id="extensión-al-caso-del-viajero" class="section level3 hasAnchor" number="9.8.5">
<h3><span class="header-section-number">9.8.5</span> Extensión al caso del viajero<a href="09-calculo-bayes.html#extensión-al-caso-del-viajero" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Retomemos el ejemplo del viajero. Supongamos que ahora existen una
cantidad infinita de lugares a los que puede ir y que la población de
cada isla es proporcional a la densidad posterior. Además, el viajero
podría saltar a cualquier isla que quisiera y su probabilidad de
salto cae de forma continua en el intervalo <span class="math inline">\([0,1]\)</span>.</p>
<p>Para hacer este ejemplo concreto, el viajero no conoce cuál es su
probabilidad de salto <span class="math inline">\(\theta\)</span> pero sabe que ha tirado la
moneda <span class="math inline">\(N\)</span> veces y observado <span class="math inline">\(z\)</span> exitos. Por lo tanto tendremos
una verosimilitud de <span class="math inline">\(L(z, N | \theta)=\theta^{z}(1-\theta)^{(N-z)}\)</span>.</p>
<p>La previa será dada por <span class="math inline">\(f(\theta)=\operatorname{beta}(\theta | a, b)\)</span>.</p>
<p>Los saltos serán gobernados por una normal centrada con media
<span class="math inline">\(\sigma\)</span> de modo que <span class="math inline">\(\Delta \theta \sim \mathcal{N}\left(0,\sigma^{2}\right)\)</span>.</p>
<p>Entonces el algoritmo de Metropolis Hasting se puede reformular como</p>
<ol style="list-style-type: decimal">
<li><p>Simule un valor de salto<span class="math inline">\(\Delta \theta \sim \mathcal{N}\left(0,\sigma^{2}\right)\)</span> y denote <span class="math inline">\(\theta^{t} = \theta^{t} + \Delta\theta\)</span>.</p></li>
<li><p>Probabilidad de aceptación <span class="math inline">\(p_{\text {moverse }}\)</span>
<span class="math display">\[\begin{align*}
p_{\text {moverse }}
&amp; =\min \left(1, \frac{P\left(\theta_{\ast}\right)}{P\left(\theta_{t-1}\right)}\right) \\
   &amp; =\min \left(1, \frac{p\left(D |
  \theta_{\ast}\right) p\left(\theta_{\ast}\right)}{p\left(D | \theta_{t-1}\right)
  p\left(\theta_{t-1}\right)}\right) \\
&amp; =\min \left(1, \frac{\operatorname{Bernoulli}\left(z, N |
  \theta_{\ast}\right)
  \operatorname{beta}\left(\theta_{\ast} | a,
  b\right)}{\operatorname{Bernoulli}\left(z, N |
  \theta_{t-1}\right)
  \operatorname{beta}\left(\theta_{t-1} | a, b\right)}\right) \\
&amp; =\min \left(1,
\frac{\theta_{\ast}^{z}\left(1-\theta_{\ast}\right)^{(N-z)}
\theta_{\ast} \left(1-\theta_{\ast}\right)^{(b-1)}
/ B(a,b)}{\theta_{t-1}^{z}\left(1-\theta_{t-1}\right)^{(N-z)}
\theta_{t-1}^{(a-1)}\left(1-\theta_{t-1}\right)^{(b-1)}
/ B(a, b)}\right)
\end{align*}\]</span></p></li>
<li><p>Tome <span class="math inline">\(\theta_{t}\)</span> tal que <span class="math inline">\(\theta_{t}=\theta_{*}\)</span>
con probabilidad <span class="math inline">\(p_{\text {moverse }} ;\)</span> en otro caso <span class="math inline">\(\theta_{t}=\)</span> <span class="math inline">\(\theta_{t-1}\)</span></p></li>
</ol>
<p>En el ejemplo del viajero queremos ver la probabilidad <span class="math inline">\(\theta\)</span> de
que salte al siguiente destino. Tomemos <span class="math inline">\(\sigma=0.2\)</span> y supongamos
que se ha visto que el viajero de <span class="math inline">\(N=20\)</span> y <span class="math inline">\(z=14\)</span> éxitos. Por
cuestiones de practicidad se tomará <span class="math inline">\(\theta_0 = 0.1\)</span>.</p>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb611-1"><a href="09-calculo-bayes.html#cb611-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Carga de datos observados</span></span>
<span id="cb611-2"><a href="09-calculo-bayes.html#cb611-2" aria-hidden="true" tabindex="-1"></a>datos_observados <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">6</span>), <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">14</span>))</span>
<span id="cb611-3"><a href="09-calculo-bayes.html#cb611-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-4"><a href="09-calculo-bayes.html#cb611-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Función de verosimilitud Binomial</span></span>
<span id="cb611-5"><a href="09-calculo-bayes.html#cb611-5" aria-hidden="true" tabindex="-1"></a>verosimilitud <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, data) {</span>
<span id="cb611-6"><a href="09-calculo-bayes.html#cb611-6" aria-hidden="true" tabindex="-1"></a>    z <span class="ot">&lt;-</span> <span class="fu">sum</span>(data)</span>
<span id="cb611-7"><a href="09-calculo-bayes.html#cb611-7" aria-hidden="true" tabindex="-1"></a>    N <span class="ot">&lt;-</span> <span class="fu">length</span>(data)</span>
<span id="cb611-8"><a href="09-calculo-bayes.html#cb611-8" aria-hidden="true" tabindex="-1"></a>    pDatosDadoTheta <span class="ot">&lt;-</span> theta<span class="sc">^</span>z <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> theta)<span class="sc">^</span>(N <span class="sc">-</span> z)</span>
<span id="cb611-9"><a href="09-calculo-bayes.html#cb611-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Es para asegurarse que los datos caigan en</span></span>
<span id="cb611-10"><a href="09-calculo-bayes.html#cb611-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># [0,1].</span></span>
<span id="cb611-11"><a href="09-calculo-bayes.html#cb611-11" aria-hidden="true" tabindex="-1"></a>    pDatosDadoTheta[theta <span class="sc">&gt;</span> <span class="dv">1</span> <span class="sc">|</span> theta <span class="sc">&lt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb611-12"><a href="09-calculo-bayes.html#cb611-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(pDatosDadoTheta)</span>
<span id="cb611-13"><a href="09-calculo-bayes.html#cb611-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb611-14"><a href="09-calculo-bayes.html#cb611-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-15"><a href="09-calculo-bayes.html#cb611-15" aria-hidden="true" tabindex="-1"></a><span class="co"># densidad previa</span></span>
<span id="cb611-16"><a href="09-calculo-bayes.html#cb611-16" aria-hidden="true" tabindex="-1"></a>previa <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {</span>
<span id="cb611-17"><a href="09-calculo-bayes.html#cb611-17" aria-hidden="true" tabindex="-1"></a>    pTheta <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(theta, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb611-18"><a href="09-calculo-bayes.html#cb611-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Es para asegurarse que los datos caigan en</span></span>
<span id="cb611-19"><a href="09-calculo-bayes.html#cb611-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># [0,1].</span></span>
<span id="cb611-20"><a href="09-calculo-bayes.html#cb611-20" aria-hidden="true" tabindex="-1"></a>    pTheta[theta <span class="sc">&gt;</span> <span class="dv">1</span> <span class="sc">|</span> theta <span class="sc">&lt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb611-21"><a href="09-calculo-bayes.html#cb611-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(pTheta)</span>
<span id="cb611-22"><a href="09-calculo-bayes.html#cb611-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb611-23"><a href="09-calculo-bayes.html#cb611-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-24"><a href="09-calculo-bayes.html#cb611-24" aria-hidden="true" tabindex="-1"></a><span class="co"># densidad posterior</span></span>
<span id="cb611-25"><a href="09-calculo-bayes.html#cb611-25" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, data) {</span>
<span id="cb611-26"><a href="09-calculo-bayes.html#cb611-26" aria-hidden="true" tabindex="-1"></a>    posterior <span class="ot">&lt;-</span> <span class="fu">verosimilitud</span>(theta, data) <span class="sc">*</span> <span class="fu">previa</span>(theta)</span>
<span id="cb611-27"><a href="09-calculo-bayes.html#cb611-27" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(posterior)</span>
<span id="cb611-28"><a href="09-calculo-bayes.html#cb611-28" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb611-29"><a href="09-calculo-bayes.html#cb611-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-30"><a href="09-calculo-bayes.html#cb611-30" aria-hidden="true" tabindex="-1"></a>n_pasos <span class="ot">&lt;-</span> <span class="dv">50000</span></span>
<span id="cb611-31"><a href="09-calculo-bayes.html#cb611-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-32"><a href="09-calculo-bayes.html#cb611-32" aria-hidden="true" tabindex="-1"></a>trayectoria <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, n_pasos)</span>
<span id="cb611-33"><a href="09-calculo-bayes.html#cb611-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-34"><a href="09-calculo-bayes.html#cb611-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Valor inicial</span></span>
<span id="cb611-35"><a href="09-calculo-bayes.html#cb611-35" aria-hidden="true" tabindex="-1"></a>trayectoria[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fl">0.01</span></span>
<span id="cb611-36"><a href="09-calculo-bayes.html#cb611-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-37"><a href="09-calculo-bayes.html#cb611-37" aria-hidden="true" tabindex="-1"></a>n_aceptados <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb611-38"><a href="09-calculo-bayes.html#cb611-38" aria-hidden="true" tabindex="-1"></a>n_rechazados <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb611-39"><a href="09-calculo-bayes.html#cb611-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-40"><a href="09-calculo-bayes.html#cb611-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-41"><a href="09-calculo-bayes.html#cb611-41" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fl">0.2</span></span>
<span id="cb611-42"><a href="09-calculo-bayes.html#cb611-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-43"><a href="09-calculo-bayes.html#cb611-43" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>(n_pasos <span class="sc">-</span> <span class="dv">1</span>)) {</span>
<span id="cb611-44"><a href="09-calculo-bayes.html#cb611-44" aria-hidden="true" tabindex="-1"></a>    pos_actual <span class="ot">&lt;-</span> trayectoria[t]</span>
<span id="cb611-45"><a href="09-calculo-bayes.html#cb611-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-46"><a href="09-calculo-bayes.html#cb611-46" aria-hidden="true" tabindex="-1"></a>    salto_propuesto <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)</span>
<span id="cb611-47"><a href="09-calculo-bayes.html#cb611-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-48"><a href="09-calculo-bayes.html#cb611-48" aria-hidden="true" tabindex="-1"></a>    proba_aceptacion <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="dv">1</span>, <span class="fu">posterior</span>(pos_actual <span class="sc">+</span></span>
<span id="cb611-49"><a href="09-calculo-bayes.html#cb611-49" aria-hidden="true" tabindex="-1"></a>        salto_propuesto, datos_observados)<span class="sc">/</span><span class="fu">posterior</span>(pos_actual,</span>
<span id="cb611-50"><a href="09-calculo-bayes.html#cb611-50" aria-hidden="true" tabindex="-1"></a>        datos_observados))</span>
<span id="cb611-51"><a href="09-calculo-bayes.html#cb611-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb611-52"><a href="09-calculo-bayes.html#cb611-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Aceptamos el salto?</span></span>
<span id="cb611-53"><a href="09-calculo-bayes.html#cb611-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> proba_aceptacion) {</span>
<span id="cb611-54"><a href="09-calculo-bayes.html#cb611-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Aceptados</span></span>
<span id="cb611-55"><a href="09-calculo-bayes.html#cb611-55" aria-hidden="true" tabindex="-1"></a>        trayectoria[t <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> pos_actual <span class="sc">+</span> salto_propuesto</span>
<span id="cb611-56"><a href="09-calculo-bayes.html#cb611-56" aria-hidden="true" tabindex="-1"></a>        n_aceptados <span class="ot">&lt;-</span> n_aceptados <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb611-57"><a href="09-calculo-bayes.html#cb611-57" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb611-58"><a href="09-calculo-bayes.html#cb611-58" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Rechazos</span></span>
<span id="cb611-59"><a href="09-calculo-bayes.html#cb611-59" aria-hidden="true" tabindex="-1"></a>        trayectoria[t <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> pos_actual</span>
<span id="cb611-60"><a href="09-calculo-bayes.html#cb611-60" aria-hidden="true" tabindex="-1"></a>        n_rechazados <span class="ot">&lt;-</span> n_rechazados <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb611-61"><a href="09-calculo-bayes.html#cb611-61" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb611-62"><a href="09-calculo-bayes.html#cb611-62" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Obtenemos una tasa de aceptación del 49.8 y tasa de rechazo del 50.2</p>
<p>Podemos desechar los primeros 500 pasos (por ejemplo) del proceso ya que estos son de “calentamiento”. De esta forma podremos estimar la media y la varianza de las trayectoria.</p>
<div class="sourceCode" id="cb612"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb612-1"><a href="09-calculo-bayes.html#cb612-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(trayectoria[<span class="dv">500</span><span class="sc">:</span>n_pasos])</span></code></pre></div>
<pre><code>## [1] 0.683422</code></pre>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb614-1"><a href="09-calculo-bayes.html#cb614-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(trayectoria[<span class="dv">500</span><span class="sc">:</span>n_pasos])</span></code></pre></div>
<pre><code>## [1] 0.09785508</code></pre>
<div class="sourceCode" id="cb616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb616-1"><a href="09-calculo-bayes.html#cb616-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span>n_pasos, <span class="at">P =</span> trayectoria)</span>
<span id="cb616-2"><a href="09-calculo-bayes.html#cb616-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb616-3"><a href="09-calculo-bayes.html#cb616-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df[<span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>, ]) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="fu">aes</span>(x, P), <span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb616-4"><a href="09-calculo-bayes.html#cb616-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_flip</span>() <span class="sc">+</span> <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">16</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-355-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb617-1"><a href="09-calculo-bayes.html#cb617-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df[<span class="dv">500</span><span class="sc">:</span>n_pasos, ]) <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(P, <span class="at">y =</span> ..density..),</span>
<span id="cb617-2"><a href="09-calculo-bayes.html#cb617-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">16</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-355-2.svg" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="el-problema-del-viajero-con-dos-monedas" class="section level2 hasAnchor" number="9.9">
<h2><span class="header-section-number">9.9</span> El problema del viajero con dos monedas<a href="09-calculo-bayes.html#el-problema-del-viajero-con-dos-monedas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Un problema con el algoritmo de Metropolis-Hastings (M-H) es que solo funciona para la estimación de un solo parámetro.</p>
<p>El muestreo de Gibbs está pensado en el caso de la estimación de muchos parámetros de forma bastante ordenada.</p>
<p>Supongamos que tenemos dos monedas y queremos ver la proporción de escudos generados entre las dos monedas:</p>
<p>Tenemos:</p>
<ul>
<li>Parámetros: <span class="math inline">\(\theta_{1}\)</span> y <span class="math inline">\(\theta_{2}\)</span>.</li>
<li>Datos: <span class="math inline">\(N_{1}\)</span> tiradas de la moneda 1 y <span class="math inline">\(N_{2}\)</span> tiradas de la moneda 2. (cada una tuvo <span class="math inline">\(z_{1}\)</span> y <span class="math inline">\(z_{2}\)</span> éxitos).</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p>Verosimilitud: Bernoulli.
<span class="math display">\[\begin{equation*}
y_{1}^{i}\sim \mathrm{Bernoulli}(\theta_{1})
\quad
y_{2}^{i}\sim \mathrm{Bernoulli}(\theta_{2})
\end{equation*}\]</span></p></li>
<li><p>Previa: Beta independiente para cada <span class="math inline">\(\theta\)</span>.
<span class="math display">\[\begin{equation*}
\theta_{1}\sim \mathrm{Beta}(a_{1},b_{1})
\quad
\theta_{2}\sim \mathrm{Beta}(a_{2},b_{2})
\end{equation*}\]</span></p></li>
</ol>
<p>La distribución posterior se puede escribir como</p>
<p><span class="math display">\[\begin{align*}
f\left(\theta_{1}, \theta_{2} | D\right)
&amp;=f\left(D | \theta_{1}, \theta_{2}\right) \frac{f\left(\theta_{1}, \theta_{2}\right)}{f(D)} \\
&amp;=\theta_{1}^{z_{1}}\left(1-\theta_{1}\right)^{N_{1}-z_{1}} \theta_{1}^{z_{2}}\left(1-\theta_{2}\right)^{N_{2}-z_{2}} \frac{f\left(\theta_{1}, \theta_{2}\right)}{f(D)}  \\
&amp;=\frac{\theta_{1}^{z_{1}}\left(1-\theta_{1}\right)^{N_{1}-z_{1}} \theta_{1}^{z_{2}}\left(1-\theta_{2}\right)^{N_{2}-z_{2}} \theta_{1}^{a_{1}-1}\left(1-\theta_{1}\right)^{b_{1}-1} \theta_{2}^{a_{2}-1}\left(1-\theta_{2}\right)^{b_{2}-1}}{f(D) B\left(a_{1}, b_{1}\right) B\left(a_{2}, b_{2}\right)} \\
&amp;=\frac{\theta_{1}^{z_{1}+a_{1}-1}\left(1-\theta_{1}\right)^{N_{1}-z_{1}+b_{1}-1} \theta_{2}^{z_{2}+a_{2}-1}\left(1-\theta_{2}\right)^{N_{2}-z_{2}+b_{2}-1}}{f(D) B\left(a_{1}, b_{1}\right) B\left(a_{2}, b_{2}\right)}
\end{align*}\]</span>
Entonces la distribución posterior de <span class="math inline">\(\left(\theta_{1}, \theta_{2}\right)\)</span> son dos distribuciones independientes Betas:
<span class="math inline">\(\operatorname{Beta}\left(z_{1}+a, N_{1}-z_{1}+b_{1}\right)\)</span> y <span class="math inline">\(\operatorname{Beta}\left(z_{2}+a, N_{2}-z_{2}+b_{2}\right)\)</span></p>
<p>Tratemos de encontrar los parámetros para la distribución posterior usando un algoritmo de Metropolis-Hasting. <a href="https://rpruim.github.io/Kruschke-Notes/markov-chain-monte-carlo-mcmc.html#metropolis">Función tomada de Kruschke-Notes</a></p>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb618-1"><a href="09-calculo-bayes.html#cb618-1" aria-hidden="true" tabindex="-1"></a>metro_2coins <span class="ot">&lt;-</span> <span class="cf">function</span>(z1, n1, <span class="co"># z = successes, n = trials</span></span>
<span id="cb618-2"><a href="09-calculo-bayes.html#cb618-2" aria-hidden="true" tabindex="-1"></a>                         z2, n2, <span class="co"># z = successes, n = trials</span></span>
<span id="cb618-3"><a href="09-calculo-bayes.html#cb618-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">size =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.1</span>), <span class="co"># sds of jump distribution</span></span>
<span id="cb618-4"><a href="09-calculo-bayes.html#cb618-4" aria-hidden="true" tabindex="-1"></a>                         <span class="at">start =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>), <span class="co"># value of thetas to start at</span></span>
<span id="cb618-5"><a href="09-calculo-bayes.html#cb618-5" aria-hidden="true" tabindex="-1"></a>                         <span class="at">num_steps =</span> <span class="fl">5e4</span>, <span class="co"># number of steps to run the algorithm</span></span>
<span id="cb618-6"><a href="09-calculo-bayes.html#cb618-6" aria-hidden="true" tabindex="-1"></a>                         <span class="at">prior1 =</span> dbeta, <span class="co"># function describing prior</span></span>
<span id="cb618-7"><a href="09-calculo-bayes.html#cb618-7" aria-hidden="true" tabindex="-1"></a>                         <span class="at">prior2 =</span> dbeta, <span class="co"># function describing prior</span></span>
<span id="cb618-8"><a href="09-calculo-bayes.html#cb618-8" aria-hidden="true" tabindex="-1"></a>                         <span class="at">args1 =</span> <span class="fu">list</span>(), <span class="co"># additional args for prior1</span></span>
<span id="cb618-9"><a href="09-calculo-bayes.html#cb618-9" aria-hidden="true" tabindex="-1"></a>                         <span class="at">args2 =</span> <span class="fu">list</span>() <span class="co"># additional args for prior2</span></span>
<span id="cb618-10"><a href="09-calculo-bayes.html#cb618-10" aria-hidden="true" tabindex="-1"></a>) {</span>
<span id="cb618-11"><a href="09-calculo-bayes.html#cb618-11" aria-hidden="true" tabindex="-1"></a>  theta1 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, num_steps) <span class="co"># trick to pre-alocate memory</span></span>
<span id="cb618-12"><a href="09-calculo-bayes.html#cb618-12" aria-hidden="true" tabindex="-1"></a>  theta2 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, num_steps) <span class="co"># trick to pre-alocate memory</span></span>
<span id="cb618-13"><a href="09-calculo-bayes.html#cb618-13" aria-hidden="true" tabindex="-1"></a>  proposed_theta1 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, num_steps) <span class="co"># trick to pre-alocate memory</span></span>
<span id="cb618-14"><a href="09-calculo-bayes.html#cb618-14" aria-hidden="true" tabindex="-1"></a>  proposed_theta2 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, num_steps) <span class="co"># trick to pre-alocate memory</span></span>
<span id="cb618-15"><a href="09-calculo-bayes.html#cb618-15" aria-hidden="true" tabindex="-1"></a>  move <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, num_steps) <span class="co"># trick to pre-alocate memory</span></span>
<span id="cb618-16"><a href="09-calculo-bayes.html#cb618-16" aria-hidden="true" tabindex="-1"></a>  theta1[<span class="dv">1</span>] <span class="ot">&lt;-</span> start[<span class="dv">1</span>]</span>
<span id="cb618-17"><a href="09-calculo-bayes.html#cb618-17" aria-hidden="true" tabindex="-1"></a>  theta2[<span class="dv">1</span>] <span class="ot">&lt;-</span> start[<span class="dv">2</span>]</span>
<span id="cb618-18"><a href="09-calculo-bayes.html#cb618-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb618-19"><a href="09-calculo-bayes.html#cb618-19" aria-hidden="true" tabindex="-1"></a>  size1 <span class="ot">&lt;-</span> size[<span class="dv">1</span>]</span>
<span id="cb618-20"><a href="09-calculo-bayes.html#cb618-20" aria-hidden="true" tabindex="-1"></a>  size2 <span class="ot">&lt;-</span> size[<span class="dv">2</span>]</span>
<span id="cb618-21"><a href="09-calculo-bayes.html#cb618-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb618-22"><a href="09-calculo-bayes.html#cb618-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(num_steps <span class="sc">-</span> <span class="dv">1</span>)) {</span>
<span id="cb618-23"><a href="09-calculo-bayes.html#cb618-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># head to new &quot;island&quot;</span></span>
<span id="cb618-24"><a href="09-calculo-bayes.html#cb618-24" aria-hidden="true" tabindex="-1"></a>    proposed_theta1[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, theta1[i], size1)</span>
<span id="cb618-25"><a href="09-calculo-bayes.html#cb618-25" aria-hidden="true" tabindex="-1"></a>    proposed_theta2[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, theta2[i], size2)</span>
<span id="cb618-26"><a href="09-calculo-bayes.html#cb618-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb618-27"><a href="09-calculo-bayes.html#cb618-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (proposed_theta1[i <span class="sc">+</span> <span class="dv">1</span>] <span class="sc">&lt;=</span> <span class="dv">0</span> <span class="sc">||</span></span>
<span id="cb618-28"><a href="09-calculo-bayes.html#cb618-28" aria-hidden="true" tabindex="-1"></a>      proposed_theta1[i <span class="sc">+</span> <span class="dv">1</span>] <span class="sc">&gt;=</span> <span class="dv">1</span> <span class="sc">||</span></span>
<span id="cb618-29"><a href="09-calculo-bayes.html#cb618-29" aria-hidden="true" tabindex="-1"></a>      proposed_theta2[i <span class="sc">+</span> <span class="dv">1</span>] <span class="sc">&lt;=</span> <span class="dv">0</span> <span class="sc">||</span></span>
<span id="cb618-30"><a href="09-calculo-bayes.html#cb618-30" aria-hidden="true" tabindex="-1"></a>      proposed_theta2[i <span class="sc">+</span> <span class="dv">1</span>] <span class="sc">&gt;=</span> <span class="dv">1</span>) {</span>
<span id="cb618-31"><a href="09-calculo-bayes.html#cb618-31" aria-hidden="true" tabindex="-1"></a>      proposed_posterior <span class="ot">&lt;-</span> <span class="dv">0</span> <span class="co"># because prior is 0</span></span>
<span id="cb618-32"><a href="09-calculo-bayes.html#cb618-32" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb618-33"><a href="09-calculo-bayes.html#cb618-33" aria-hidden="true" tabindex="-1"></a>      current_prior <span class="ot">&lt;-</span></span>
<span id="cb618-34"><a href="09-calculo-bayes.html#cb618-34" aria-hidden="true" tabindex="-1"></a>        <span class="fu">do.call</span>(prior1, <span class="fu">c</span>(<span class="fu">list</span>(theta1[i]), args1)) <span class="sc">*</span></span>
<span id="cb618-35"><a href="09-calculo-bayes.html#cb618-35" aria-hidden="true" tabindex="-1"></a>          <span class="fu">do.call</span>(prior2, <span class="fu">c</span>(<span class="fu">list</span>(theta2[i]), args2))</span>
<span id="cb618-36"><a href="09-calculo-bayes.html#cb618-36" aria-hidden="true" tabindex="-1"></a>      current_likelihood <span class="ot">&lt;-</span></span>
<span id="cb618-37"><a href="09-calculo-bayes.html#cb618-37" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dbinom</span>(z1, n1, theta1[i]) <span class="sc">*</span></span>
<span id="cb618-38"><a href="09-calculo-bayes.html#cb618-38" aria-hidden="true" tabindex="-1"></a>          <span class="fu">dbinom</span>(z2, n2, theta2[i])</span>
<span id="cb618-39"><a href="09-calculo-bayes.html#cb618-39" aria-hidden="true" tabindex="-1"></a>      current_posterior <span class="ot">&lt;-</span> current_prior <span class="sc">*</span> current_likelihood</span>
<span id="cb618-40"><a href="09-calculo-bayes.html#cb618-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb618-41"><a href="09-calculo-bayes.html#cb618-41" aria-hidden="true" tabindex="-1"></a>      proposed_prior <span class="ot">&lt;-</span></span>
<span id="cb618-42"><a href="09-calculo-bayes.html#cb618-42" aria-hidden="true" tabindex="-1"></a>        <span class="fu">do.call</span>(prior1, <span class="fu">c</span>(<span class="fu">list</span>(proposed_theta1[i <span class="sc">+</span> <span class="dv">1</span>]), args1)) <span class="sc">*</span></span>
<span id="cb618-43"><a href="09-calculo-bayes.html#cb618-43" aria-hidden="true" tabindex="-1"></a>          <span class="fu">do.call</span>(prior2, <span class="fu">c</span>(<span class="fu">list</span>(proposed_theta2[i <span class="sc">+</span> <span class="dv">1</span>]), args2))</span>
<span id="cb618-44"><a href="09-calculo-bayes.html#cb618-44" aria-hidden="true" tabindex="-1"></a>      proposed_likelihood <span class="ot">&lt;-</span></span>
<span id="cb618-45"><a href="09-calculo-bayes.html#cb618-45" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dbinom</span>(z1, n1, proposed_theta1[i <span class="sc">+</span> <span class="dv">1</span>]) <span class="sc">*</span></span>
<span id="cb618-46"><a href="09-calculo-bayes.html#cb618-46" aria-hidden="true" tabindex="-1"></a>          <span class="fu">dbinom</span>(z2, n2, proposed_theta2[i <span class="sc">+</span> <span class="dv">1</span>])</span>
<span id="cb618-47"><a href="09-calculo-bayes.html#cb618-47" aria-hidden="true" tabindex="-1"></a>      proposed_posterior <span class="ot">&lt;-</span> proposed_prior <span class="sc">*</span> proposed_likelihood</span>
<span id="cb618-48"><a href="09-calculo-bayes.html#cb618-48" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb618-49"><a href="09-calculo-bayes.html#cb618-49" aria-hidden="true" tabindex="-1"></a>    prob_move <span class="ot">&lt;-</span> proposed_posterior <span class="sc">/</span> current_posterior</span>
<span id="cb618-50"><a href="09-calculo-bayes.html#cb618-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb618-51"><a href="09-calculo-bayes.html#cb618-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sometimes we &quot;sail back&quot;</span></span>
<span id="cb618-52"><a href="09-calculo-bayes.html#cb618-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&gt;</span> prob_move) { <span class="co"># sail back</span></span>
<span id="cb618-53"><a href="09-calculo-bayes.html#cb618-53" aria-hidden="true" tabindex="-1"></a>      move[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="cn">FALSE</span></span>
<span id="cb618-54"><a href="09-calculo-bayes.html#cb618-54" aria-hidden="true" tabindex="-1"></a>      theta1[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> theta1[i]</span>
<span id="cb618-55"><a href="09-calculo-bayes.html#cb618-55" aria-hidden="true" tabindex="-1"></a>      theta2[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> theta2[i]</span>
<span id="cb618-56"><a href="09-calculo-bayes.html#cb618-56" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> { <span class="co"># stay</span></span>
<span id="cb618-57"><a href="09-calculo-bayes.html#cb618-57" aria-hidden="true" tabindex="-1"></a>      move[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="cn">TRUE</span></span>
<span id="cb618-58"><a href="09-calculo-bayes.html#cb618-58" aria-hidden="true" tabindex="-1"></a>      theta1[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> proposed_theta1[i <span class="sc">+</span> <span class="dv">1</span>]</span>
<span id="cb618-59"><a href="09-calculo-bayes.html#cb618-59" aria-hidden="true" tabindex="-1"></a>      theta2[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> proposed_theta2[i <span class="sc">+</span> <span class="dv">1</span>]</span>
<span id="cb618-60"><a href="09-calculo-bayes.html#cb618-60" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb618-61"><a href="09-calculo-bayes.html#cb618-61" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb618-62"><a href="09-calculo-bayes.html#cb618-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb618-63"><a href="09-calculo-bayes.html#cb618-63" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(</span>
<span id="cb618-64"><a href="09-calculo-bayes.html#cb618-64" aria-hidden="true" tabindex="-1"></a>    <span class="at">step =</span> <span class="dv">1</span><span class="sc">:</span>num_steps,</span>
<span id="cb618-65"><a href="09-calculo-bayes.html#cb618-65" aria-hidden="true" tabindex="-1"></a>    <span class="at">theta1 =</span> theta1,</span>
<span id="cb618-66"><a href="09-calculo-bayes.html#cb618-66" aria-hidden="true" tabindex="-1"></a>    <span class="at">theta2 =</span> theta2,</span>
<span id="cb618-67"><a href="09-calculo-bayes.html#cb618-67" aria-hidden="true" tabindex="-1"></a>    <span class="at">proposed_theta1 =</span> proposed_theta1,</span>
<span id="cb618-68"><a href="09-calculo-bayes.html#cb618-68" aria-hidden="true" tabindex="-1"></a>    <span class="at">proposed_theta2 =</span> proposed_theta2,</span>
<span id="cb618-69"><a href="09-calculo-bayes.html#cb618-69" aria-hidden="true" tabindex="-1"></a>    <span class="at">move =</span> move,</span>
<span id="cb618-70"><a href="09-calculo-bayes.html#cb618-70" aria-hidden="true" tabindex="-1"></a>    <span class="at">size1 =</span> size1,</span>
<span id="cb618-71"><a href="09-calculo-bayes.html#cb618-71" aria-hidden="true" tabindex="-1"></a>    <span class="at">size2 =</span> size2</span>
<span id="cb618-72"><a href="09-calculo-bayes.html#cb618-72" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb618-73"><a href="09-calculo-bayes.html#cb618-73" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb619"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb619-1"><a href="09-calculo-bayes.html#cb619-1" aria-hidden="true" tabindex="-1"></a>Metro_2coinsA <span class="ot">&lt;-</span> <span class="fu">metro_2coins</span>(<span class="at">z1 =</span> <span class="dv">6</span>, <span class="at">n1 =</span> <span class="dv">8</span>, <span class="at">z2 =</span> <span class="dv">2</span>,</span>
<span id="cb619-2"><a href="09-calculo-bayes.html#cb619-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">n2 =</span> <span class="dv">7</span>, <span class="at">size =</span> <span class="fu">c</span>(<span class="fl">0.02</span>, <span class="fl">0.02</span>), <span class="at">args1 =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> <span class="dv">2</span>,</span>
<span id="cb619-3"><a href="09-calculo-bayes.html#cb619-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">shape2 =</span> <span class="dv">2</span>), <span class="at">args2 =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> <span class="dv">2</span>, <span class="at">shape2 =</span> <span class="dv">2</span>))</span>
<span id="cb619-4"><a href="09-calculo-bayes.html#cb619-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb619-5"><a href="09-calculo-bayes.html#cb619-5" aria-hidden="true" tabindex="-1"></a>Metro_2coinsA <span class="sc">%&gt;%</span></span>
<span id="cb619-6"><a href="09-calculo-bayes.html#cb619-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_density2d</span>(theta2 <span class="sc">~</span> theta1)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-357-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb620-1"><a href="09-calculo-bayes.html#cb620-1" aria-hidden="true" tabindex="-1"></a>Metro_2coinsA <span class="sc">%&gt;%</span></span>
<span id="cb620-2"><a href="09-calculo-bayes.html#cb620-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_density</span>(<span class="sc">~</span>(theta2 <span class="sc">-</span> theta1))</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-357-2.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb621"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb621-1"><a href="09-calculo-bayes.html#cb621-1" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(Metro_2coinsA<span class="sc">$</span>theta2 <span class="sc">-</span> Metro_2coinsA<span class="sc">$</span>theta1)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-357-3.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb622"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb622-1"><a href="09-calculo-bayes.html#cb622-1" aria-hidden="true" tabindex="-1"></a>Metro_2coinsA <span class="sc">%&gt;%</span></span>
<span id="cb622-2"><a href="09-calculo-bayes.html#cb622-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(step <span class="sc">&lt;</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span></span>
<span id="cb622-3"><a href="09-calculo-bayes.html#cb622-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_path</span>(theta2 <span class="sc">~</span> theta1, <span class="at">color =</span> <span class="sc">~</span>step, <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb622-4"><a href="09-calculo-bayes.html#cb622-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">type =</span> <span class="st">&quot;open&quot;</span>, <span class="at">angle =</span> <span class="dv">30</span>, <span class="at">length =</span> <span class="fu">unit</span>(<span class="fl">0.1</span>,</span>
<span id="cb622-5"><a href="09-calculo-bayes.html#cb622-5" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;inches&quot;</span>))) <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-358-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb623"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb623-1"><a href="09-calculo-bayes.html#cb623-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gganimate)</span>
<span id="cb623-2"><a href="09-calculo-bayes.html#cb623-2" aria-hidden="true" tabindex="-1"></a>Metro_2coinsAplot <span class="ot">&lt;-</span> Metro_2coinsA <span class="sc">%&gt;%</span></span>
<span id="cb623-3"><a href="09-calculo-bayes.html#cb623-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(step <span class="sc">&lt;</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span></span>
<span id="cb623-4"><a href="09-calculo-bayes.html#cb623-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_path</span>(theta2 <span class="sc">~</span> theta1, <span class="at">color =</span> <span class="sc">~</span>step, <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb623-5"><a href="09-calculo-bayes.html#cb623-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">type =</span> <span class="st">&quot;open&quot;</span>, <span class="at">angle =</span> <span class="dv">30</span>)) <span class="sc">+</span></span>
<span id="cb623-6"><a href="09-calculo-bayes.html#cb623-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span> <span class="fu">transition_reveal</span>(step)</span>
<span id="cb623-7"><a href="09-calculo-bayes.html#cb623-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb623-8"><a href="09-calculo-bayes.html#cb623-8" aria-hidden="true" tabindex="-1"></a><span class="fu">animate</span>(Metro_2coinsAplot, <span class="at">fps =</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="sourceCode" id="cb624"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb624-1"><a href="09-calculo-bayes.html#cb624-1" aria-hidden="true" tabindex="-1"></a>Metro_2coinsB <span class="ot">&lt;-</span> <span class="fu">metro_2coins</span>(<span class="at">z1 =</span> <span class="dv">6</span>, <span class="at">n1 =</span> <span class="dv">8</span>, <span class="at">z2 =</span> <span class="dv">2</span>,</span>
<span id="cb624-2"><a href="09-calculo-bayes.html#cb624-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">n2 =</span> <span class="dv">7</span>, <span class="at">size =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.2</span>), <span class="at">args1 =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> <span class="dv">2</span>,</span>
<span id="cb624-3"><a href="09-calculo-bayes.html#cb624-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">shape2 =</span> <span class="dv">2</span>), <span class="at">args2 =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> <span class="dv">2</span>, <span class="at">shape2 =</span> <span class="dv">2</span>))</span>
<span id="cb624-4"><a href="09-calculo-bayes.html#cb624-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb624-5"><a href="09-calculo-bayes.html#cb624-5" aria-hidden="true" tabindex="-1"></a>Metro_2coinsB <span class="sc">%&gt;%</span></span>
<span id="cb624-6"><a href="09-calculo-bayes.html#cb624-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_density2d</span>(theta2 <span class="sc">~</span> theta1)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-360-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb625"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb625-1"><a href="09-calculo-bayes.html#cb625-1" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(Metro_2coinsB<span class="sc">$</span>theta2 <span class="sc">-</span> Metro_2coinsB<span class="sc">$</span>theta1)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-360-2.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb626"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb626-1"><a href="09-calculo-bayes.html#cb626-1" aria-hidden="true" tabindex="-1"></a>Metro_2coinsB <span class="sc">%&gt;%</span></span>
<span id="cb626-2"><a href="09-calculo-bayes.html#cb626-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(step <span class="sc">&lt;</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span></span>
<span id="cb626-3"><a href="09-calculo-bayes.html#cb626-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_path</span>(theta2 <span class="sc">~</span> theta1, <span class="at">color =</span> <span class="sc">~</span>step, <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb626-4"><a href="09-calculo-bayes.html#cb626-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">type =</span> <span class="st">&quot;open&quot;</span>, <span class="at">angle =</span> <span class="dv">30</span>, <span class="at">length =</span> <span class="fu">unit</span>(<span class="fl">0.1</span>,</span>
<span id="cb626-5"><a href="09-calculo-bayes.html#cb626-5" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;inches&quot;</span>))) <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-361-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb627"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb627-1"><a href="09-calculo-bayes.html#cb627-1" aria-hidden="true" tabindex="-1"></a>Metro_2coinsBplot <span class="ot">&lt;-</span> Metro_2coinsA <span class="sc">%&gt;%</span></span>
<span id="cb627-2"><a href="09-calculo-bayes.html#cb627-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(step <span class="sc">&lt;</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span></span>
<span id="cb627-3"><a href="09-calculo-bayes.html#cb627-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_path</span>(theta2 <span class="sc">~</span> theta1, <span class="at">color =</span> <span class="sc">~</span>step, <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb627-4"><a href="09-calculo-bayes.html#cb627-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">type =</span> <span class="st">&quot;open&quot;</span>, <span class="at">angle =</span> <span class="dv">30</span>)) <span class="sc">+</span></span>
<span id="cb627-5"><a href="09-calculo-bayes.html#cb627-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span> <span class="fu">transition_reveal</span>(step)</span>
<span id="cb627-6"><a href="09-calculo-bayes.html#cb627-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb627-7"><a href="09-calculo-bayes.html#cb627-7" aria-hidden="true" tabindex="-1"></a><span class="fu">animate</span>(Metro_2coinsBplot, <span class="at">fps =</span> <span class="dv">1</span>)</span></code></pre></div>
<div id="muestreo-de-gibbs" class="section level3 hasAnchor" number="9.9.1">
<h3><span class="header-section-number">9.9.1</span> Muestreo de Gibbs<a href="09-calculo-bayes.html#muestreo-de-gibbs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para este ejemplo <span class="math inline">\(\left( \theta_{1},\theta_{2} \right)\)</span>, entonces la forma de escoger la posteriores en cada paso sería de la forma:</p>
<ol style="list-style-type: decimal">
<li>Tome al azar un <span class="math inline">\(\boldsymbol{\theta}^{0} = \left( \theta_{1}^{0},\theta_{2}^{0} \right)\)</span>.</li>
<li>Escoja <span class="math inline">\(\theta_{1}^{1}\)</span> a partir de la distribución
<span class="math inline">\(f\left(\theta_{1} \vert \theta_{1}=\theta_{1}^{0}, \theta_{2}=\theta_{2}^{0}, \boldsymbol{X} \right)\)</span>.</li>
<li>Escoja <span class="math inline">\(\theta_{2}^{1}\)</span> a partir de la distribución
<span class="math inline">\(f\left(\theta_{2} \vert \theta_{1}=\theta_{1}^{1}, \theta_{2}=\theta_{2}^{0}, \boldsymbol{X} \right)\)</span>.</li>
</ol>
<p>Esto completa un ciclo del muestreo. Cada ciclo genera nuevos <span class="math inline">\(\boldsymbol{\theta}^{i} = \left( \theta_{1}^{i},\theta_{2}^{i} \right)\)</span> hasta que el proceso converja.</p>
<div class="remark">
<p><span id="unlabeled-div-31" class="remark"><em>Nota</em>. </span>En realidad el muestreo de Gibbs se basa en el algoritmo de M-H, con la diferencia que la elección de los parámetros se escogen teniendo en cuanta los datos y fijando los otros parámetros. Es decir,</p>
<p><span class="math display">\[\begin{align*}
&amp;{\left[\theta_{1} | \theta_{2}, \ldots, \theta_{M}, datos \right]} \\
&amp;{\left[\theta_{2} | \theta_{1}, \theta_{3}, \ldots, \theta_{M}, datos \right]} \\
&amp;{\left[\theta_{M} | \theta_{1}, \ldots, \theta_{M-1}, datos \right]}
\end{align*}\]</span></p>
</div>
<p>El tratamiento teórico puede ser consultado <a href="https://www.ece.iastate.edu/~namrata/EE527_Spring08/l4c.pdf#page=16">https://www.ece.iastate.edu/~namrata/EE527_Spring08/l4c.pdf#page=16</a></p>
<p><span class="math display">\[\begin{align*}
f\left(\theta_{1} | \theta_{2}, D\right)
&amp;= \frac{f\left(\theta_{1}, \theta_{2} | D\right)}{f\left(\theta_{2} | D\right)}  \\
&amp;= \frac{f\left(\theta_{1}, \theta_{2} | D\right)}{\int f\left(\theta_{1}, \theta_{2} | D\right)d \theta_{1}}   \\
&amp;=\frac{\operatorname{dbeta}\left(\theta_{1}, z_{1}+a_{1}, N_{1}-z_{1}+b_{1}\right) \cdot \operatorname{dbeta}\left(\theta_{2}, z_{2}+a_{2}, N_{2}-z_{2}+b_{2}\right)}{\int  \operatorname{dbeta}\left(\theta_{1}, z_{1}+a_{1}, N_{1}-z_{1}+b_{1}\right) \cdot \operatorname{dbeta}\left(\theta_{2} | z_{2}+a_{2}, N_{2}-z_{2}+b_{2}\right)d \theta_{1}} \\
&amp;=\frac{\operatorname{dbeta}\left(\theta_{1}, z_{1}+a_{1}, N_{1}-z_{1}+b_{1}\right) \cdot \operatorname{dbeta}\left(\theta_{2}, z_{2}+a_{2}, N_{2}-z_{2}+b_{2}\right)}{\operatorname{dbeta}\left(\theta_{2} | z_{2}+a_{2}, N_{2}-z_{2}+b_{2}\right) \int  \operatorname{dbeta}\left(\theta_{1}, z_{1}+a_{1}, N_{1}-z_{1}+b_{1}\right)d \theta_{1}} \\
&amp;=\frac{\operatorname{dbeta}\left(\theta_{1}, z_{1}+a_{1}, N_{1}-z_{1}+b_{1}\right)}{\int  \operatorname{dbeta}\left(\theta_{1}, z_{1}+a_{1}, N_{1}-z_{1}+b_{1}\right)d \theta_{1}} \\
&amp;=\operatorname{dbeta}\left(\theta_{1}, z_{1}+a_{1}, N_{1}-z_{1}+b_{1}\right)
\end{align*}\]</span></p>
<div class="sourceCode" id="cb628"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb628-1"><a href="09-calculo-bayes.html#cb628-1" aria-hidden="true" tabindex="-1"></a>gibbs_2coins <span class="ot">&lt;-</span> <span class="cf">function</span>(z1, n1, <span class="co"># z = successes, n = trials</span></span>
<span id="cb628-2"><a href="09-calculo-bayes.html#cb628-2" aria-hidden="true" tabindex="-1"></a>                         z2, n2, <span class="co"># z = successes, n = trials</span></span>
<span id="cb628-3"><a href="09-calculo-bayes.html#cb628-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">start =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>), <span class="co"># value of thetas to start at</span></span>
<span id="cb628-4"><a href="09-calculo-bayes.html#cb628-4" aria-hidden="true" tabindex="-1"></a>                         <span class="at">num_steps =</span> <span class="fl">1e4</span>, <span class="co"># number of steps to run the algorithm</span></span>
<span id="cb628-5"><a href="09-calculo-bayes.html#cb628-5" aria-hidden="true" tabindex="-1"></a>                         a1, b1, <span class="co"># params for prior for theta1</span></span>
<span id="cb628-6"><a href="09-calculo-bayes.html#cb628-6" aria-hidden="true" tabindex="-1"></a>                         a2, b2 <span class="co"># params for prior for theta2</span></span>
<span id="cb628-7"><a href="09-calculo-bayes.html#cb628-7" aria-hidden="true" tabindex="-1"></a>) {</span>
<span id="cb628-8"><a href="09-calculo-bayes.html#cb628-8" aria-hidden="true" tabindex="-1"></a>  theta1 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, num_steps) <span class="co"># trick to pre-alocate memory</span></span>
<span id="cb628-9"><a href="09-calculo-bayes.html#cb628-9" aria-hidden="true" tabindex="-1"></a>  theta2 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, num_steps) <span class="co"># trick to pre-alocate memory</span></span>
<span id="cb628-10"><a href="09-calculo-bayes.html#cb628-10" aria-hidden="true" tabindex="-1"></a>  theta1[<span class="dv">1</span>] <span class="ot">&lt;-</span> start[<span class="dv">1</span>]</span>
<span id="cb628-11"><a href="09-calculo-bayes.html#cb628-11" aria-hidden="true" tabindex="-1"></a>  theta2[<span class="dv">1</span>] <span class="ot">&lt;-</span> start[<span class="dv">2</span>]</span>
<span id="cb628-12"><a href="09-calculo-bayes.html#cb628-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb628-13"><a href="09-calculo-bayes.html#cb628-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(num_steps <span class="sc">-</span> <span class="dv">1</span>)) {</span>
<span id="cb628-14"><a href="09-calculo-bayes.html#cb628-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (i <span class="sc">%%</span> <span class="dv">2</span> <span class="sc">==</span> <span class="dv">1</span>) { <span class="co"># update theta1</span></span>
<span id="cb628-15"><a href="09-calculo-bayes.html#cb628-15" aria-hidden="true" tabindex="-1"></a>      theta1[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, z1 <span class="sc">+</span> a1, n1 <span class="sc">-</span> z1 <span class="sc">+</span> b1)</span>
<span id="cb628-16"><a href="09-calculo-bayes.html#cb628-16" aria-hidden="true" tabindex="-1"></a>      theta2[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> theta2[i]</span>
<span id="cb628-17"><a href="09-calculo-bayes.html#cb628-17" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> { <span class="co"># update theta2</span></span>
<span id="cb628-18"><a href="09-calculo-bayes.html#cb628-18" aria-hidden="true" tabindex="-1"></a>      theta1[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> theta1[i]</span>
<span id="cb628-19"><a href="09-calculo-bayes.html#cb628-19" aria-hidden="true" tabindex="-1"></a>      theta2[i <span class="sc">+</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rbeta</span>(<span class="dv">1</span>, z2 <span class="sc">+</span> a2, n2 <span class="sc">-</span> z2 <span class="sc">+</span> b2)</span>
<span id="cb628-20"><a href="09-calculo-bayes.html#cb628-20" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb628-21"><a href="09-calculo-bayes.html#cb628-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb628-22"><a href="09-calculo-bayes.html#cb628-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb628-23"><a href="09-calculo-bayes.html#cb628-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(</span>
<span id="cb628-24"><a href="09-calculo-bayes.html#cb628-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">step =</span> <span class="dv">1</span><span class="sc">:</span>num_steps,</span>
<span id="cb628-25"><a href="09-calculo-bayes.html#cb628-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">theta1 =</span> theta1,</span>
<span id="cb628-26"><a href="09-calculo-bayes.html#cb628-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">theta2 =</span> theta2,</span>
<span id="cb628-27"><a href="09-calculo-bayes.html#cb628-27" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb628-28"><a href="09-calculo-bayes.html#cb628-28" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb629-1"><a href="09-calculo-bayes.html#cb629-1" aria-hidden="true" tabindex="-1"></a>Gibbs <span class="ot">&lt;-</span> <span class="fu">gibbs_2coins</span>(<span class="at">z1 =</span> <span class="dv">6</span>, <span class="at">n1 =</span> <span class="dv">8</span>, <span class="at">z2 =</span> <span class="dv">2</span>, <span class="at">n2 =</span> <span class="dv">7</span>,</span>
<span id="cb629-2"><a href="09-calculo-bayes.html#cb629-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">a1 =</span> <span class="dv">2</span>, <span class="at">b1 =</span> <span class="dv">2</span>, <span class="at">a2 =</span> <span class="dv">2</span>, <span class="at">b2 =</span> <span class="dv">2</span>)</span>
<span id="cb629-3"><a href="09-calculo-bayes.html#cb629-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb629-4"><a href="09-calculo-bayes.html#cb629-4" aria-hidden="true" tabindex="-1"></a>Gibbs <span class="sc">%&gt;%</span></span>
<span id="cb629-5"><a href="09-calculo-bayes.html#cb629-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_density2d</span>(theta2 <span class="sc">~</span> theta1)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-365-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb630"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb630-1"><a href="09-calculo-bayes.html#cb630-1" aria-hidden="true" tabindex="-1"></a>Gibbs <span class="sc">%&gt;%</span></span>
<span id="cb630-2"><a href="09-calculo-bayes.html#cb630-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_dens</span>(<span class="sc">~</span>theta1)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-365-2.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb631"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb631-1"><a href="09-calculo-bayes.html#cb631-1" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(Gibbs<span class="sc">$</span>theta1)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-365-3.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb632"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb632-1"><a href="09-calculo-bayes.html#cb632-1" aria-hidden="true" tabindex="-1"></a>Gibbs <span class="sc">%&gt;%</span></span>
<span id="cb632-2"><a href="09-calculo-bayes.html#cb632-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(step <span class="sc">&lt;</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span></span>
<span id="cb632-3"><a href="09-calculo-bayes.html#cb632-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_path</span>(theta2 <span class="sc">~</span> theta1, <span class="at">color =</span> <span class="sc">~</span>step, <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb632-4"><a href="09-calculo-bayes.html#cb632-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">type =</span> <span class="st">&quot;open&quot;</span>, <span class="at">angle =</span> <span class="dv">30</span>, <span class="at">length =</span> <span class="fu">unit</span>(<span class="fl">0.1</span>,</span>
<span id="cb632-5"><a href="09-calculo-bayes.html#cb632-5" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;inches&quot;</span>))) <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-366-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb633"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb633-1"><a href="09-calculo-bayes.html#cb633-1" aria-hidden="true" tabindex="-1"></a>Gibbsplot <span class="ot">&lt;-</span> Gibbs <span class="sc">%&gt;%</span></span>
<span id="cb633-2"><a href="09-calculo-bayes.html#cb633-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(step <span class="sc">&lt;</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span></span>
<span id="cb633-3"><a href="09-calculo-bayes.html#cb633-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_path</span>(theta2 <span class="sc">~</span> theta1, <span class="at">color =</span> <span class="sc">~</span>step, <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb633-4"><a href="09-calculo-bayes.html#cb633-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">type =</span> <span class="st">&quot;open&quot;</span>, <span class="at">angle =</span> <span class="dv">30</span>)) <span class="sc">+</span></span>
<span id="cb633-5"><a href="09-calculo-bayes.html#cb633-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span> <span class="fu">transition_reveal</span>(step)</span>
<span id="cb633-6"><a href="09-calculo-bayes.html#cb633-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb633-7"><a href="09-calculo-bayes.html#cb633-7" aria-hidden="true" tabindex="-1"></a><span class="fu">animate</span>(Gibbsplot, <span class="at">fps =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>Ciclos completos</p>
<div class="sourceCode" id="cb634"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb634-1"><a href="09-calculo-bayes.html#cb634-1" aria-hidden="true" tabindex="-1"></a>Gibbs <span class="sc">%&gt;%</span></span>
<span id="cb634-2"><a href="09-calculo-bayes.html#cb634-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(step<span class="sc">%%</span><span class="dv">2</span> <span class="sc">==</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb634-3"><a href="09-calculo-bayes.html#cb634-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_density2d</span>(theta2 <span class="sc">~</span> theta1)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-368-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb635"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb635-1"><a href="09-calculo-bayes.html#cb635-1" aria-hidden="true" tabindex="-1"></a>Gibbs <span class="sc">%&gt;%</span></span>
<span id="cb635-2"><a href="09-calculo-bayes.html#cb635-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(step<span class="sc">%%</span><span class="dv">2</span> <span class="sc">==</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb635-3"><a href="09-calculo-bayes.html#cb635-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_density</span>(<span class="sc">~</span>(theta2 <span class="sc">-</span> theta1))</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-368-2.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb636"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb636-1"><a href="09-calculo-bayes.html#cb636-1" aria-hidden="true" tabindex="-1"></a>Gibbs <span class="sc">%&gt;%</span></span>
<span id="cb636-2"><a href="09-calculo-bayes.html#cb636-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(step<span class="sc">%%</span><span class="dv">2</span> <span class="sc">==</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb636-3"><a href="09-calculo-bayes.html#cb636-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">difference =</span> theta2 <span class="sc">-</span> theta1) <span class="sc">%&gt;%</span></span>
<span id="cb636-4"><a href="09-calculo-bayes.html#cb636-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pull</span>(difference) <span class="sc">%&gt;%</span></span>
<span id="cb636-5"><a href="09-calculo-bayes.html#cb636-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">acf</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-368-3.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb637"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb637-1"><a href="09-calculo-bayes.html#cb637-1" aria-hidden="true" tabindex="-1"></a>Gibbs <span class="sc">%&gt;%</span></span>
<span id="cb637-2"><a href="09-calculo-bayes.html#cb637-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(step <span class="sc">&lt;</span> <span class="dv">500</span>, step<span class="sc">%%</span><span class="dv">2</span> <span class="sc">==</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb637-3"><a href="09-calculo-bayes.html#cb637-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_path</span>(theta2 <span class="sc">~</span> theta1, <span class="at">color =</span> <span class="sc">~</span>step, <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb637-4"><a href="09-calculo-bayes.html#cb637-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">type =</span> <span class="st">&quot;open&quot;</span>, <span class="at">angle =</span> <span class="dv">30</span>, <span class="at">length =</span> <span class="fu">unit</span>(<span class="fl">0.1</span>,</span>
<span id="cb637-5"><a href="09-calculo-bayes.html#cb637-5" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;inches&quot;</span>))) <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-369-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb638-1"><a href="09-calculo-bayes.html#cb638-1" aria-hidden="true" tabindex="-1"></a>Gibbsplot2 <span class="ot">&lt;-</span> Gibbs <span class="sc">%&gt;%</span></span>
<span id="cb638-2"><a href="09-calculo-bayes.html#cb638-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(step <span class="sc">&lt;</span> <span class="dv">500</span>, step<span class="sc">%%</span><span class="dv">2</span> <span class="sc">==</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb638-3"><a href="09-calculo-bayes.html#cb638-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_path</span>(theta2 <span class="sc">~</span> theta1, <span class="at">color =</span> <span class="sc">~</span>step, <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb638-4"><a href="09-calculo-bayes.html#cb638-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">type =</span> <span class="st">&quot;open&quot;</span>, <span class="at">angle =</span> <span class="dv">30</span>)) <span class="sc">+</span></span>
<span id="cb638-5"><a href="09-calculo-bayes.html#cb638-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span> <span class="fu">transition_reveal</span>(step)</span>
<span id="cb638-6"><a href="09-calculo-bayes.html#cb638-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb638-7"><a href="09-calculo-bayes.html#cb638-7" aria-hidden="true" tabindex="-1"></a><span class="fu">animate</span>(Gibbsplot2, <span class="at">fps =</span> <span class="dv">1</span>)</span></code></pre></div>
</div>
</div>
<div id="uso-de-jags" class="section level2 hasAnchor" number="9.10">
<h2><span class="header-section-number">9.10</span> Uso de JAGS<a href="09-calculo-bayes.html#uso-de-jags" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El paquete que usaremos en esta sección es <code>R2jags</code> y <code>coda</code>. Los cargamos con las instrucciones</p>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb639-1"><a href="09-calculo-bayes.html#cb639-1" aria-hidden="true" tabindex="-1"></a>remotes<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">&quot;rpruim/CalvinBayes&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb640"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb640-1"><a href="09-calculo-bayes.html#cb640-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(R2jags)</span>
<span id="cb640-2"><a href="09-calculo-bayes.html#cb640-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(coda)</span>
<span id="cb640-3"><a href="09-calculo-bayes.html#cb640-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(CalvinBayes)</span></code></pre></div>
<div class="sourceCode" id="cb641"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb641-1"><a href="09-calculo-bayes.html#cb641-1" aria-hidden="true" tabindex="-1"></a>bernoulli <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">file =</span> <span class="st">&quot;data/bernoulli.csv&quot;</span>,</span>
<span id="cb641-2"><a href="09-calculo-bayes.html#cb641-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">sep =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb641-3"><a href="09-calculo-bayes.html#cb641-3" aria-hidden="true" tabindex="-1"></a>tibble<span class="sc">::</span><span class="fu">glimpse</span>(bernoulli)</span></code></pre></div>
<pre><code>## Rows: 50
## Columns: 1
## $ y &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,…</code></pre>
<div class="sourceCode" id="cb643"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb643-1"><a href="09-calculo-bayes.html#cb643-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(bernoulli<span class="sc">$</span>y)</span></code></pre></div>
<pre><code>## [1] 0.3</code></pre>
<div class="sourceCode" id="cb645"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb645-1"><a href="09-calculo-bayes.html#cb645-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(bernoulli<span class="sc">$</span>y)</span></code></pre></div>
<pre><code>## [1] 0.46291</code></pre>
<p>En el lenguaje usual de JAGS, el modelo debe escribirse de la forma:</p>
<pre><code>model
{
    for (i in 1:N) {
        y[i] ~ dbern(theta)
    }
    theta ~ dbeta(1, 1)
}
</code></pre>
<p>donde <code>dbern</code> y <code>dbeta</code> son las densidades de una bernoulli y beta respectivamente. En este lenguage no existen versiones vectorizadas de las funciones por lo que todo debe llenarse usando <code>for</code>’s. Una revisión completa de este lenguage la pueden econtrar en su manual de uso <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>El paquete <code>R2jags</code> tiene la capacidad que en lugar de usar este tipo de sintaxis, se pueda usar el lenguaje natural para escribir el modelo. Note el uso de <code>function</code> en este caso.</p>
<div class="sourceCode" id="cb648"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb648-1"><a href="09-calculo-bayes.html#cb648-1" aria-hidden="true" tabindex="-1"></a>bern_model <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb648-2"><a href="09-calculo-bayes.html#cb648-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb648-3"><a href="09-calculo-bayes.html#cb648-3" aria-hidden="true" tabindex="-1"></a>        y[i] <span class="sc">~</span> <span class="fu">dbern</span>(theta)</span>
<span id="cb648-4"><a href="09-calculo-bayes.html#cb648-4" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb648-5"><a href="09-calculo-bayes.html#cb648-5" aria-hidden="true" tabindex="-1"></a>    theta <span class="sc">~</span> <span class="fu">dbeta</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb648-6"><a href="09-calculo-bayes.html#cb648-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb649-1"><a href="09-calculo-bayes.html#cb649-1" aria-hidden="true" tabindex="-1"></a>bern_jags <span class="ot">&lt;-</span> <span class="fu">jags</span>(<span class="at">data =</span> <span class="fu">list</span>(<span class="at">y =</span> bernoulli<span class="sc">$</span>y, <span class="at">N =</span> <span class="fu">nrow</span>(bernoulli)),</span>
<span id="cb649-2"><a href="09-calculo-bayes.html#cb649-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">model.file =</span> bern_model, <span class="at">parameters.to.save =</span> <span class="fu">c</span>(<span class="st">&quot;theta&quot;</span>))</span></code></pre></div>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 50
##    Unobserved stochastic nodes: 1
##    Total graph size: 53
## 
## Initializing model</code></pre>
<p>Veamos el resultado</p>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb651-1"><a href="09-calculo-bayes.html#cb651-1" aria-hidden="true" tabindex="-1"></a>bern_jags</span></code></pre></div>
<pre><code>## Inference for Bugs model at &quot;/var/folders/4d/qj4qr8zx1n36td0hlt0p7x_h0000gn/T//RtmpC6DYg2/model14d6a5bc19be9.txt&quot;, fit using jags,
##  3 chains, each with 2000 iterations (first 1000 discarded)
##  n.sims = 3000 iterations saved
##          mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
## theta      0.305   0.063  0.193  0.261  0.303  0.346  0.436 1.001  3000
## deviance  62.031   1.300 61.088 61.186 61.519 62.313 65.727 1.005   920
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 0.8 and DIC = 62.9
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb653-1"><a href="09-calculo-bayes.html#cb653-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">posterior</span>(bern_jags))</span></code></pre></div>
<pre><code>## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;head&#39;: argument &quot;data&quot; is missing, with no default</code></pre>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb655-1"><a href="09-calculo-bayes.html#cb655-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gf_dhistogram</span>(<span class="sc">~</span>theta, <span class="at">data =</span> <span class="fu">posterior</span>(bern_jags),</span>
<span id="cb655-2"><a href="09-calculo-bayes.html#cb655-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">bins =</span> <span class="dv">50</span>) <span class="sc">%&gt;%</span></span>
<span id="cb655-3"><a href="09-calculo-bayes.html#cb655-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_dens</span>(<span class="sc">~</span>theta, <span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">%&gt;%</span></span>
<span id="cb655-4"><a href="09-calculo-bayes.html#cb655-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_dist</span>(<span class="st">&quot;beta&quot;</span>, <span class="at">shape1 =</span> <span class="dv">16</span>, <span class="at">shape2 =</span> <span class="dv">36</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<pre><code>## Error in verosimilitud(theta, data): argument &quot;data&quot; is missing, with no default</code></pre>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb657-1"><a href="09-calculo-bayes.html#cb657-1" aria-hidden="true" tabindex="-1"></a>bern_mcmc <span class="ot">&lt;-</span> <span class="fu">as.mcmc</span>(bern_jags)</span>
<span id="cb657-2"><a href="09-calculo-bayes.html#cb657-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(bern_mcmc)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-379-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb658"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb658-1"><a href="09-calculo-bayes.html#cb658-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bayesplot)</span>
<span id="cb658-2"><a href="09-calculo-bayes.html#cb658-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_areas</span>(bern_mcmc, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;theta&quot;</span>), <span class="at">prob =</span> <span class="fl">0.9</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-380-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="09-calculo-bayes.html#cb659-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_trace</span>(bern_mcmc, <span class="at">pars =</span> <span class="st">&quot;theta&quot;</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-381-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb660"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb660-1"><a href="09-calculo-bayes.html#cb660-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_trace</span>(bern_mcmc, <span class="at">pars =</span> <span class="st">&quot;theta&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb660-2"><a href="09-calculo-bayes.html#cb660-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_facet_grid</span>(Chain <span class="sc">~</span> .) <span class="sc">%&gt;%</span></span>
<span id="cb660-3"><a href="09-calculo-bayes.html#cb660-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">gf_refine</span>(<span class="fu">scale_color_viridis_d</span>())</span></code></pre></div>
<pre><code>## Error in `combine_vars()`:
## ! At least one layer must contain all faceting variables: `Chain`.
## * Plot is missing `Chain`
## * Layer 1 is missing `Chain`</code></pre>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-382-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb662-1"><a href="09-calculo-bayes.html#cb662-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_post</span>(bern_mcmc[, <span class="st">&quot;theta&quot;</span>], <span class="at">main =</span> <span class="st">&quot;theta&quot;</span>, <span class="at">xlab =</span> <span class="fu">expression</span>(theta),</span>
<span id="cb662-2"><a href="09-calculo-bayes.html#cb662-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">cenTend =</span> <span class="st">&quot;median&quot;</span>, <span class="at">compVal =</span> <span class="fl">0.5</span>, <span class="at">ROPE =</span> <span class="fu">c</span>(<span class="fl">0.45</span>,</span>
<span id="cb662-3"><a href="09-calculo-bayes.html#cb662-3" aria-hidden="true" tabindex="-1"></a>        <span class="fl">0.55</span>), <span class="at">credMass =</span> <span class="fl">0.9</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-383-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb663"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb663-1"><a href="09-calculo-bayes.html#cb663-1" aria-hidden="true" tabindex="-1"></a>twobernoulli <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/2bernoulli.csv&quot;</span>)</span>
<span id="cb663-2"><a href="09-calculo-bayes.html#cb663-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb663-3"><a href="09-calculo-bayes.html#cb663-3" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(twobernoulli)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">y</th>
<th align="left">s</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">Reginald</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="left">Reginald</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Reginald</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Reginald</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Reginald</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Reginald</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Reginald</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="left">Reginald</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="left">Tony</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="left">Tony</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Tony</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="left">Tony</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="left">Tony</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Tony</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="left">Tony</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb664-1"><a href="09-calculo-bayes.html#cb664-1" aria-hidden="true" tabindex="-1"></a>Target <span class="ot">&lt;-</span> twobernoulli <span class="sc">%&gt;%</span></span>
<span id="cb664-2"><a href="09-calculo-bayes.html#cb664-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rename</span>(<span class="at">hit =</span> y, <span class="at">subject =</span> s)</span>
<span id="cb664-3"><a href="09-calculo-bayes.html#cb664-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-4"><a href="09-calculo-bayes.html#cb664-4" aria-hidden="true" tabindex="-1"></a>Target <span class="sc">%&gt;%</span></span>
<span id="cb664-5"><a href="09-calculo-bayes.html#cb664-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(subject) <span class="sc">%&gt;%</span></span>
<span id="cb664-6"><a href="09-calculo-bayes.html#cb664-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarise</span>(<span class="at">prop_0 =</span> <span class="fu">sum</span>(<span class="dv">1</span> <span class="sc">-</span> hit)<span class="sc">/</span><span class="fu">n</span>(), <span class="at">prop_1 =</span> <span class="fu">sum</span>(hit)<span class="sc">/</span><span class="fu">n</span>(),</span>
<span id="cb664-7"><a href="09-calculo-bayes.html#cb664-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">attemps =</span> <span class="fu">n</span>())</span></code></pre></div>
<pre><code>## # A tibble: 2 × 4
##   subject  prop_0 prop_1 attemps
##   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;int&gt;
## 1 Reginald  0.25   0.75        8
## 2 Tony      0.714  0.286       7</code></pre>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb666-1"><a href="09-calculo-bayes.html#cb666-1" aria-hidden="true" tabindex="-1"></a>bern2_model <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb666-2"><a href="09-calculo-bayes.html#cb666-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>Nobs) {</span>
<span id="cb666-3"><a href="09-calculo-bayes.html#cb666-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># each response is Bernoulli with the</span></span>
<span id="cb666-4"><a href="09-calculo-bayes.html#cb666-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># appropriate theta</span></span>
<span id="cb666-5"><a href="09-calculo-bayes.html#cb666-5" aria-hidden="true" tabindex="-1"></a>        hit[i] <span class="sc">~</span> <span class="fu">dbern</span>(theta[subject[i]])</span>
<span id="cb666-6"><a href="09-calculo-bayes.html#cb666-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb666-7"><a href="09-calculo-bayes.html#cb666-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>Nsub) {</span>
<span id="cb666-8"><a href="09-calculo-bayes.html#cb666-8" aria-hidden="true" tabindex="-1"></a>        theta[s] <span class="sc">~</span> <span class="fu">dbeta</span>(<span class="dv">2</span>, <span class="dv">2</span>)  <span class="co"># prior for each theta</span></span>
<span id="cb666-9"><a href="09-calculo-bayes.html#cb666-9" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb666-10"><a href="09-calculo-bayes.html#cb666-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb667"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb667-1"><a href="09-calculo-bayes.html#cb667-1" aria-hidden="true" tabindex="-1"></a>TargetList <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">Nobs =</span> <span class="fu">nrow</span>(Target), <span class="at">Nsub =</span> <span class="dv">2</span>, <span class="at">hit =</span> Target<span class="sc">$</span>hit,</span>
<span id="cb667-2"><a href="09-calculo-bayes.html#cb667-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">subject =</span> <span class="fu">as.numeric</span>(<span class="fu">as.factor</span>(Target<span class="sc">$</span>subject)))</span>
<span id="cb667-3"><a href="09-calculo-bayes.html#cb667-3" aria-hidden="true" tabindex="-1"></a>TargetList</span></code></pre></div>
<pre><code>## $Nobs
## [1] 15
## 
## $Nsub
## [1] 2
## 
## $hit
##  [1] 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0
## 
## $subject
##  [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2</code></pre>
<div class="sourceCode" id="cb669"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb669-1"><a href="09-calculo-bayes.html#cb669-1" aria-hidden="true" tabindex="-1"></a>bern2_jags <span class="ot">&lt;-</span> <span class="fu">jags</span>(<span class="at">data =</span> TargetList, <span class="at">model =</span> bern2_model,</span>
<span id="cb669-2"><a href="09-calculo-bayes.html#cb669-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">parameters.to.save =</span> <span class="st">&quot;theta&quot;</span>)</span></code></pre></div>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 15
##    Unobserved stochastic nodes: 2
##    Total graph size: 35
## 
## Initializing model</code></pre>
<div class="sourceCode" id="cb671"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb671-1"><a href="09-calculo-bayes.html#cb671-1" aria-hidden="true" tabindex="-1"></a>bern2_mcmc <span class="ot">&lt;-</span> <span class="fu">as.mcmc</span>(bern2_jags)</span>
<span id="cb671-2"><a href="09-calculo-bayes.html#cb671-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb671-3"><a href="09-calculo-bayes.html#cb671-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_acf</span>(bern2_mcmc)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-388-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb672"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb672-1"><a href="09-calculo-bayes.html#cb672-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_combo</span>(bern2_mcmc, <span class="at">combo =</span> <span class="fu">c</span>(<span class="st">&quot;dens&quot;</span>, <span class="st">&quot;dens_overlay&quot;</span>,</span>
<span id="cb672-2"><a href="09-calculo-bayes.html#cb672-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;trace&quot;</span>, <span class="st">&quot;scatter&quot;</span>), <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;theta[1]&quot;</span>, <span class="st">&quot;theta[2]&quot;</span>))</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-388-2.svg" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="uso-de-stan" class="section level2 hasAnchor" number="9.11">
<h2><span class="header-section-number">9.11</span> Uso de STAN<a href="09-calculo-bayes.html#uso-de-stan" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>STAN<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> es otro tipo de lenguaje para definir modelos bayesiano. El lenguaje es un poco más sencillo, pero es particularmente útil para modelos bastante complejos.</p>
<p>STAN no usa el muestreo de Gibbs, sino en el método de Monte-Carlo Hamiltoniano. En el artículo <span class="citation">(Hoffman and Gelman 2014)</span> se propone el método NUTS para mejorar el muestreo de Gibbs.</p>
<p>En este curso no nos referiremos a este procedimiento, pero si veremos un poco de la sintaxis del lenguaje STAN.</p>
<div class="sourceCode" id="cb673"><pre class="sourceCode stan"><code class="sourceCode stan"><span id="cb673-1"><a href="09-calculo-bayes.html#cb673-1" aria-hidden="true" tabindex="-1"></a><span class="kw">data</span> {</span>
<span id="cb673-2"><a href="09-calculo-bayes.html#cb673-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>&gt; N;               <span class="co">// number of trials</span></span>
<span id="cb673-3"><a href="09-calculo-bayes.html#cb673-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>, <span class="kw">upper</span>=<span class="dv">1</span>&gt; y[N];   <span class="co">// success on trial n</span></span>
<span id="cb673-4"><a href="09-calculo-bayes.html#cb673-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb673-5"><a href="09-calculo-bayes.html#cb673-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb673-6"><a href="09-calculo-bayes.html#cb673-6" aria-hidden="true" tabindex="-1"></a><span class="kw">parameters</span> {</span>
<span id="cb673-7"><a href="09-calculo-bayes.html#cb673-7" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>, <span class="kw">upper</span>=<span class="dv">1</span>&gt; theta; <span class="co">// chance of success</span></span>
<span id="cb673-8"><a href="09-calculo-bayes.html#cb673-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb673-9"><a href="09-calculo-bayes.html#cb673-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb673-10"><a href="09-calculo-bayes.html#cb673-10" aria-hidden="true" tabindex="-1"></a><span class="kw">model</span> {</span>
<span id="cb673-11"><a href="09-calculo-bayes.html#cb673-11" aria-hidden="true" tabindex="-1"></a>  theta ~ uniform(<span class="dv">0</span>, <span class="dv">1</span>);        <span class="co">// prior</span></span>
<span id="cb673-12"><a href="09-calculo-bayes.html#cb673-12" aria-hidden="true" tabindex="-1"></a>  y ~ bernoulli(theta);         <span class="co">// likelihood</span></span>
<span id="cb673-13"><a href="09-calculo-bayes.html#cb673-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb674-1"><a href="09-calculo-bayes.html#cb674-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rstan)</span>
<span id="cb674-2"><a href="09-calculo-bayes.html#cb674-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb674-3"><a href="09-calculo-bayes.html#cb674-3" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">stan</span>(<span class="at">model_code =</span> bern_stan<span class="sc">@</span>model_code, <span class="at">data =</span> <span class="fu">list</span>(<span class="at">y =</span> bernoulli<span class="sc">$</span>y,</span>
<span id="cb674-4"><a href="09-calculo-bayes.html#cb674-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">N =</span> <span class="fu">nrow</span>(bernoulli)), <span class="at">iter =</span> <span class="dv">5000</span>)</span></code></pre></div>
<pre><code>## 
## SAMPLING FOR MODEL &#39;4584de91ce47196187979d2da8a67926&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 2.4e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 5000 [  0%]  (Warmup)
## Chain 1: Iteration:  500 / 5000 [ 10%]  (Warmup)
## Chain 1: Iteration: 1000 / 5000 [ 20%]  (Warmup)
## Chain 1: Iteration: 1500 / 5000 [ 30%]  (Warmup)
## Chain 1: Iteration: 2000 / 5000 [ 40%]  (Warmup)
## Chain 1: Iteration: 2500 / 5000 [ 50%]  (Warmup)
## Chain 1: Iteration: 2501 / 5000 [ 50%]  (Sampling)
## Chain 1: Iteration: 3000 / 5000 [ 60%]  (Sampling)
## Chain 1: Iteration: 3500 / 5000 [ 70%]  (Sampling)
## Chain 1: Iteration: 4000 / 5000 [ 80%]  (Sampling)
## Chain 1: Iteration: 4500 / 5000 [ 90%]  (Sampling)
## Chain 1: Iteration: 5000 / 5000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.026362 seconds (Warm-up)
## Chain 1:                0.030089 seconds (Sampling)
## Chain 1:                0.056451 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &#39;4584de91ce47196187979d2da8a67926&#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 6e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 5000 [  0%]  (Warmup)
## Chain 2: Iteration:  500 / 5000 [ 10%]  (Warmup)
## Chain 2: Iteration: 1000 / 5000 [ 20%]  (Warmup)
## Chain 2: Iteration: 1500 / 5000 [ 30%]  (Warmup)
## Chain 2: Iteration: 2000 / 5000 [ 40%]  (Warmup)
## Chain 2: Iteration: 2500 / 5000 [ 50%]  (Warmup)
## Chain 2: Iteration: 2501 / 5000 [ 50%]  (Sampling)
## Chain 2: Iteration: 3000 / 5000 [ 60%]  (Sampling)
## Chain 2: Iteration: 3500 / 5000 [ 70%]  (Sampling)
## Chain 2: Iteration: 4000 / 5000 [ 80%]  (Sampling)
## Chain 2: Iteration: 4500 / 5000 [ 90%]  (Sampling)
## Chain 2: Iteration: 5000 / 5000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.027912 seconds (Warm-up)
## Chain 2:                0.02768 seconds (Sampling)
## Chain 2:                0.055592 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &#39;4584de91ce47196187979d2da8a67926&#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 2e-05 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 5000 [  0%]  (Warmup)
## Chain 3: Iteration:  500 / 5000 [ 10%]  (Warmup)
## Chain 3: Iteration: 1000 / 5000 [ 20%]  (Warmup)
## Chain 3: Iteration: 1500 / 5000 [ 30%]  (Warmup)
## Chain 3: Iteration: 2000 / 5000 [ 40%]  (Warmup)
## Chain 3: Iteration: 2500 / 5000 [ 50%]  (Warmup)
## Chain 3: Iteration: 2501 / 5000 [ 50%]  (Sampling)
## Chain 3: Iteration: 3000 / 5000 [ 60%]  (Sampling)
## Chain 3: Iteration: 3500 / 5000 [ 70%]  (Sampling)
## Chain 3: Iteration: 4000 / 5000 [ 80%]  (Sampling)
## Chain 3: Iteration: 4500 / 5000 [ 90%]  (Sampling)
## Chain 3: Iteration: 5000 / 5000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.025409 seconds (Warm-up)
## Chain 3:                0.027097 seconds (Sampling)
## Chain 3:                0.052506 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL &#39;4584de91ce47196187979d2da8a67926&#39; NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 7e-06 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 5000 [  0%]  (Warmup)
## Chain 4: Iteration:  500 / 5000 [ 10%]  (Warmup)
## Chain 4: Iteration: 1000 / 5000 [ 20%]  (Warmup)
## Chain 4: Iteration: 1500 / 5000 [ 30%]  (Warmup)
## Chain 4: Iteration: 2000 / 5000 [ 40%]  (Warmup)
## Chain 4: Iteration: 2500 / 5000 [ 50%]  (Warmup)
## Chain 4: Iteration: 2501 / 5000 [ 50%]  (Sampling)
## Chain 4: Iteration: 3000 / 5000 [ 60%]  (Sampling)
## Chain 4: Iteration: 3500 / 5000 [ 70%]  (Sampling)
## Chain 4: Iteration: 4000 / 5000 [ 80%]  (Sampling)
## Chain 4: Iteration: 4500 / 5000 [ 90%]  (Sampling)
## Chain 4: Iteration: 5000 / 5000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.026013 seconds (Warm-up)
## Chain 4:                0.028213 seconds (Sampling)
## Chain 4:                0.054226 seconds (Total)
## Chain 4:</code></pre>
<div class="sourceCode" id="cb676"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb676-1"><a href="09-calculo-bayes.html#cb676-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>))</span></code></pre></div>
<pre><code>## Inference for Stan model: 4584de91ce47196187979d2da8a67926.
## 4 chains, each with iter=5000; warmup=2500; thin=1; 
## post-warmup draws per chain=2500, total post-warmup draws=10000.
## 
##         mean se_mean   sd    10%    90% n_eff Rhat
## theta   0.31    0.00 0.06   0.23   0.39  3497    1
## lp__  -32.61    0.01 0.73 -33.48 -32.10  3903    1
## 
## Samples were drawn using NUTS(diag_e) at Mon Jun 27 08:32:05 2022.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb678-1"><a href="09-calculo-bayes.html#cb678-1" aria-hidden="true" tabindex="-1"></a>theta_draws <span class="ot">&lt;-</span> <span class="fu">extract</span>(fit)<span class="sc">$</span>theta</span>
<span id="cb678-2"><a href="09-calculo-bayes.html#cb678-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb678-3"><a href="09-calculo-bayes.html#cb678-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(theta_draws)</span></code></pre></div>
<pre><code>## [1] 0.3069652</code></pre>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb680-1"><a href="09-calculo-bayes.html#cb680-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(theta_draws, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>))</span></code></pre></div>
<pre><code>##       10%       90% 
## 0.2261308 0.3905893</code></pre>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="09-calculo-bayes.html#cb682-1" aria-hidden="true" tabindex="-1"></a>shinystan<span class="sc">::</span><span class="fu">launch_shinystan</span>(fit)</span></code></pre></div>
<div class="exercise">
<p><span id="exr:unnamed-chunk-392" class="exercise"><strong>Ejercicio 9.1  </strong></span>Replique los resultados anteriores pero para el caso de 2 monedas y comente los resultados.</p>
</div>
<!-- ## Algoritmo de Metropolis-Hastings -->
<!-- Muestreo por cadenas de Markov-Monte Carlo (MCMC): algoritmos que definen una cadena de Markov irreducible y aperiódica cuya densidad estacionaria es la densidad posterior de interés. -->
<!-- Simplificamos la notación de la densidad posterior $g(\theta|y)$ usando $g(\theta)$. Seleccionamos un valor inicial del algoritmo $\theta^0$ y procedemos con el -->
<!-- Algoritmo -->
<!-- - Simule un candidato $\theta^*\sim p(\theta^*|\theta^{t-1})$ (densidad propuesta). -->
<!-- - Calcule: -->
<!-- $$R=\frac{g(\theta^*)p(\theta^{t-1}|\theta^*)}{g(\theta^{t-1})p(\theta^*|\theta^{t-1})}$$ -->
<!-- - Calcule la probabilidad de aceptación $P=\min \{R,1\}$. -->
<!-- - Acepte la propuesta $\theta^{t}=\theta^*$ con probabilidad P, en caso contrario $\theta^t=\theta^{t-1}$. -->
<!-- Nota: bajo ciertas condiciones de regularidad sobre la probabilidad propuesta: -->
<!-- $$\theta^n \stackrel{d}{\longrightarrow} M\sim g(\theta)$$ -->
<!-- cuando $n\rightarrow \infty$. -->
<!-- Escogencias de la densidad propuesta: -->
<!-- - Metropolis-Hastings independiente:  -->
<!-- $$p(\theta^*|\theta^{t-1})=p(\theta^*)$$ -->
<!-- - Metropolis-Hastings con caminata aleatoria:  -->
<!-- $$p(\theta^*|\theta^{t-1})=h(\theta^*-\theta^{t-1})$$ -->
<!-- donde $h$ es una función simétrica alrededor del origen. En este caso es fácil verificar que: -->
<!-- $$R=\frac{g(\theta^*)}{g(\theta^{t-1})}$$ -->
<!-- Nota: las implementaciones de Metropolis-Hastings dentro del paquete LearnBayes tienen las siguientes particularidades: -->
<!-- - La función *indepmetrop* contiene una propuesta que es normal multivariada con media $\mu$ y varianza $V$ (modelo independiente). Los parámetros de la propuesta se debe escoger de manera que $g/p$ se acotado, especialmente en las colas. -->
<!-- - La función *rwmetrop* contiene una propuesta de la siguiente forma: -->
<!-- $$\theta^*=\theta^{t-1}+\sigma Z$$ -->
<!-- donde $Z$ es una normal multivariada con media 0 y matriz de varianza $V$. Además $\sigma$ es un parámetro de escala positivo. -->
<!-- ## Algoritmo de Gibbs -->
<!-- Suponga que el parámetro de interés es $\theta=(\theta_1,\ldots,\theta_p)$ y que podemos obtener muestras de manera secuencial a partir de las siguientes distribuciones condicionales (dado un valor inicial $\theta^0$ y $t=1,\ldots,n$): -->
<!-- \begin{align*} -->
<!-- \theta_1^t&\sim [\theta_1|\theta_2^{t-1},\ldots,\theta_p^{t-1},\text{datos}]\\ -->
<!-- \theta_2^t&\sim [\theta_2|\theta_1^t,\theta_3^{t-1},\ldots,\theta_p^{t-1},\text{datos}]\\ -->
<!-- \vdots & \qquad \vdots\\ -->
<!-- \theta_p^t&\sim [\theta_p|\theta_1^t,\ldots,\theta_{p-1}^t,\text{datos}] -->
<!-- \end{align*} -->
<!-- Bajo condiciones bastante generales se puede comprobar que $\theta^t$ converge a una muestra de la distribución conjunta posterior de $\theta$. -->
<!-- Nota: cuando en alguna de las condicionales anteriores no se puede obtener muestras de manera directa, entonces se puede sustituir el muestreo por un paso del algoritmo de Metropolis-Hastings. Así está implementado en la función *gibbs* del paquete LearnBayes. -->
<!-- ### Diagnósticos de convergencia de MCMC -->
<!-- - Tasa de aceptación. -->
<!-- - Gráficos de traza (traceplots): gráfico de $(t,\theta^t)$. Por la naturaleza secuencial de los algoritmos de MH y Gibbs, los primeros valores de la cadena no representan normalmente una muestra confiable de la distribución posterior, por lo que generalmente se desecha un porcentaje inicial de la muestra (periodo de quema o burn-in period).  -->
<!-- - Por construcción, uno esperaría que el nivel de autocorrelación de las cadenas sea bajo. Al igual que en el análisis de residuos de regresión, uno puede construir un ACF de las cadenas y esperar autocorrelación baja y convergente a 0. -->
<!-- ## Ejemplos -->
<!-- ### Datos agrupados bajo una población normal -->
<!-- Suponga que observamos los siguientes datos agrupados: -->
<!-- |Altura (pulgadas)|Frecuencia| -->
<!-- |------|----------| -->
<!-- |Menos de 66| 14| -->
<!-- |Entre 66 y 68 |30| -->
<!-- |Entre 68 y 70 |49| -->
<!-- |Entre 70 y 72 |70| -->
<!-- |Entre 72 y 74 |33| -->
<!-- |Más de 74|15| -->
<!-- Si asumimos que las alturas son normales con media $\mu$ y desviación estándar $\sigma$, podemos asumir una verosimilitud multinomial para los datos agrupados: -->
<!-- \begin{align*} -->
<!-- L(\mu,\sigma)&\propto \Phi(66,\mu,\sigma)^{14}(\Phi(68,\mu,\sigma)-\Phi(66,\mu,\sigma))^{30} \\ -->
<!-- &\times  (\Phi(70,\mu,\sigma)-\Phi(68,\mu,\sigma))^{49} (\Phi(72,\mu,\sigma)-\Phi(70,\mu,\sigma))^{70}\\ -->
<!-- &\times  (\Phi(74,\mu,\sigma)-\Phi(72,\mu,\sigma))^{33} (1-\Phi(74,\mu,\sigma))^{15} -->
<!-- \end{align*} -->
<!-- y asumimos una previa no informativa para $(\mu,\sigma)\sim \frac 1 \sigma$. Como $\sigma>0$ entonces usamos la transformación $\lambda=\log (\sigma)$. -->
<!-- ```{r} -->
<!-- d <- list( -->
<!--   int.lo = c(-Inf, seq(66, 74, by = 2)), -->
<!--   int.hi = c(seq(66, 74, by = 2), Inf), -->
<!--   f = c(14, 30, 49, 70, 33, 15) -->
<!-- ) -->
<!-- ``` -->
<!-- es una estructura de los datos agrupados. La log-densidad posterior de los datos sería: -->
<!-- ```{r} -->
<!-- groupeddatapost <- function(theta, data) { -->
<!--   dj <- function(f, int.lo, int.hi, mu, sigma) { -->
<!--     f * log(pnorm(int.hi, mu, sigma) - pnorm(int.lo, mu, sigma)) -->
<!--   } -->
<!--   mu <- theta[1] -->
<!--   sigma <- exp(theta[2]) -->
<!--   sum(dj(data$f, data$int.lo, data$int.hi, mu, sigma)) -->
<!-- } -->
<!-- ``` -->
<!-- Usamos el método de Laplace para encontrar una aproximación de los parámetros de la previa bajo Metropolis-Hastings: -->
<!-- ```{r} -->
<!-- start <- c(70, 1) -->
<!-- fit <- laplace(groupeddatapost, start, d) -->
<!-- fit -->
<!-- ``` -->
<!-- la escogencia del valor inicial se basa en los datos artificiales en la página 126 del [@Albert2009]. De esta forma definimos los parámetros de la propuesta como: -->
<!-- ```{r} -->
<!-- proposal <- list(var = fit$var, scale = 2) -->
<!-- ``` -->
<!-- y ajustamos la versión bajo caminata aleatoria de un Metropolis-Hastings (MH): -->
<!-- ```{r} -->
<!-- fit2 <- rwmetrop(groupeddatapost, proposal, start, 10000, d) -->
<!-- ``` -->
<!-- con una tasa de aceptación: -->
<!-- ```{r} -->
<!-- fit2$accept -->
<!-- ``` -->
<!-- Algunas estadísticas de la distribución posterior de $\mu$ y $\log \sigma$: -->
<!-- ```{r} -->
<!-- post.means <- apply(fit2$par, 2, mean) -->
<!-- post.sds <- apply(fit2$par, 2, sd) -->
<!-- cbind(post.means, post.sds) -->
<!-- ``` -->
<!-- esto se puede comparar con los estimadores de la aproximación de Laplace: -->
<!-- ```{r} -->
<!-- modal.sds <- sqrt(diag(fit$var)) -->
<!-- cbind(c(fit$mode), modal.sds) -->
<!-- ``` -->
<!-- También podemos graficar la densidad posterior junto con la muestra generada por el MH, usando una muestra de burn-in de 5000: -->
<!-- ```{r} -->
<!--  mycontour(groupeddatapost, -->
<!--            c(69, 71, .6, 1.3), d, -->
<!--    xlab = "mu", ylab = "log sigma" -->
<!--  ) -->
<!--  points(fit2$par[5001:10000, 1], fit2$par[5001:10000, 2]) -->
<!-- ``` -->
<!-- Los traceplots del MCMC los graficamos a través del paquete *coda* junto con el paquete *bayesplot*: -->
<!-- ```{r} -->
<!-- library(coda) -->
<!-- library(bayesplot) -->
<!-- dimnames(fit2$par)[[2]] <- c("mu", "log sigma") -->
<!-- obj_mcmc <- mcmc(fit2$par[-c(1:5000), ]) -->
<!-- mcmc_trace(obj_mcmc) -->
<!-- ``` -->
<!-- Los gráficos de autocorrelación empíricos se pueden generar con: -->
<!-- ```{r} -->
<!-- mcmc_acf(obj_mcmc) -->
<!-- ``` -->
<!-- y funciones de densidad estimadas con intervalos de predicción al 95% para algunos de los parámetros: -->
<!-- ```{r} -->
<!-- mcmc_areas(obj_mcmc, pars = c("mu"), prob = 0.95) -->
<!-- ``` -->
<!-- ### Datos con outliers -->
<!-- Suponga $y_1,\ldots,y_n\sim \text{Cauchy}(\mu,\sigma)$: -->
<!-- $$f(y|\mu,\sigma)=\frac{1}{\pi\sigma(1+z^2)}$$ -->
<!-- donde $z=\frac{y-\mu}{\sigma}$. Con una previa no informativa $g(\mu,\sigma)\propto 1/\sigma$ y transformando $\lambda = \log \sigma$ se puede comprobar que la log-densidad posterior es: -->
<!-- $$\log g(\mu,\lambda|\text{datos}) = \sum_{i=1}^n\left[-\lambda-\log\left(1+\exp(-2\lambda)(y_i-\mu)^2\right)\right]$$ -->
<!-- y la implementación de la log-posterior usando la distribución t de Student como generador de la distribución Cauchy: -->
<!-- ```{r} -->
<!-- cauchyerrorpost <- function (theta, data){ -->
<!--   logf <- function(data, theta) -->
<!--     log(dt((data - theta[1])/exp(theta[2]),df = 1)/exp(theta[2])) -->
<!-- return(sum(logf(data, theta))) -->
<!-- } -->
<!-- ``` -->
<!-- Los datos provienen de la base *darwin* con 15 diferencias entre alturas de plantas según Fisher (1960). La media y log-desviación estándar empíricos de los datos son: -->
<!-- ```{r} -->
<!-- data(darwin) -->
<!-- data_darwin <- darwin$difference -->
<!-- mean(data_darwin) -->
<!-- log(sd(data_darwin)) -->
<!-- ``` -->
<!-- y usamos estos valores como valores iniciales dentro de la aproximación de Laplace: -->
<!-- ```{r} -->
<!-- fitlaplace <- laplace(cauchyerrorpost, c(21.6, 3.6), data_darwin) -->
<!-- fitlaplace -->
<!-- ``` -->
<!-- y usamos lo anterior como insumo para generar tres escenarios de MCMC: -->
<!-- - Metropolis-Hastings con caminata aleatoria: -->
<!-- ```{r} -->
<!-- proposal <- list(var=fitlaplace$var,scale=2.5) -->
<!-- start <- c(20,3) -->
<!-- E1 <- rwmetrop(cauchyerrorpost,proposal,start,50000,data_darwin) -->
<!-- mycontour(cauchyerrorpost,c(-10,60,1,4.5),data_darwin, -->
<!--            xlab="mu",ylab="log sigma") -->
<!-- points(E1$par[,1],E1$par[,2]) -->
<!-- ``` -->
<!-- - Metropolis-Hastings independiente: -->
<!-- ```{r} -->
<!-- proposal2 <- list(var=fitlaplace$var,mu=t(fitlaplace$mode)) -->
<!-- E2 <- indepmetrop(cauchyerrorpost,proposal2, -->
<!--                   start,50000,data_darwin) -->
<!-- mycontour(cauchyerrorpost,c(-10,60,1,4.5),data_darwin, -->
<!--            xlab="mu",ylab="log sigma") -->
<!-- points(E2$par[,1],E2$par[,2]) -->
<!-- ``` -->
<!-- - Muestreo de Gibbs: -->
<!-- ```{r} -->
<!-- E3 <- gibbs(cauchyerrorpost,start,50000, -->
<!--                c(12,.75),data_darwin) -->
<!-- mycontour(cauchyerrorpost,c(-10,60,1,4.5),data_darwin, -->
<!--            xlab="mu",ylab="log sigma") -->
<!-- points(E3$par[,1],E3$par[,2]) -->
<!-- ``` -->
<!-- Comparemos el estimador bayesiano e intervalos de predicción al 95% para la media $\mu$: -->
<!-- ```{r} -->
<!-- Resultados <- data.frame(rbind( -->
<!--   c(mean(E1$par[,1]),quantile(E1$par[,1],probs =c(0.025,0.975)),E1$accept),  c(mean(E2$par[,1]),quantile(E2$par[,1],probs =c(0.025,0.975)),E2$accept), -->
<!--   c(mean(E3$par[,1]),quantile(E3$par[,1],probs =c(0.025,0.975)),NA))) -->
<!-- colnames(Resultados) <- c('Media','Q1','Q3','Accept') -->
<!-- rownames(Resultados) <- c('MH-RW','MH-Indep','Gibbs') -->
<!-- Resultados <- Resultados %>% mutate(Ancho = Q3-Q1) -->
<!-- library(knitr) -->
<!-- kable(Resultados) -->
<!-- ``` -->
<!-- En el caso del algoritmo de Gibbs, cada uno de los pasos tiene una tasa de aceptación de MH en este caso: -->
<!-- ```{r} -->
<!-- E3$accept -->
<!-- ``` -->
<!-- También podemos incluir histogramas para las muestras posteriores de ambos parámetros. Para el MH independiente (burn-in=5000): -->
<!-- ```{r} -->
<!-- color_scheme_set('green') -->
<!-- dimnames(E2$par)[[2]] <- c("mu","log sigma") -->
<!-- obj_mcmc2 <- mcmc(E2$par[-c(1:5000),]) -->
<!-- mcmc_hist(obj_mcmc2,pars = c('mu','log sigma')) -->
<!-- ``` -->
<!-- y los gráficos de autocorrelación respectivos: -->
<!-- ```{r} -->
<!-- mcmc_acf_bar(obj_mcmc2,pars = c('mu','log sigma')) -->
<!-- ``` -->
<!-- ## Ejercicios  -->
<!-- - Del libro [@Albert2009] -->
<!--     - Capítulo 5:  1, 2, 4, 5. -->
<!--     - Capítulo 6: 3, 5, 6, 10. -->

<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
Albert, Jim, Robert Gentleman, Giovanni Parmigiani, and Kurt Hornik. 2009. <em>Bayesian Computation with <span>R</span></em>. <em>Bayesian Computation with R</em>. <span>New York, NY</span>: <span>Springer New York</span>. <a href="https://doi.org/10.1007/978-0-387-92298-0">https://doi.org/10.1007/978-0-387-92298-0</a>.
</div>
<div class="csl-entry">
Cavanaugh, Joseph E., and Andrew A. Neath. 2019. <span>“The <span>Akaike</span> Information Criterion: <span>Background</span>, Derivation, Properties, Application, Interpretation, and Refinements.”</span> <em>WIREs Computational Statistics</em> 11 (3): e1460. <a href="https://doi.org/10.1002/wics.1460">https://doi.org/10.1002/wics.1460</a>.
</div>
<div class="csl-entry">
Efron, B. 1979. <span>“Bootstrap <span>Methods</span>: <span>Another Look</span> at the <span>Jackknife</span>.”</span> <em>The Annals of Statistics</em> 7 (1): 1–26. <a href="https://doi.org/10.1214/aos/1176344552">https://doi.org/10.1214/aos/1176344552</a>.
</div>
<div class="csl-entry">
Hall, Peter. 1987. <span>“On <span>Kullback</span>-<span>Leibler Loss</span> and <span>Density Estimation</span>.”</span> <em>The Annals of Statistics</em> 15 (4): 1491–1519. <a href="https://doi.org/10.1214/aos/1176350606">https://doi.org/10.1214/aos/1176350606</a>.
</div>
<div class="csl-entry">
Härdle, Wolfgang, Axel Werwatz, Marlene Müller, and Stefan Sperlich. 2004. <em>Nonparametric and <span>Semiparametric Models</span></em>. <span>Berlin, Heidelberg</span>: <span>Springer Berlin Heidelberg</span>. <a href="https://doi.org/10.1007/978-3-642-17146-8">https://doi.org/10.1007/978-3-642-17146-8</a>.
</div>
<div class="csl-entry">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em>The <span>Elements</span> of <span>Statistical Learning</span>: <span>Data</span> Mining, <span>Inference</span>, and <span>Prediction</span></em>. <span>New York</span>: <span>Springer</span>. <a href="https://doi.org/10.1007/978-0-387-84858-7">https://doi.org/10.1007/978-0-387-84858-7</a>.
</div>
<div class="csl-entry">
Hoffman, Matthew D., and Andrew Gelman. 2014. <span>“The No-<span>U</span>-Turn Sampler: <span>Adaptively</span> Setting Path Lengths in <span>Hamiltonian Monte Carlo</span>.”</span> <em>Journal of Machine Learning Research</em> 15 (47): 1593–623. <a href="https://arxiv.org/abs/1111.4246">https://arxiv.org/abs/1111.4246</a>.
</div>
<div class="csl-entry">
Husson, Francois, Sebastien Le, and Jérôme Pagès. 2017. <em>Exploratory <span>Multivariate Analysis</span> by <span>Example Using R</span></em>. <span>CRC Press</span>.
</div>
<div class="csl-entry">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An <span>Introduction</span> to <span>Statistical Learning</span></em>. Vol. 103. <span>New York, NY</span>: <span>Springer New York</span>. <a href="https://doi.org/10.1007/978-1-4614-7138-7">https://doi.org/10.1007/978-1-4614-7138-7</a>.
</div>
<div class="csl-entry">
Quenouille, M. H. 1949. <span>“Approximate <span>Tests</span> of <span>Correlation</span> in <span>Time</span>-<span>Series</span>.”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 11 (1): 68–84. <a href="https://doi.org/10.1111/j.2517-6161.1949.tb00023.x">https://doi.org/10.1111/j.2517-6161.1949.tb00023.x</a>.
</div>
<div class="csl-entry">
Stone, M. 1977. <span>“An <span>Asymptotic Equivalence</span> of <span>Choice</span> of <span>Model</span> by <span>Cross</span>-<span>Validation</span> and <span>Akaike</span>’s <span>Criterion</span>.”</span> <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 39 (1): 44–47.
</div>
<div class="csl-entry">
Wasserman, Larry. 2006. <em>All of <span>Nonparametric Statistics</span></em>. <em>All of Nonparametric Statistics</em>. <span>New York, NY</span>: <span>Springer New York</span>. <a href="https://doi.org/10.1007/0-387-30623-4">https://doi.org/10.1007/0-387-30623-4</a>.
</div>
</div>
</div>
</div>







<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p><a href="http://web.sgh.waw.pl/~atoroj/ekonometria_bayesowska/jags_user_manual.pdf">http://web.sgh.waw.pl/~atoroj/ekonometria_bayesowska/jags_user_manual.pdf</a><a href="09-calculo-bayes.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><a href="https://mc-stan.org/">https://mc-stan.org/</a><a href="09-calculo-bayes.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="07-componentes-principales.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica/edit/master/09-calculo-bayes.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica/blob/master/09-calculo-bayes.Rmd",
"text": null
},
"download": ["Notas-Curso-Estadistica.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"toc_depth": 5
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
