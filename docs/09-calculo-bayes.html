<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 8 Análisis en componentes principales | Notas Curso de Estadística II</title>
  <meta name="description" content="Capítulo 8 Análisis en componentes principales | Notas Curso de Estadística II" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 8 Análisis en componentes principales | Notas Curso de Estadística II" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 8 Análisis en componentes principales | Notas Curso de Estadística II" />
  
  
  

<meta name="author" content="Maikol Solís Chacón y Luis Barboza Chinchilla" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="08-clasificacion.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/rglWebGL-binding-0.108.3/rglWebGL.js"></script>
<link href="libs/rglwidgetClass-0.108.3/rgl.css" rel="stylesheet" />
<script src="libs/rglwidgetClass-0.108.3/rglClass.min.js"></script>
<script src="libs/CanvasMatrix4-0.108.3/CanvasMatrix.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso de Estadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html"><i class="fa fa-check"></i><b>2</b> Estimación no-paramétrica de densidades</a>
<ul>
<li class="chapter" data-level="2.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#histograma"><i class="fa fa-check"></i><b>2.1</b> Histograma</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#construcción-estadística"><i class="fa fa-check"></i><b>2.1.1</b> Construcción Estadística</a></li>
<li class="chapter" data-level="2.1.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#construcción-probabilística"><i class="fa fa-check"></i><b>2.1.2</b> Construcción probabilística</a></li>
<li class="chapter" data-level="2.1.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas"><i class="fa fa-check"></i><b>2.1.3</b> Propiedades estadísticas</a></li>
<li class="chapter" data-level="2.1.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas-1"><i class="fa fa-check"></i><b>2.1.4</b> Propiedades estadísticas</a></li>
<li class="chapter" data-level="2.1.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#sesgo"><i class="fa fa-check"></i><b>2.1.5</b> Sesgo</a></li>
<li class="chapter" data-level="2.1.6" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#varianza"><i class="fa fa-check"></i><b>2.1.6</b> Varianza</a></li>
<li class="chapter" data-level="2.1.7" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio"><i class="fa fa-check"></i><b>2.1.7</b> Error cuadrático medio</a></li>
<li class="chapter" data-level="2.1.8" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio-integrado"><i class="fa fa-check"></i><b>2.1.8</b> Error cuadrático medio integrado</a></li>
<li class="chapter" data-level="2.1.9" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo-para-el-histograma"><i class="fa fa-check"></i><b>2.1.9</b> Ancho de banda óptimo para el histograma</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#estimación-de-densidades-basada-en-kernels."><i class="fa fa-check"></i><b>2.2</b> Estimación de densidades basada en kernels.</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#primera-construcción"><i class="fa fa-check"></i><b>2.2.1</b> Primera construcción</a></li>
<li class="chapter" data-level="2.2.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#otra-construcción"><i class="fa fa-check"></i><b>2.2.2</b> Otra construcción</a></li>
<li class="chapter" data-level="2.2.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas-2"><i class="fa fa-check"></i><b>2.2.3</b> Propiedades Estadísticas</a></li>
<li class="chapter" data-level="2.2.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#sesgo-1"><i class="fa fa-check"></i><b>2.2.4</b> Sesgo</a></li>
<li class="chapter" data-level="2.2.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio-y-error-cuadrático-medio-integrado"><i class="fa fa-check"></i><b>2.2.5</b> Error cuadrático medio y Error cuadrático medio integrado</a></li>
<li class="chapter" data-level="2.2.6" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo"><i class="fa fa-check"></i><b>2.2.6</b> Ancho de banda óptimo</a></li>
<li class="chapter" data-level="2.2.7" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#intervalos-de-confianza-para-estimadores-de-densidad-no-paramétricos"><i class="fa fa-check"></i><b>2.2.7</b> Intervalos de confianza para estimadores de densidad no paramétricos</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#laboratorio"><i class="fa fa-check"></i><b>2.3</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#efecto-de-distintos-kernels-en-la-estimación"><i class="fa fa-check"></i><b>2.3.1</b> Efecto de distintos Kernels en la estimación</a></li>
<li class="chapter" data-level="2.3.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#efecto-del-ancho-de-banda-en-la-estimación"><i class="fa fa-check"></i><b>2.3.2</b> Efecto del ancho de banda en la estimación</a></li>
<li class="chapter" data-level="2.3.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo-1"><i class="fa fa-check"></i><b>2.3.3</b> Ancho de banda óptimo</a></li>
<li class="chapter" data-level="2.3.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#validación-cruzada-1"><i class="fa fa-check"></i><b>2.3.4</b> Validación cruzada</a></li>
<li class="chapter" data-level="2.3.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#temas-adicionales"><i class="fa fa-check"></i><b>2.3.5</b> Temas adicionales</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ejercicios"><i class="fa fa-check"></i><b>2.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html"><i class="fa fa-check"></i><b>3</b> Jackknife y Bootstrap</a>
<ul>
<li class="chapter" data-level="3.1" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#caso-concreto"><i class="fa fa-check"></i><b>3.1</b> Caso concreto</a></li>
<li class="chapter" data-level="3.2" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#jackknife"><i class="fa fa-check"></i><b>3.2</b> Jackknife</a></li>
<li class="chapter" data-level="3.3" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#bootstrap"><i class="fa fa-check"></i><b>3.3</b> Bootstrap</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>3.3.1</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="3.3.2" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#resumiendo"><i class="fa fa-check"></i><b>3.3.2</b> Resumiendo</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#ejercicios-1"><i class="fa fa-check"></i><b>3.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html"><i class="fa fa-check"></i><b>4</b> Métodos lineales de regresión</a>
<ul>
<li class="chapter" data-level="4.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#introducción-al-aprendizaje-estadístico."><i class="fa fa-check"></i><b>4.1</b> Introducción al Aprendizaje Estadístico.</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#formas-de-estimar-f"><i class="fa fa-check"></i><b>4.1.1</b> Formas de estimar <span class="math inline">\(f\)</span></a></li>
<li class="chapter" data-level="4.1.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#medidas-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>4.1.2</b> Medidas de bondad de ajuste</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#regresión-lineal"><i class="fa fa-check"></i><b>4.2</b> Regresión lineal</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#forma-matricial"><i class="fa fa-check"></i><b>4.2.1</b> Forma matricial</a></li>
<li class="chapter" data-level="4.2.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-1"><i class="fa fa-check"></i><b>4.2.2</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#propiedades-estadísticas-3"><i class="fa fa-check"></i><b>4.3</b> Propiedades estadísticas</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#prueba-t"><i class="fa fa-check"></i><b>4.3.1</b> Prueba <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="4.3.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#prueba-f"><i class="fa fa-check"></i><b>4.3.2</b> Prueba <span class="math inline">\(F\)</span></a></li>
<li class="chapter" data-level="4.3.3" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-2"><i class="fa fa-check"></i><b>4.3.3</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#medida-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>4.4</b> Medida de bondad de ajuste</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-3"><i class="fa fa-check"></i><b>4.4.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#predicción"><i class="fa fa-check"></i><b>4.5</b> Predicción</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-4"><i class="fa fa-check"></i><b>4.5.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#interacciones"><i class="fa fa-check"></i><b>4.6</b> Interacciones</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-5"><i class="fa fa-check"></i><b>4.6.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#supuestos"><i class="fa fa-check"></i><b>4.7</b> Supuestos</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#chequeos-básicos-de-las-hipótesis-de-regresión-lineal"><i class="fa fa-check"></i><b>4.7.1</b> Chequeos básicos de las hipótesis de regresión lineal</a></li>
<li class="chapter" data-level="4.7.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#otros-chequeos-importantes"><i class="fa fa-check"></i><b>4.7.2</b> Otros chequeos importantes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#ejercicios-2"><i class="fa fa-check"></i><b>4.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html"><i class="fa fa-check"></i><b>5</b> Regresión Logística</a>
<ul>
<li class="chapter" data-level="5.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#preliminares"><i class="fa fa-check"></i><b>5.1</b> Preliminares</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#oportunidad-relativa-odds-ratio"><i class="fa fa-check"></i><b>5.1.1</b> Oportunidad relativa (Odds Ratio)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#máxima-verosimilitud"><i class="fa fa-check"></i><b>5.2</b> Máxima verosimilitud</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#resultados-adicionales"><i class="fa fa-check"></i><b>5.2.1</b> Resultados adicionales</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#diágnosticos-del-modelo"><i class="fa fa-check"></i><b>5.3</b> Diágnosticos del modelo</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#supuesto-de-linealidad"><i class="fa fa-check"></i><b>5.3.1</b> Supuesto de linealidad</a></li>
<li class="chapter" data-level="5.3.2" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#valores-de-gran-influencia"><i class="fa fa-check"></i><b>5.3.2</b> Valores de gran influencia</a></li>
<li class="chapter" data-level="5.3.3" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#multicolinealidad-1"><i class="fa fa-check"></i><b>5.3.3</b> Multicolinealidad</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#predicción-y-poder-de-clasificación"><i class="fa fa-check"></i><b>5.4</b> Predicción y poder de clasificación</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#curva-roc"><i class="fa fa-check"></i><b>5.4.1</b> Curva ROC</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#ejercicios-3"><i class="fa fa-check"></i><b>5.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html"><i class="fa fa-check"></i><b>6</b> Métodos de selección de variables y regularización.</a>
<ul>
<li class="chapter" data-level="6.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#estimación-del-error-de-prueba"><i class="fa fa-check"></i><b>6.1</b> Estimación del error de prueba</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#técnica-de-conjunto-de-validación"><i class="fa fa-check"></i><b>6.1.1</b> Técnica de conjunto de validación</a></li>
<li class="chapter" data-level="6.1.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-leave-one-out-loocv"><i class="fa fa-check"></i><b>6.1.2</b> Validación cruzada “Leave-One-Out” (LOOCV)</a></li>
<li class="chapter" data-level="6.1.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-k-veces"><i class="fa fa-check"></i><b>6.1.3</b> Validación cruzada <span class="math inline">\(k-\)</span>veces</a></li>
<li class="chapter" data-level="6.1.4" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-para-clasificación"><i class="fa fa-check"></i><b>6.1.4</b> Validación cruzada para clasificación</a></li>
<li class="chapter" data-level="6.1.5" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#otras-medidas-de-error-de-prueba"><i class="fa fa-check"></i><b>6.1.5</b> Otras medidas de error de prueba</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-variables"><i class="fa fa-check"></i><b>6.2</b> Selección de variables</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-del-mejor-subconjunto."><i class="fa fa-check"></i><b>6.2.1</b> Selección del mejor subconjunto.</a></li>
<li class="chapter" data-level="6.2.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-modelos-hacia-adelante-forward-stepwise-selection"><i class="fa fa-check"></i><b>6.2.2</b> Selección de modelos hacia adelante (<strong>Forward Stepwise Selection</strong>)</a></li>
<li class="chapter" data-level="6.2.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-modelos-hacia-atrás-backward-stepwise-selection"><i class="fa fa-check"></i><b>6.2.3</b> Selección de modelos hacia atrás (<strong>Backward Stepwise Selection</strong>)</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#métodos-de-regularización"><i class="fa fa-check"></i><b>6.3</b> Métodos de regularización</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-ridge"><i class="fa fa-check"></i><b>6.3.1</b> Regresión Ridge</a></li>
<li class="chapter" data-level="6.3.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-lasso"><i class="fa fa-check"></i><b>6.3.2</b> Regresión Lasso</a></li>
<li class="chapter" data-level="6.3.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#explicación-gráfica"><i class="fa fa-check"></i><b>6.3.3</b> Explicación gráfica</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#laboratorio-6"><i class="fa fa-check"></i><b>6.4</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#cross-validation"><i class="fa fa-check"></i><b>6.4.1</b> Cross-Validation</a></li>
<li class="chapter" data-level="6.4.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-lasso-1"><i class="fa fa-check"></i><b>6.4.2</b> Regresión Lasso</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#ejercicios-4"><i class="fa fa-check"></i><b>6.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="08-clasificacion.html"><a href="08-clasificacion.html"><i class="fa fa-check"></i><b>7</b> Otros Clasificadores</a>
<ul>
<li class="chapter" data-level="7.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#clasificador-bayesiano"><i class="fa fa-check"></i><b>7.1</b> Clasificador Bayesiano</a></li>
<li class="chapter" data-level="7.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#método-de-k-vecinos-más-cercanos-knn"><i class="fa fa-check"></i><b>7.2</b> Método de k vecinos más cercanos (KNN)</a></li>
<li class="chapter" data-level="7.3" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante"><i class="fa fa-check"></i><b>7.3</b> Análisis Discriminante</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-lineal"><i class="fa fa-check"></i><b>7.3.1</b> Análisis discriminante lineal</a></li>
<li class="chapter" data-level="7.3.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-cuadrático"><i class="fa fa-check"></i><b>7.3.2</b> Análisis discriminante cuadrático</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="08-clasificacion.html"><a href="08-clasificacion.html#estimación-de-la-curva-roc"><i class="fa fa-check"></i><b>7.4</b> Estimación de la Curva ROC</a></li>
<li class="chapter" data-level="7.5" data-path="08-clasificacion.html"><a href="08-clasificacion.html#laboratorio-7"><i class="fa fa-check"></i><b>7.5</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#clasificador-logístico"><i class="fa fa-check"></i><b>7.5.1</b> Clasificador logístico</a></li>
<li class="chapter" data-level="7.5.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-lineal-1"><i class="fa fa-check"></i><b>7.5.2</b> Análisis Discriminante Lineal</a></li>
<li class="chapter" data-level="7.5.3" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-cuadrático-1"><i class="fa fa-check"></i><b>7.5.3</b> Análisis Discriminante Cuadrático</a></li>
<li class="chapter" data-level="7.5.4" data-path="08-clasificacion.html"><a href="08-clasificacion.html#k-vecinos-más-cercanos"><i class="fa fa-check"></i><b>7.5.4</b> K vecinos más cercanos</a></li>
<li class="chapter" data-level="7.5.5" data-path="08-clasificacion.html"><a href="08-clasificacion.html#máquinas-de-soporte-vectorial"><i class="fa fa-check"></i><b>7.5.5</b> Máquinas de soporte vectorial</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="08-clasificacion.html"><a href="08-clasificacion.html#ejercicios-5"><i class="fa fa-check"></i><b>7.6</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html"><i class="fa fa-check"></i><b>8</b> Análisis en componentes principales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#aprendizaje-no-supervisado"><i class="fa fa-check"></i><b>8.1</b> Aprendizaje no-supervisado</a></li>
<li class="chapter" data-level="8.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#representación-gráfica"><i class="fa fa-check"></i><b>8.2</b> Representación gráfica</a></li>
<li class="chapter" data-level="8.3" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#primer-componente-principal"><i class="fa fa-check"></i><b>8.3</b> Primer componente principal</a></li>
<li class="chapter" data-level="8.4" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#segunda-componente-principal"><i class="fa fa-check"></i><b>8.4</b> Segunda componente principal</a></li>
<li class="chapter" data-level="8.5" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#circulo-de-correlaciones"><i class="fa fa-check"></i><b>8.5</b> Circulo de correlaciones</a></li>
<li class="chapter" data-level="8.6" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#volvamos-a-nuestro-ejemplo"><i class="fa fa-check"></i><b>8.6</b> Volvamos a nuestro ejemplo</a></li>
<li class="chapter" data-level="8.7" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#cuántos-componentes-usar"><i class="fa fa-check"></i><b>8.7</b> ¿Cuántos componentes usar?</a></li>
<li class="chapter" data-level="8.8" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#laboratorio-8"><i class="fa fa-check"></i><b>8.8</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#modelo-de-más-de-un-parámetro"><i class="fa fa-check"></i><b>8.8.1</b> Modelo de más de un parámetro</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#motivación-cálculo-de-integrales"><i class="fa fa-check"></i><b>8.9</b> Motivación: Cálculo de Integrales</a></li>
<li class="chapter" data-level="8.10" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejemplo-base-modelo-beta-binomial."><i class="fa fa-check"></i><b>8.10</b> Ejemplo base: modelo beta-binomial.</a></li>
<li class="chapter" data-level="8.11" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#aproximación-de-laplace"><i class="fa fa-check"></i><b>8.11</b> Aproximación de Laplace</a></li>
<li class="chapter" data-level="8.12" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#simulación"><i class="fa fa-check"></i><b>8.12</b> Simulación</a>
<ul>
<li class="chapter" data-level="8.12.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#simulación-monte-carlo"><i class="fa fa-check"></i><b>8.12.1</b> Simulación Monte Carlo</a></li>
<li class="chapter" data-level="8.12.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#muestreo-por-rechazo"><i class="fa fa-check"></i><b>8.12.2</b> Muestreo por rechazo</a></li>
</ul></li>
<li class="chapter" data-level="8.13" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#muestreo-por-importancia"><i class="fa fa-check"></i><b>8.13</b> Muestreo por importancia</a></li>
<li class="chapter" data-level="8.14" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#remuestreo-por-importancia"><i class="fa fa-check"></i><b>8.14</b> Remuestreo por importancia</a></li>
<li class="chapter" data-level="8.15" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#algoritmo-de-metropolis-hastings"><i class="fa fa-check"></i><b>8.15</b> Algoritmo de Metropolis-Hastings</a></li>
<li class="chapter" data-level="8.16" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#algoritmo-de-gibbs"><i class="fa fa-check"></i><b>8.16</b> Algoritmo de Gibbs</a>
<ul>
<li class="chapter" data-level="8.16.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#diagnósticos-de-convergencia-de-mcmc"><i class="fa fa-check"></i><b>8.16.1</b> Diagnósticos de convergencia de MCMC</a></li>
</ul></li>
<li class="chapter" data-level="8.17" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejemplos"><i class="fa fa-check"></i><b>8.17</b> Ejemplos</a>
<ul>
<li class="chapter" data-level="8.17.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#datos-agrupados-bajo-una-población-normal"><i class="fa fa-check"></i><b>8.17.1</b> Datos agrupados bajo una población normal</a></li>
</ul></li>
<li class="chapter" data-level="8.18" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejercicios-6"><i class="fa fa-check"></i><b>8.18</b> Ejercicios</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notas Curso de Estadística II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="análisis-en-componentes-principales" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Capítulo 8</span> Análisis en componentes principales<a href="09-calculo-bayes.html#análisis-en-componentes-principales" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="aprendizaje-no-supervisado" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Aprendizaje no-supervisado<a href="09-calculo-bayes.html#aprendizaje-no-supervisado" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Al contrario de los métodos que se han estudiado de regresión y clasificación, en este caso no hay variable dependiente, y el conjunto de datos está compuesto de <span class="math inline">\(p\)</span> variables o características y <span class="math inline">\(n\)</span> observaciones.</p>
<p>El principal objetivo del aprendizaje no-supervisado no es la predicción, sino en el <em>análisis de datos</em> por sí mismo, es decir se quiere buscar patrones o relaciones interesantes dentro de la tabla de datos: por ejemplo la visualización de datos o la identificación de subgrupos en los datos. (Análisis Exploratorio de Datos)</p>
<p>En el caso de aprendizaje no-supervisado, no es posible verificar o validar los métodos adoptados.</p>
<p>Si se quiere seleccionar la mejor proyección de 2 variables de una nube de puntos <span class="math inline">\(X_1,\dots, X_p\)</span>, se debe hacer <span class="math inline">\(\binom{p}{2}\)</span> gráficos de dispersión. Un criterio de búsqueda es seleccionar la que tenga mayor información, en el sentido de mayor variabilidad.</p>
<p>Usaremos como base los libros de <span class="citation">(Husson, Le, and Pagès 2017)</span> y <span class="citation">(James et al. 2013)</span>.</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="09-calculo-bayes.html#cb509-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rgl)</span>
<span id="cb509-2"><a href="09-calculo-bayes.html#cb509-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb509-3"><a href="09-calculo-bayes.html#cb509-3" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>knit_hooks<span class="sc">$</span><span class="fu">set</span>(<span class="at">webgl =</span> hook_webgl, <span class="at">rgl =</span> hook_rgl)</span>
<span id="cb509-4"><a href="09-calculo-bayes.html#cb509-4" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">fig.pos =</span> <span class="st">&quot;!h&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb510"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb510-1"><a href="09-calculo-bayes.html#cb510-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb510-2"><a href="09-calculo-bayes.html#cb510-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb510-3"><a href="09-calculo-bayes.html#cb510-3" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">cos</span>(<span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="dv">0</span>, <span class="dv">2</span>))</span>
<span id="cb510-4"><a href="09-calculo-bayes.html#cb510-4" aria-hidden="true" tabindex="-1"></a>x3 <span class="ot">&lt;-</span> x1 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="dv">0</span>, <span class="dv">2</span>)</span></code></pre></div>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb511-1"><a href="09-calculo-bayes.html#cb511-1" aria-hidden="true" tabindex="-1"></a>GGally<span class="sc">::</span><span class="fu">ggpairs</span>(<span class="fu">data.frame</span>(x1, x2, x3))</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-284-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb512-1"><a href="09-calculo-bayes.html#cb512-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot3d</span>(x1, x2, x3, <span class="at">point.col =</span> <span class="st">&quot;black&quot;</span>)</span>
<span id="cb512-2"><a href="09-calculo-bayes.html#cb512-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb512-3"><a href="09-calculo-bayes.html#cb512-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot3d</span>(<span class="fu">scale</span>(x1), <span class="fu">scale</span>(x2), <span class="fu">scale</span>(x3), <span class="at">point.col =</span> <span class="st">&quot;black&quot;</span>)</span></code></pre></div>
<div id="rgl16375" style="width:672px;height:415.296px;" class="rglWebGL html-widget"></div>
<script type="application/json" data-for="rgl16375">{"x":{"material":{"color":"#000000","alpha":1,"lit":true,"ambient":"#000000","specular":"#FFFFFF","emission":"#000000","shininess":50,"smooth":true,"front":"filled","back":"filled","size":3,"lwd":1,"fog":true,"point_antialias":false,"line_antialias":false,"texture":null,"textype":"rgb","texmipmap":false,"texminfilter":"linear","texmagfilter":"linear","texenvmap":false,"depth_mask":true,"depth_test":"less","isTransparent":false,"polygon_offset":[0,0],"margin":"","floating":false,"tag":""},"rootSubscene":7,"objects":{"18":{"id":18,"type":"points","material":{"lit":false},"vertices":"0","colors":"1","centers":"2","ignoreExtent":false,"flags":34816},"20":{"id":20,"type":"text","material":{"lit":false,"margin":0,"floating":true,"edge":[0,1,1]},"vertices":"3","colors":"4","texts":[["scale(x1)"]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"5","family":[["sans"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"21":{"id":21,"type":"text","material":{"lit":false,"margin":1,"floating":true,"edge":[1,1,1]},"vertices":"6","colors":"7","texts":[["scale(x2)"]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"8","family":[["sans"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"22":{"id":22,"type":"text","material":{"lit":false,"margin":2,"floating":true,"edge":[1,1,1]},"vertices":"9","colors":"10","texts":[["scale(x3)"]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"11","family":[["sans"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"11":{"id":11,"type":"light","vertices":[[0,0,1]],"colors":[[1,1,1,1],[1,1,1,1],[1,1,1,1]],"viewpoint":true,"finite":false},"12":{"id":12,"type":"background","material":{"lit":false,"back":"lines"},"colors":"12","centers":"13","sphere":false,"fogtype":"none","fogscale":1,"flags":32768},"19":{"id":19,"type":"bboxdeco","material":{"front":"lines","back":"lines"},"vertices":"14","colors":"15","axes":{"mode":["pretty","pretty","pretty"],"step":[1,0.5,1],"nticks":[5,5,5],"marklen":[15,15,15],"expand":[1.02999997138977,1.02999997138977,1.02999997138977]},"draw_front":true,"flags":32769},"7":{"id":7,"type":"subscene","par3d":{"antialias":16,"FOV":30,"ignoreExtent":false,"listeners":7,"mouseMode":{"none":"none","left":"trackball","right":"zoom","middle":"fov","wheel":"pull"},"observer":[0,0,23.0897235870361],"modelMatrix":[[0.89286595582962,0,0,-0.179622709751129],[0,0.650618433952332,0.775235176086426,0.106937266886234],[0,-1.78755950927734,0.282162547111511,-23.3791122436523],[0,0,0,1]],"projMatrix":[[3.73205065727234,0,0,0],[0,3.73205065727234,0,0],[0,0,-3.86370277404785,-83.2357711791992],[0,0,-1,0]],"skipRedraw":false,"userMatrix":[[1,0,0,0],[0,0.342020143325668,0.939692620785909,0],[0,-0.939692620785909,0.342020143325668,0],[0,0,0,1]],"userProjection":[[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],"scale":[0.89286595582962,1.9022810459137,0.824988067150116],"viewport":{"x":0,"y":0,"width":1,"height":1},"zoom":1,"bbox":[-2.84956836700439,3.25191926956177,-1.59409487247467,1.26973569393158,-3.30358290672302,3.29991912841797],"windowRect":[0,45,256,301],"family":"sans","font":1,"cex":1,"useFreeType":true,"fontname":"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/rgl/fonts/FreeSans.ttf","maxClipPlanes":6,"glVersion":2.1,"activeSubscene":0},"embeddings":{"viewport":"replace","projection":"replace","model":"replace","mouse":"replace"},"objects":[12,19,18,20,21,22,11],"subscenes":[],"flags":36113}},"crosstalk":{"key":[],"group":[],"id":[],"options":[]},"width":672,"height":415.296,"context":{"shiny":false,"rmarkdown":null},"buffer":{"accessors":[{"bufferView":0,"componentType":5126,"count":1000,"type":"VEC3"},{"bufferView":1,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":2,"componentType":5126,"count":1000,"type":"VEC3"},{"bufferView":3,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":4,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":5,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":6,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":7,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":8,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":9,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":10,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":11,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":12,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":13,"componentType":5121,"count":1,"type":"VEC3"},{"bufferView":14,"componentType":5126,"count":19,"type":"VEC3"},{"bufferView":15,"componentType":5121,"count":1,"type":"VEC4"}],"bufferViews":[{"buffer":0,"byteLength":12000,"byteOffset":0},{"buffer":0,"byteLength":4,"byteOffset":12000},{"buffer":0,"byteLength":12000,"byteOffset":12004},{"buffer":0,"byteLength":12,"byteOffset":24004},{"buffer":0,"byteLength":4,"byteOffset":24016},{"buffer":0,"byteLength":12,"byteOffset":24020},{"buffer":0,"byteLength":12,"byteOffset":24032},{"buffer":0,"byteLength":4,"byteOffset":24044},{"buffer":0,"byteLength":12,"byteOffset":24048},{"buffer":0,"byteLength":12,"byteOffset":24060},{"buffer":0,"byteLength":4,"byteOffset":24072},{"buffer":0,"byteLength":12,"byteOffset":24076},{"buffer":0,"byteLength":4,"byteOffset":24088},{"buffer":0,"byteLength":3,"byteOffset":24092},{"buffer":0,"byteLength":228,"byteOffset":24096},{"buffer":0,"byteLength":4,"byteOffset":24324}],"buffers":[{"byteLength":24328,"bytes":"wNgUv1NCP7+INEa/MlR+vpEvXL+vOf87lxrHP2Booj8zfD0/pptgPcoonD8KE3A/NrHpPbUu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\nAADAfwAAwH8AAABAAADAfwAAwH8AAEBAAAAAAQ=="}]},"players":[],"webGLoptions":{"preserveDrawingBuffer":true}},"evals":[],"jsHooks":[]}</script>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-286-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<!-- ```{r, echo=FALSE} -->
<!-- library(ggplot2) -->
<!-- qplot(1:300, rnorm(300, sd = 0.1) + 5, ylim = c(0, 10)) + theme_minimal() + xlab("") + ylab("") -->
<!-- qplot(1:300, (3 * 1:300 + 100 * cos(1:300 / (2 * pi)) + 200 * rnorm(300, sd = -->
<!--                                                                       0.1)) / 100) + theme_minimal() + xlab("") + ylab("") -->
<!-- ``` -->
<p>El ACP lo que busca es un número reducido de dimensión que represente el máximo de variabilidad en las observaciones eliminando la mayor cantidad de ruido posible.</p>
</div>
<div id="representación-gráfica" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Representación gráfica<a href="09-calculo-bayes.html#representación-gráfica" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="figure">
<img src="manual_figures/pca.png" alt="" />
<p class="caption">Tomado de <a href="https://shapeofdata.wordpress.com/2013/04/09/principle-component-analysis/">The shape of data</a></p>
</div>
</div>
<div id="primer-componente-principal" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Primer componente principal<a href="09-calculo-bayes.html#primer-componente-principal" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><span class="math display">\[ Z_1 := \phi_{11}x_1 +  \phi_{21}x_2 + \dots + \phi_{p1}x_p;\quad \text{con } \sum_{j=1}^{p}\phi_{j1} = 1\]</span>
tal que <span class="math inline">\(Z_1\)</span> tenga la varianza máxima.</p>
<p>Al vector <span class="math inline">\(\phi_1 = (\phi_{11}, \phi_{21},\dots,\phi_{p1})\)</span> se le llama <em>pasos o cargas</em>.</p>
<p><span class="math inline">\(X = (X_1,\dots,X_p)_{n\times p}\)</span> es la <em>matriz de diseño</em> donde cada columna tiene media 0. Se resuelve el problema
<span class="math display">\[\hat{\phi}_1=\underset{\Vert\phi_1\Vert_2^2=1}{\mathrm{argmax}} \left\lbrace\dfrac{1}{n}\sum_{i=1}^{n}\left(\sum_{i=1}^p \phi_{j1} X_{ij} \right)^2 \right\rbrace \]</span>
La restricción de minimización se puede rescribir como <span class="math inline">\(\Vert\phi_1\Vert_2^2= \sum_{j=1}^p \phi_{j1}^2 = 1\)</span></p>
<p>Los <span class="math inline">\(Z_{11},\dots, Z_{n1}\)</span> son los scores del primer componente principal.</p>
<p><span class="math inline">\(\phi_1\)</span> es la dirección en el espacio característico en <span class="math inline">\(\mathbb{R}^p\)</span> en donde los datos tengan la máxima varianza.</p>
<p>Esta última expresión se podría rescribir de forma matricial como</p>
<p><span class="math display">\[
\hat{\phi}_1 = \underset{\Vert\phi_1\Vert_2^2=1}{\mathrm{argmax}} \left\{ \phi_1^\top X^\top X \phi_1 \right\}
\]</span></p>
<p>donde <span class="math inline">\(\phi_1 = (\phi_{11}, \phi_{21},\dots,\phi_{p1})\)</span></p>
<p>dadas las condiciones, esta expresión se podría simplificar un poco más en</p>
<p><span class="math display">\[
\hat{\phi}_1 = \underset{\phi_1}{\mathrm{argmax}} \left\{\frac{\phi_1^\top X^\top X \phi_1 }{\phi_1^\top \phi_1}\right\}
\]</span></p>
<p>Dado que la expresión anterio es un coeficiente de Rayleigh, se puede probar que <span class="math inline">\(\hat{\phi}_{1}\)</span> corresponde al primer vector propio de la matriz <span class="math inline">\(X^\top X = \mathrm{Cov}(X)\)</span> si las columnas de <span class="math inline">\(X\)</span> son centradas.</p>
</div>
<div id="segunda-componente-principal" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> Segunda componente principal<a href="09-calculo-bayes.html#segunda-componente-principal" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><span class="math display">\[ Z_{2}:= \phi_{12}x_1 + \phi_{22}x_2+\dots+\phi_{p2}x_p\]</span>
<span class="math display">\[\underset{\Vert\phi_2\Vert_2^2=1}{\mathrm{argmax}} \left\lbrace\dfrac{1}{n}\sum_{i=1}^{n}\left(\sum_{i=1}^p \phi_{j2} X_{ij} \right)^2 \right\rbrace\]</span>
Se tiene, además, que <span class="math inline">\(\forall i\)</span>, <span class="math inline">\(Z_{i2}\perp Z_1\)</span>, entonces
<span class="math display">\[ Z_{i2}\perp Z_1 \implies \phi_{2} \perp \phi_{1}\]</span></p>
<p>Esto se logra primero construyendo una matriz nueva de diseño, restando a la matrix <span class="math inline">\(X\)</span> original, el primer componente principal.</p>
<p><span class="math display">\[
\tilde{X}_2 = X - X\phi_1\phi_1^\top
\]</span></p>
<p>Luego a esa matriz, se le aplica el procedimiento anterior</p>
<p><span class="math display">\[
\hat{\phi}_2 = \underset{\phi_2}{\mathrm{argmax}} \left\{\frac{\phi_2^\top X^\top X \phi_2 }{\phi_2^\top \phi_2}\right\}
\]</span></p>
<p>Y nuevamente se puede probar que el componente principal corresponde al segundo vector propio de
<span class="math inline">\(X^\top X = \mathrm{Cov}(X)\)</span></p>
<p>De la misma forma se construye <span class="math inline">\(\phi_3,\phi_4,\dots, \phi_p\)</span>.</p>
<p>Notas:</p>
<ul>
<li><strong>Escalas</strong>: la varianza de las variables depende de las unidades. El problema es que los pesos <span class="math inline">\(\phi_i\)</span> son distintos dependiendo de las escalas. La solución es estandarizar las variables: <span class="math inline">\(\dfrac{X_i-\mu_i}{\hat\sigma_i}\)</span>.</li>
<li><strong>Unicidad</strong>: los componentes principales son únicos, módulo cambio de signo.
\end{itemize}</li>
</ul>
</div>
<div id="circulo-de-correlaciones" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> Circulo de correlaciones<a href="09-calculo-bayes.html#circulo-de-correlaciones" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Se puede construir la correlación de cada variable con respecto a cada componente principal</p>
<p><span class="math display">\[
cos(\theta_{i,j^\prime}) = \mathrm{Corr}(X_i, \mathrm{PC}_{j^\prime})
\]</span></p>
<p>El ángulo <span class="math inline">\(\theta_{i,j^\prime}\)</span> significa la lejanía o cercanía de cierta variable con respecto a cada componente principal.</p>
<p>Además, basados en el el círculo identidad <span class="math inline">\(\cos^2(\theta)+\sin^2(\theta)=1\)</span>, el valor de <span class="math inline">\(cos^2(\theta_{i,j^\prime})\)</span> representa la “intensidad” con la cual la variable <span class="math inline">\(X_i\)</span> es representada por el componente principal <span class="math inline">\(\mathrm{PC}_{i^\prime}\)</span>.</p>
</div>
<div id="volvamos-a-nuestro-ejemplo" class="section level2 hasAnchor" number="8.6">
<h2><span class="header-section-number">8.6</span> Volvamos a nuestro ejemplo<a href="09-calculo-bayes.html#volvamos-a-nuestro-ejemplo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb513"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb513-1"><a href="09-calculo-bayes.html#cb513-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;factoextra&quot;</span>)</span>
<span id="cb513-2"><a href="09-calculo-bayes.html#cb513-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;FactoMineR&quot;</span>)</span>
<span id="cb513-3"><a href="09-calculo-bayes.html#cb513-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">PCA</span>(<span class="fu">scale</span>(<span class="fu">cbind</span>(x1, x2, x3)))</span></code></pre></div>
<div class="sourceCode" id="cb514"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb514-1"><a href="09-calculo-bayes.html#cb514-1" aria-hidden="true" tabindex="-1"></a>p<span class="sc">$</span>var<span class="sc">$</span>cor</span></code></pre></div>
<pre><code>##          Dim.1       Dim.2       Dim.3
## x1  0.92280569 0.037753401 -0.38341145
## x2 -0.03690606 0.999225664  0.01363871
## x3  0.92346176 0.002207375  0.38368413</code></pre>
<div class="sourceCode" id="cb516"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb516-1"><a href="09-calculo-bayes.html#cb516-1" aria-hidden="true" tabindex="-1"></a>p<span class="sc">$</span>var<span class="sc">$</span>cos2</span></code></pre></div>
<pre><code>##          Dim.1        Dim.2        Dim.3
## x1 0.851570337 1.425319e-03 0.1470043434
## x2 0.001362057 9.984519e-01 0.0001860145
## x3 0.852781615 4.872503e-06 0.1472135129</code></pre>
</div>
<div id="cuántos-componentes-usar" class="section level2 hasAnchor" number="8.7">
<h2><span class="header-section-number">8.7</span> ¿Cuántos componentes usar?<a href="09-calculo-bayes.html#cuántos-componentes-usar" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb518-1"><a href="09-calculo-bayes.html#cb518-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_screeplot</span>(p, <span class="at">addlabels =</span> F, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">50</span>)) <span class="sc">+</span></span>
<span id="cb518-2"><a href="09-calculo-bayes.html#cb518-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">xlab</span>(<span class="st">&quot;Variables&quot;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;Porcentaje de varianza de Z explicada&quot;</span>) <span class="sc">+</span></span>
<span id="cb518-3"><a href="09-calculo-bayes.html#cb518-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Diagrama&quot;</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-289-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb519"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb519-1"><a href="09-calculo-bayes.html#cb519-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qplot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, p<span class="sc">$</span>eig[, <span class="dv">3</span>], <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;Cantidad de componentes&quot;</span>) <span class="sc">+</span></span>
<span id="cb519-2"><a href="09-calculo-bayes.html#cb519-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylab</span>(<span class="st">&quot;Varianza acumulada&quot;</span>) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb519-3"><a href="09-calculo-bayes.html#cb519-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">80</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span> <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-290-1.svg" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="laboratorio-8" class="section level2 hasAnchor" number="8.8">
<h2><span class="header-section-number">8.8</span> Laboratorio<a href="09-calculo-bayes.html#laboratorio-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Vamos a usar los datos <code>decathlon</code> de <code>FactomineR</code> que representa los resultados de varios atletas en pruebas de decathlon en el 2004.</p>
<p>El objetivo es encontrar si hay patrones entre ciudad y tipos de crimen.</p>
<p>Exploración de datos
Ejecute una exploración de datos</p>
<pre><code>##       100m         Long.jump       Shot.put       High.jump          400m      
##  Min.   :10.44   Min.   :6.61   Min.   :12.68   Min.   :1.850   Min.   :46.81  
##  1st Qu.:10.85   1st Qu.:7.03   1st Qu.:13.88   1st Qu.:1.920   1st Qu.:48.93  
##  Median :10.98   Median :7.30   Median :14.57   Median :1.950   Median :49.40  
##  Mean   :11.00   Mean   :7.26   Mean   :14.48   Mean   :1.977   Mean   :49.62  
##  3rd Qu.:11.14   3rd Qu.:7.48   3rd Qu.:14.97   3rd Qu.:2.040   3rd Qu.:50.30  
##  Max.   :11.64   Max.   :7.96   Max.   :16.36   Max.   :2.150   Max.   :53.20  
##   110m.hurdle        Discus        Pole.vault       Javeline    
##  Min.   :13.97   Min.   :37.92   Min.   :4.200   Min.   :50.31  
##  1st Qu.:14.21   1st Qu.:41.90   1st Qu.:4.500   1st Qu.:55.27  
##  Median :14.48   Median :44.41   Median :4.800   Median :58.36  
##  Mean   :14.61   Mean   :44.33   Mean   :4.762   Mean   :58.32  
##  3rd Qu.:14.98   3rd Qu.:46.07   3rd Qu.:4.920   3rd Qu.:60.89  
##  Max.   :15.67   Max.   :51.65   Max.   :5.400   Max.   :70.52  
##      1500m            Rank           Points       Competition
##  Min.   :262.1   Min.   : 1.00   Min.   :7313   Decastar:13  
##  1st Qu.:271.0   1st Qu.: 6.00   1st Qu.:7802   OlympicG:28  
##  Median :278.1   Median :11.00   Median :8021                
##  Mean   :279.0   Mean   :12.12   Mean   :8005                
##  3rd Qu.:285.1   3rd Qu.:18.00   3rd Qu.:8122                
##  Max.   :317.0   Max.   :28.00   Max.   :8893</code></pre>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-293-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-295-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb521"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb521-1"><a href="09-calculo-bayes.html#cb521-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(acp.decathlon<span class="sc">$</span>ind<span class="sc">$</span>coord[, <span class="dv">1</span>], acp.decathlon<span class="sc">$</span>ind<span class="sc">$</span>coord[,</span>
<span id="cb521-2"><a href="09-calculo-bayes.html#cb521-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span>])</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-296-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb522-1"><a href="09-calculo-bayes.html#cb522-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(acp.decathlon<span class="sc">$</span>ind<span class="sc">$</span>coord[, <span class="dv">3</span>], acp.decathlon<span class="sc">$</span>ind<span class="sc">$</span>coord[,</span>
<span id="cb522-2"><a href="09-calculo-bayes.html#cb522-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">4</span>])</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-296-2.svg" width="100%" style="display: block; margin: auto;" /></p>
<pre><code>
## Ejercicios 

- Del libro [@James2013b] 
    - Capítulo 10:  6, 8
`


&lt;!--chapter:end:07-componentes-principales.Rmd--&gt;


# Cálculo Bayesiano Computacional

## Repaso de Estadística Bayesiana

### Modelo de un parámetro

Vamos a considerar el ejemplo en la sección 3.3 del [@Albert2009]. En este caso se quiere estimar la tasa de éxito en transplantes de corazón en un hospital de EEUU. Suponga que en ese hospital hay $n$ transplantes y $y$ es el número de muertes en el transcurso de 30 días del transplante. Si se sabe el número esperado de muertes $e$ a través de un modelo auxiliar, entonces un modelo sencillo para $y$ es asumir que:
$$y\sim \text{Poisson}(e\lambda)$$
donde $\lambda$ es la tasa de mortalidad por unidad de exposición y tiempo.

Posible solución: estimar $\hat \lambda=y/e$, pero el estimador es malo si hay pocas muertes observadas $y$.

Solución bayesiana: Considere una previa conjugada (gamma) para $\lambda$:
$$p(\lambda)\propto \lambda^{\alpha-1}\exp(-\beta \lambda)$$
además, suponga que se cuenta con información externa de un grupo pequeño de hospitales con condiciones similares a la del hospital de interés, es decir se cuenta con muertes $z_j$ y exposición $o_j$ para diez hospitales ($j=1,\ldots,10$). Asuma que:
$$z_j\sim \text{Poisson}(o_j\lambda)$$
asignamos una previa no-informativa a $p(\lambda)\propto \lambda^{-1}$ y se obtiene un previa propuesta para $\lambda$:
$$p(\lambda)\propto \lambda^{\sum_{j=1}^{10}z_j-1}\exp{\left(-\lambda\sum_{j=1}^{10} o_j\right)}$$y
Suponga que $\alpha:=\sum z_j=16$ y $\beta:=\sum o_j=15174$. Si para el hospital de interés $y_{obs}$ es el número observado de muertes y $e$ es la exposición entonces la distribución posterior de $\lambda$ es:
$$g(\lambda|y_{obs})\sim \Gamma(\alpha+y_{obs},\beta+e)$$
y la densidad predictiva de $y$ es (Ejercicio):
$$f(y)=\frac{f(y|\lambda)p(\lambda)}{g(\lambda|y_{obs})}$$

donde $f(y|\lambda)\sim \text{Poisson}(e\lambda)$ (verosimilitud). Supongamos dos posibles hospitales:

- Hospital A: Se observa una muerte con 66 personas expuestas. Cálculo de la densidad posterior y densidad predictiva con $\lambda = \alpha/\beta$:


```r
alpha &lt;- 16
beta &lt;- 15174
yobs &lt;- 1
ex &lt;- 66
y &lt;- 0:10
lam &lt;- alpha/beta
fy &lt;- dpois(y, lam * ex) * dgamma(lam, shape = alpha,
    rate = beta)/dgamma(lam, shape = alpha + y, rate = beta +
    ex)

dpred &lt;- tibble(y, fy)
ggplot(dpred) + geom_line(mapping = aes(x = y, y = fy)) +
    geom_vline(xintercept = yobs, col = 2) + theme_bw()</code></pre>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-298-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>por lo tanto una muerte no es un valor inusual en el comportamiento de muertes bajo transplantes. La comparación de las densidades posterior y previa de lambda:</p>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb524-1"><a href="09-calculo-bayes.html#cb524-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb524-2"><a href="09-calculo-bayes.html#cb524-2" aria-hidden="true" tabindex="-1"></a>lambda_prev <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">1000</span>, <span class="at">shape =</span> alpha, <span class="at">rate =</span> beta)</span>
<span id="cb524-3"><a href="09-calculo-bayes.html#cb524-3" aria-hidden="true" tabindex="-1"></a>lambda_post <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">1000</span>, <span class="at">shape =</span> alpha <span class="sc">+</span> y, <span class="at">rate =</span> beta <span class="sc">+</span></span>
<span id="cb524-4"><a href="09-calculo-bayes.html#cb524-4" aria-hidden="true" tabindex="-1"></a>    ex)</span>
<span id="cb524-5"><a href="09-calculo-bayes.html#cb524-5" aria-hidden="true" tabindex="-1"></a>datoslambda <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">Previa =</span> lambda_prev, <span class="at">Posterior =</span> lambda_post) <span class="sc">%&gt;%</span></span>
<span id="cb524-6"><a href="09-calculo-bayes.html#cb524-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">everything</span>())</span>
<span id="cb524-7"><a href="09-calculo-bayes.html#cb524-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> datoslambda) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> value,</span>
<span id="cb524-8"><a href="09-calculo-bayes.html#cb524-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> name)) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-299-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<ul>
<li>Hospital B: 4 muertes en 1767 expuestos. Mismos cálculos:</li>
</ul>
<div class="sourceCode" id="cb525"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb525-1"><a href="09-calculo-bayes.html#cb525-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">16</span></span>
<span id="cb525-2"><a href="09-calculo-bayes.html#cb525-2" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="dv">15174</span></span>
<span id="cb525-3"><a href="09-calculo-bayes.html#cb525-3" aria-hidden="true" tabindex="-1"></a>yobs <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb525-4"><a href="09-calculo-bayes.html#cb525-4" aria-hidden="true" tabindex="-1"></a>ex <span class="ot">&lt;-</span> <span class="dv">1767</span></span>
<span id="cb525-5"><a href="09-calculo-bayes.html#cb525-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">10</span></span>
<span id="cb525-6"><a href="09-calculo-bayes.html#cb525-6" aria-hidden="true" tabindex="-1"></a>lam <span class="ot">&lt;-</span> alpha<span class="sc">/</span>beta</span>
<span id="cb525-7"><a href="09-calculo-bayes.html#cb525-7" aria-hidden="true" tabindex="-1"></a>fy <span class="ot">&lt;-</span> <span class="fu">dpois</span>(y, lam <span class="sc">*</span> ex) <span class="sc">*</span> <span class="fu">dgamma</span>(lam, <span class="at">shape =</span> alpha,</span>
<span id="cb525-8"><a href="09-calculo-bayes.html#cb525-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">rate =</span> beta)<span class="sc">/</span><span class="fu">dgamma</span>(lam, <span class="at">shape =</span> alpha <span class="sc">+</span> y, <span class="at">rate =</span> beta <span class="sc">+</span></span>
<span id="cb525-9"><a href="09-calculo-bayes.html#cb525-9" aria-hidden="true" tabindex="-1"></a>    ex)</span>
<span id="cb525-10"><a href="09-calculo-bayes.html#cb525-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb525-11"><a href="09-calculo-bayes.html#cb525-11" aria-hidden="true" tabindex="-1"></a>dpred <span class="ot">&lt;-</span> <span class="fu">tibble</span>(y, fy)</span>
<span id="cb525-12"><a href="09-calculo-bayes.html#cb525-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dpred) <span class="sc">+</span> <span class="fu">geom_line</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> y, <span class="at">y =</span> fy)) <span class="sc">+</span></span>
<span id="cb525-13"><a href="09-calculo-bayes.html#cb525-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> yobs, <span class="at">col =</span> <span class="dv">2</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-300-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb526-1"><a href="09-calculo-bayes.html#cb526-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb526-2"><a href="09-calculo-bayes.html#cb526-2" aria-hidden="true" tabindex="-1"></a>lambda_prev <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">1000</span>, <span class="at">shape =</span> alpha, <span class="at">rate =</span> beta)</span>
<span id="cb526-3"><a href="09-calculo-bayes.html#cb526-3" aria-hidden="true" tabindex="-1"></a>lambda_post <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">1000</span>, <span class="at">shape =</span> alpha <span class="sc">+</span> y, <span class="at">rate =</span> beta <span class="sc">+</span></span>
<span id="cb526-4"><a href="09-calculo-bayes.html#cb526-4" aria-hidden="true" tabindex="-1"></a>    ex)</span>
<span id="cb526-5"><a href="09-calculo-bayes.html#cb526-5" aria-hidden="true" tabindex="-1"></a>datoslambda <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">Previa =</span> lambda_prev, <span class="at">Posterior =</span> lambda_post) <span class="sc">%&gt;%</span></span>
<span id="cb526-6"><a href="09-calculo-bayes.html#cb526-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">everything</span>())</span>
<span id="cb526-7"><a href="09-calculo-bayes.html#cb526-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> datoslambda) <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> value,</span>
<span id="cb526-8"><a href="09-calculo-bayes.html#cb526-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> name)) <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>())</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-301-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div id="modelo-de-más-de-un-parámetro" class="section level3 hasAnchor" number="8.8.1">
<h3><span class="header-section-number">8.8.1</span> Modelo de más de un parámetro<a href="09-calculo-bayes.html#modelo-de-más-de-un-parámetro" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Se usará el ejemplo de la sección 4.2 del <span class="citation">(Albert et al. 2009)</span> para ilustrar la inferencia bayesiana conjugada en el caso de más un parámetro. Suponga que se tiene datos del tiempo en completar la maratón de Nueva York para 20 atletas entre 20 y 29 años y asumimos que la muestra proviene de una <span class="math inline">\(N(\mu,\sigma^2)\)</span>. Si asumimos la previa no informativa:</p>
<p><span class="math display">\[g(\mu,\sigma^2) \propto 1/\sigma^2\]</span></p>
<p>entonces la distribución posterior de <span class="math inline">\((\mu,\sigma^2)\)</span> es:
<span class="math display">\[g(\mu,\sigma^2|y)\propto \frac{1}{(\sigma^2)^{n/2+1}}\exp{\left(-\frac{1}{2\sigma^2}\left(S+n(\mu-\bar y)^2\right)\right)}\]</span></p>
<p>donde <span class="math inline">\(n\)</span> es el tamaño de muestra, <span class="math inline">\(\bar y\)</span> es la media empírica y <span class="math inline">\(S=\sum_{i=1}^n(y_i-\bar y)^2\)</span>. Recuerden que la distribución posterior conjunta satisface:</p>
<ul>
<li>La distribución posterior de <span class="math inline">\(\mu\)</span> condicional en <span class="math inline">\(\sigma^2\)</span> se distribuye como <span class="math inline">\(N(\bar y,\sigma/\sqrt{n})\)</span>.</li>
<li>La distribución posterior marginal de <span class="math inline">\(\sigma^2\)</span> se distribuye según <span class="math inline">\(S\chi_{n-1}^{-2}\)</span> (<span class="math inline">\(S\)</span> veces una chi-cuadrada inversa con <span class="math inline">\(n-1\)</span> grados de libertad).</li>
</ul>
<p>Cargamos los datos de los 20 atletas:</p>
<div class="sourceCode" id="cb527"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb527-1"><a href="09-calculo-bayes.html#cb527-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(LearnBayes)</span>
<span id="cb527-2"><a href="09-calculo-bayes.html#cb527-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(marathontimes)</span></code></pre></div>
<pre><code>##   time
## 1  182
## 2  201
## 3  221
## 4  234
## 5  237
## 6  251</code></pre>
<p>y graficamos un diagrama de contorno de la distribución posterior de <span class="math inline">\(\mu,\sigma^2\)</span>:</p>
<div class="sourceCode" id="cb529"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb529-1"><a href="09-calculo-bayes.html#cb529-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(marathontimes)</span>
<span id="cb529-2"><a href="09-calculo-bayes.html#cb529-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(normchi2post, <span class="fu">c</span>(<span class="dv">220</span>, <span class="dv">330</span>, <span class="dv">500</span>, <span class="dv">9000</span>), time,</span>
<span id="cb529-3"><a href="09-calculo-bayes.html#cb529-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;media&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;varianza&quot;</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-303-1.svg" width="100%" style="display: block; margin: auto;" />
y les agregamos una muestra aleatoria de tamaño 1000 de la distribución posterior conjunta, generada a través de las distribuciones marginales:</p>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb530-1"><a href="09-calculo-bayes.html#cb530-1" aria-hidden="true" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="fu">sum</span>((time <span class="sc">-</span> <span class="fu">mean</span>(time))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb530-2"><a href="09-calculo-bayes.html#cb530-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(time)</span>
<span id="cb530-3"><a href="09-calculo-bayes.html#cb530-3" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> S<span class="sc">/</span><span class="fu">rchisq</span>(<span class="dv">1000</span>, n <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb530-4"><a href="09-calculo-bayes.html#cb530-4" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="at">mean =</span> <span class="fu">mean</span>(time), <span class="at">sd =</span> <span class="fu">sqrt</span>(sigma2)<span class="sc">/</span><span class="fu">sqrt</span>(n))</span>
<span id="cb530-5"><a href="09-calculo-bayes.html#cb530-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(normchi2post, <span class="fu">c</span>(<span class="dv">220</span>, <span class="dv">330</span>, <span class="dv">500</span>, <span class="dv">9000</span>), time,</span>
<span id="cb530-6"><a href="09-calculo-bayes.html#cb530-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;media&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;varianza&quot;</span>)</span>
<span id="cb530-7"><a href="09-calculo-bayes.html#cb530-7" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(mu, sigma2)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-304-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>Si estamos interesados en hacer inferencia de <span class="math inline">\(\mu\)</span>, podemos calcular un intervalo de credibilidad al 95%, usando la muestra marginal:</p>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb531-1"><a href="09-calculo-bayes.html#cb531-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(mu, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 254.9617 300.8669</code></pre>
<p>y también inferencia sobre <span class="math inline">\(\sigma\)</span>:</p>
<div class="sourceCode" id="cb533"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb533-1"><a href="09-calculo-bayes.html#cb533-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(<span class="fu">sqrt</span>(sigma2), <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 37.66930 72.69096</code></pre>
<p>o aún sobre otros parámetros, por ejemplo el coeficiente de variación (<span class="math inline">\(CV=\sigma/\mu\)</span>):</p>
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb535-1"><a href="09-calculo-bayes.html#cb535-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(<span class="fu">sqrt</span>(sigma2)<span class="sc">/</span>mu, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##      2.5%     97.5% 
## 0.1357104 0.2634229</code></pre>
</div>
</div>
<div id="motivación-cálculo-de-integrales" class="section level2 hasAnchor" number="8.9">
<h2><span class="header-section-number">8.9</span> Motivación: Cálculo de Integrales<a href="09-calculo-bayes.html#motivación-cálculo-de-integrales" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Recuerden que según el teorema de Bayes, si observamos datos <span class="math inline">\(y\)</span> a partir de una verosimilitud <span class="math inline">\(f(y|\theta)\)</span> y se le asigna al parámetro <span class="math inline">\(\theta\)</span> una previa <span class="math inline">\(g(\theta)\)</span>, entonces:</p>
<p><span class="math display">\[g(\theta|y)\propto g(\theta)f(y|\theta)\]</span></p>
<p>Problema: tratar de manejar la distribución posterior de <span class="math inline">\(\theta\)</span> desde un punto de vista computacional con el fin de hacer inferencia.</p>
<p>Los procesos de inferencia requieren el cálculo o aproximación de integrales, por ejemplo:</p>
<ul>
<li>Valor esperado de una función de <span class="math inline">\(\theta\)</span>:</li>
</ul>
<p><span class="math display">\[E(h(\theta)|y)=\frac{\int h(\theta)g(\theta)f(y|\theta) d\theta}{\int g(\theta)f(y|\theta) d\theta}\]</span></p>
<ul>
<li>Probabilidad posterior de que <span class="math inline">\(h(\theta) \in A\)</span>:</li>
</ul>
<p><span class="math display">\[P(h(\theta) \in A|y)=\frac{\int_{h(\theta) \in A} g(\theta)f(y|\theta) d\theta}{\int g(\theta)f(y|\theta) d\theta}\]</span>
- Densidades marginales. Si <span class="math inline">\(\theta=(\theta_1,\theta_2)\)</span>:</p>
<p><span class="math display">\[g(\theta_1|y)\propto \int g(\theta_1,\theta_2|y)d\theta_2\]</span></p>
</div>
<div id="ejemplo-base-modelo-beta-binomial." class="section level2 hasAnchor" number="8.10">
<h2><span class="header-section-number">8.10</span> Ejemplo base: modelo beta-binomial.<a href="09-calculo-bayes.html#ejemplo-base-modelo-beta-binomial." class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En este ejemplo se estimará las tasas de muerte por cáncer gástrico en una población de hombres entre 45 y 64 años. Para ello se tiene datos de muertes <span class="math inline">\(y_j\)</span> y exposición <span class="math inline">\(n_j\)</span> para 20 ciudades en Missouri:</p>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb537-1"><a href="09-calculo-bayes.html#cb537-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;cancermortality&quot;</span>)</span>
<span id="cb537-2"><a href="09-calculo-bayes.html#cb537-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(cancermortality)</span></code></pre></div>
<pre><code>##   y    n
## 1 0 1083
## 2 0  855
## 3 2 3461
## 4 0  657
## 5 1 1208
## 6 1 1025</code></pre>
<p>Un primer intento de modelación podría considerar <span class="math inline">\(y_j\sim \text{Binomial}(p,n_j)\)</span> pero en este caso se puede comprobar que el modelo binomial no logra captar la variabilidad de las muertes totalmente. Otro intento de modelación que no tiene ese problema es un modelo beta-binomial con media <span class="math inline">\(\eta\)</span> y precisión <span class="math inline">\(K\)</span>:
<span class="math display">\[f(y_j|\eta,K)={n_j \choose y_j}\frac{B(K\eta+y_j,K(1-\eta)+n_j-y_j)}{B(K\eta,K(1-\eta))}\]</span>
con previa no informativa:
<span class="math display">\[g(\eta,K)\propto \frac{1}{\eta(1-\eta)}\frac{1}{(1+K)^2}\]</span>
entonces la densidad posterior de los parámetros sería:
<span class="math display">\[g(\eta,K|\text{datos})\propto \frac{1}{\eta(1-\eta)}\frac{1}{(1+K)^2} \prod_{j=1}^{20}\frac{B(K\eta+y_j,K(1-\eta)+n_j-y_j)}{B(K\eta,K(1-\eta))}\]</span>
donde <span class="math inline">\(0&lt;\eta&lt;1\)</span>, <span class="math inline">\(K&gt;0\)</span> y <span class="math inline">\(B(\cdot,\cdot)\)</span> es la función beta. La función <em>betabinexch0</em> contiene la implementación de la log-densidad posterior de <span class="math inline">\(\eta,K\)</span>:</p>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb539-1"><a href="09-calculo-bayes.html#cb539-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(betabinexch0, <span class="fu">c</span>(<span class="fl">1e-04</span>, <span class="fl">0.003</span>, <span class="dv">1</span>, <span class="dv">20000</span>),</span>
<span id="cb539-2"><a href="09-calculo-bayes.html#cb539-2" aria-hidden="true" tabindex="-1"></a>    cancermortality, <span class="at">xlab =</span> <span class="st">&quot;eta&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;K&quot;</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-309-1.svg" width="100%" style="display: block; margin: auto;" />
y note la gran asimetría en el comportamiento de la densidad conjunta, especialmente en la dirección de la variable <span class="math inline">\(K\)</span>. Por el dominio de las variables <span class="math inline">\(K\)</span> y <span class="math inline">\(\eta\)</span>, entonces se transforman según:
<span class="math display">\[\theta_1=\text{logit}(\eta)=\log\left(\frac{\eta}{1-\eta}\right),\quad  \theta_2=\log(K)\]</span>
y usando el teorema de cambio de variable en densidades:
<span class="math display">\[g_1(\theta_1,\theta_2|\text{datos})=g\left(\frac{e^{\theta_1}}{1+e^{\theta_2}},e^{\theta_2}\right)\frac{e^{\theta_1+\theta_2}}{(1+e^{\theta_2})^2}\]</span>
<span class="math inline">\(g_1\)</span> está implementada en la función <em>betabinexch</em> y el gráfico de contorno es más manejable ahora desde el punto de vista computacional:</p>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb540-1"><a href="09-calculo-bayes.html#cb540-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(betabinexch, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">8</span>, <span class="sc">-</span><span class="fl">4.5</span>, <span class="dv">3</span>, <span class="fl">16.5</span>), cancermortality,</span>
<span id="cb540-2"><a href="09-calculo-bayes.html#cb540-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;logit eta&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;log K&quot;</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-310-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>Definitivamente esta es una distribución posterior a la que no se le puede aplicar las técnicas usuales para hacer inferencia (caso no conjugado). Se va a considerar dos formas de realizar inferencia:</p>
<ul>
<li>Aproximación de Laplace.</li>
<li>Simulación Monte Carlo.</li>
</ul>
</div>
<div id="aproximación-de-laplace" class="section level2 hasAnchor" number="8.11">
<h2><span class="header-section-number">8.11</span> Aproximación de Laplace<a href="09-calculo-bayes.html#aproximación-de-laplace" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Considere el logaritmo de la densidad posterior proporcional:
<span class="math display">\[h(\theta,y)=\log(g(\theta)f(y|\theta))\]</span>
Suponga que <span class="math inline">\(\hat \theta\)</span> es la moda de <span class="math inline">\(\theta\)</span>. Un desarrollo de Taylor alrededor de <span class="math inline">\(\hat \theta\)</span> para <span class="math inline">\(h(\theta)\)</span> da la siguiente aproximación:
<span class="math display">\[h(\theta)\approx h(\hat \theta)+\frac 1 2(\theta-\hat \theta)^Th&#39;&#39;(\hat \theta)(\theta-\hat \theta)\]</span>
Por lo tanto podemos aproximar el comportamiento en distribución de <span class="math inline">\(\theta\)</span> como:
<span class="math display">\[\theta \sim N(\hat \theta,V)\]</span>
donde <span class="math inline">\(V=(-h&#39;&#39;(\hat \theta))^{-1}\)</span>. Con el fin de encontrar la moda <span class="math inline">\(\hat \theta\)</span> se puede usar algún algoritmo para encontrar máximos en funciones de varias variables, por ejemplo el método de Newton o el de Nelder-Mead (default en <em>optim</em>). La función <em>laplace</em> tiene el método de optimización implementado tomando como argumentos la log-densidad posterior, un valor inicial de los parámetros y el conjunto de datos.</p>
<p>Por ejemplo, en el caso anterior:</p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="09-calculo-bayes.html#cb541-1" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">laplace</span>(betabinexch, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">7</span>, <span class="dv">6</span>), cancermortality)</span>
<span id="cb541-2"><a href="09-calculo-bayes.html#cb541-2" aria-hidden="true" tabindex="-1"></a>fit</span></code></pre></div>
<pre><code>## $mode
## [1] -6.819793  7.576111
## 
## $var
##             [,1]       [,2]
## [1,]  0.07896568 -0.1485087
## [2,] -0.14850874  1.3483208
## 
## $int
## [1] -570.7743
## 
## $converge
## [1] TRUE</code></pre>
<p>donde el punto (-7,6) se puede inferir a través del gráfico de contorno anterior. Por lo tanto podemos aproximar la densidad posterior conjunta de <span class="math inline">\((\text{logit}(\eta),\log K)\)</span> se puede aproximar como una normal multivariada con media <em>fit$mode</em> y varianza <em>fit.var</em>. Un gráfico de contorno de la aproximación es:</p>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb543-1"><a href="09-calculo-bayes.html#cb543-1" aria-hidden="true" tabindex="-1"></a>npar <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">m =</span> fit<span class="sc">$</span>mode, <span class="at">v =</span> fit<span class="sc">$</span>var)</span>
<span id="cb543-2"><a href="09-calculo-bayes.html#cb543-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(lbinorm, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">8</span>, <span class="sc">-</span><span class="fl">4.5</span>, <span class="dv">3</span>, <span class="fl">16.5</span>), npar, <span class="at">xlab =</span> <span class="st">&quot;logit eta&quot;</span>,</span>
<span id="cb543-3"><a href="09-calculo-bayes.html#cb543-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;log K&quot;</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-312-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>También podemos hacer inferencia de los parámetros:</p>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="09-calculo-bayes.html#cb544-1" aria-hidden="true" tabindex="-1"></a>se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(fit<span class="sc">$</span>var))</span>
<span id="cb544-2"><a href="09-calculo-bayes.html#cb544-2" aria-hidden="true" tabindex="-1"></a>lb <span class="ot">&lt;-</span> fit<span class="sc">$</span>mode <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> se</span>
<span id="cb544-3"><a href="09-calculo-bayes.html#cb544-3" aria-hidden="true" tabindex="-1"></a>ub <span class="ot">&lt;-</span> fit<span class="sc">$</span>mode <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> se</span>
<span id="cb544-4"><a href="09-calculo-bayes.html#cb544-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb544-5"><a href="09-calculo-bayes.html#cb544-5" aria-hidden="true" tabindex="-1"></a>etainv <span class="ot">&lt;-</span> <span class="fu">c</span>(lb[<span class="dv">1</span>], ub[<span class="dv">1</span>])</span>
<span id="cb544-6"><a href="09-calculo-bayes.html#cb544-6" aria-hidden="true" tabindex="-1"></a>Kinv <span class="ot">&lt;-</span> <span class="fu">c</span>(lb[<span class="dv">2</span>], ub[<span class="dv">2</span>])</span>
<span id="cb544-7"><a href="09-calculo-bayes.html#cb544-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb544-8"><a href="09-calculo-bayes.html#cb544-8" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(etainv)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(etainv))</span></code></pre></div>
<pre><code>## [1] 0.0006291199 0.0018904899</code></pre>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="09-calculo-bayes.html#cb546-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(Kinv)</span></code></pre></div>
<pre><code>## [1]   200.3879 18995.6680</code></pre>
<p>son intervalos de predicción al 95% para <span class="math inline">\(\eta\)</span> y <span class="math inline">\(K\)</span> respectivamente.</p>
</div>
<div id="simulación" class="section level2 hasAnchor" number="8.12">
<h2><span class="header-section-number">8.12</span> Simulación<a href="09-calculo-bayes.html#simulación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="simulación-monte-carlo" class="section level3 hasAnchor" number="8.12.1">
<h3><span class="header-section-number">8.12.1</span> Simulación Monte Carlo<a href="09-calculo-bayes.html#simulación-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suponga que <span class="math inline">\(g(\theta|y)\)</span> es la densidad posterior de <span class="math inline">\(\theta\)</span> y queremos estimar una característica de <span class="math inline">\(\theta\)</span>, a través de la función <span class="math inline">\(h(\theta)\)</span>. La media posterior de <span class="math inline">\(h(\theta)\)</span> es:
<span class="math display">\[E(h(\theta)|y)=\int h(\theta)g(\theta|y)d\theta\]</span>
y suponga que podemos simular una muestra independiente <span class="math inline">\(\theta^1,\ldots,\theta^m\)</span> de <span class="math inline">\(g(\theta|y)\)</span>. El estimador Monte Carlo del valor esperado es:
<span class="math display">\[\bar h =\frac 1 m\sum_{j=1}^mh(\theta^j) \]</span>
con su error estándar:
<span class="math display">\[se_{\bar h}=\sqrt{\frac{1}{m(m-1)}\sum_{j=1}^m\left(h(\theta^j)-\bar h\right)^2}\]</span>
En el caso en que no es posible obtener muestras de la densidad posterior, entonces se pueden definir algoritmos que aproximan la generación de muestras.</p>
</div>
<div id="muestreo-por-rechazo" class="section level3 hasAnchor" number="8.12.2">
<h3><span class="header-section-number">8.12.2</span> Muestreo por rechazo<a href="09-calculo-bayes.html#muestreo-por-rechazo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suponga que queremos obtener una muestra de <span class="math inline">\(g(\theta|y)\)</span> donde la constante de normalización no es conocida. Suponga que conocemos una densidad <span class="math inline">\(p(\theta)\)</span> que satisface:</p>
<ul>
<li>Fácil de obtener muestras.</li>
<li><span class="math inline">\(p\)</span> aproxima <span class="math inline">\(g\)</span> en términos de localización y escala.</li>
<li>Para todo <span class="math inline">\(\theta\)</span>: <span class="math inline">\(g(\theta|y)\leq cp(\theta)\)</span>, para una constante <span class="math inline">\(c\)</span>.</li>
</ul>
<p>Algoritmo:</p>
<ol style="list-style-type: decimal">
<li>Simule una realización independiente de <span class="math inline">\(\theta \sim p\)</span> y <span class="math inline">\(U\sim Unif(0,1)\)</span>.</li>
<li>Si <span class="math inline">\(U\leq g(\theta|y)/(cp(\theta))\)</span> entonces acepte <span class="math inline">\(\theta\)</span>, caso contrario rechace la muestra propuesta.</li>
<li>Continue 1 y 2 hasta que se haya generado un número deseado de muestras.</li>
</ol>
<p>Nota: un algoritmo eficiente tiene una tasa de aceptación de muestras alta.</p>
<p>En el ejemplo anterior, seleccionamos <span class="math inline">\(p(\theta)\)</span> una distribución <span class="math inline">\(t\)</span> multivariada con parámetro de locación igual a la media aproximada del método de Laplace, matriz de escala igual a 2 veces la matriz de varianza aproximada según Laplace y 4 grados de libertad. De esta forma nos aseguramos que <span class="math inline">\(g(\theta|y)/p(\theta)\)</span> está acotado superiormente.</p>
<p>Con el fin de encontrar <span class="math inline">\(c\)</span>, maximizamos la diferencia de logaritmos entre <span class="math inline">\(g(\theta|y)\)</span> y la propuesta <span class="math inline">\(p(\theta)\)</span>, usando la función <em>laplace</em>:</p>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb548-1"><a href="09-calculo-bayes.html#cb548-1" aria-hidden="true" tabindex="-1"></a>betabinT <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, datapar) {</span>
<span id="cb548-2"><a href="09-calculo-bayes.html#cb548-2" aria-hidden="true" tabindex="-1"></a>    data <span class="ot">&lt;-</span> datapar<span class="sc">$</span>data</span>
<span id="cb548-3"><a href="09-calculo-bayes.html#cb548-3" aria-hidden="true" tabindex="-1"></a>    tpar <span class="ot">&lt;-</span> datapar<span class="sc">$</span>par</span>
<span id="cb548-4"><a href="09-calculo-bayes.html#cb548-4" aria-hidden="true" tabindex="-1"></a>    d <span class="ot">&lt;-</span> <span class="fu">betabinexch</span>(theta, data) <span class="sc">-</span> <span class="fu">dmt</span>(theta, <span class="at">mean =</span> <span class="fu">c</span>(tpar<span class="sc">$</span>m),</span>
<span id="cb548-5"><a href="09-calculo-bayes.html#cb548-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">S =</span> tpar<span class="sc">$</span>var, <span class="at">df =</span> tpar<span class="sc">$</span>df, <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb548-6"><a href="09-calculo-bayes.html#cb548-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(d)</span>
<span id="cb548-7"><a href="09-calculo-bayes.html#cb548-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>definimos parámetros:</p>
<div class="sourceCode" id="cb549"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb549-1"><a href="09-calculo-bayes.html#cb549-1" aria-hidden="true" tabindex="-1"></a>tpar <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">m =</span> fit<span class="sc">$</span>mode, <span class="at">var =</span> <span class="dv">2</span> <span class="sc">*</span> fit<span class="sc">$</span>var, <span class="at">df =</span> <span class="dv">4</span>)</span>
<span id="cb549-2"><a href="09-calculo-bayes.html#cb549-2" aria-hidden="true" tabindex="-1"></a>datapar <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">data =</span> cancermortality, <span class="at">par =</span> tpar)</span></code></pre></div>
<p>y resolvemos:</p>
<div class="sourceCode" id="cb550"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb550-1"><a href="09-calculo-bayes.html#cb550-1" aria-hidden="true" tabindex="-1"></a>start <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">6.9</span>, <span class="fl">12.4</span>)</span>
<span id="cb550-2"><a href="09-calculo-bayes.html#cb550-2" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">laplace</span>(betabinT, start, datapar)</span>
<span id="cb550-3"><a href="09-calculo-bayes.html#cb550-3" aria-hidden="true" tabindex="-1"></a>fit1<span class="sc">$</span>mode</span></code></pre></div>
<pre><code>## [1] -6.888963 12.421993</code></pre>
<p>y el valor máximo de las diferencias de logaritmos es:</p>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb552-1"><a href="09-calculo-bayes.html#cb552-1" aria-hidden="true" tabindex="-1"></a>dmax <span class="ot">&lt;-</span> <span class="fu">betabinT</span>(fit1<span class="sc">$</span>mode, datapar)</span>
<span id="cb552-2"><a href="09-calculo-bayes.html#cb552-2" aria-hidden="true" tabindex="-1"></a>dmax</span></code></pre></div>
<pre><code>## [1] -569.2829</code></pre>
<p>el algoritmo sería:</p>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb554-1"><a href="09-calculo-bayes.html#cb554-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb554-2"><a href="09-calculo-bayes.html#cb554-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb554-3"><a href="09-calculo-bayes.html#cb554-3" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">rmt</span>(n, <span class="at">mean =</span> <span class="fu">c</span>(tpar<span class="sc">$</span>m), <span class="at">S =</span> tpar<span class="sc">$</span>var, <span class="at">df =</span> tpar<span class="sc">$</span>df)</span>
<span id="cb554-4"><a href="09-calculo-bayes.html#cb554-4" aria-hidden="true" tabindex="-1"></a>lf <span class="ot">&lt;-</span> <span class="fu">map_dbl</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>, <span class="sc">~</span><span class="fu">betabinexch</span>(theta[., ], cancermortality))</span>
<span id="cb554-5"><a href="09-calculo-bayes.html#cb554-5" aria-hidden="true" tabindex="-1"></a>lg <span class="ot">&lt;-</span> <span class="fu">dmt</span>(theta, <span class="at">mean =</span> <span class="fu">c</span>(tpar<span class="sc">$</span>m), <span class="at">S =</span> tpar<span class="sc">$</span>var, <span class="at">df =</span> tpar<span class="sc">$</span>df,</span>
<span id="cb554-6"><a href="09-calculo-bayes.html#cb554-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb554-7"><a href="09-calculo-bayes.html#cb554-7" aria-hidden="true" tabindex="-1"></a>prob <span class="ot">=</span> <span class="fu">exp</span>(lf <span class="sc">-</span> lg <span class="sc">-</span> dmax)</span>
<span id="cb554-8"><a href="09-calculo-bayes.html#cb554-8" aria-hidden="true" tabindex="-1"></a>thetaRS <span class="ot">&lt;-</span> theta[<span class="fu">runif</span>(n) <span class="sc">&lt;</span> prob, ]</span></code></pre></div>
<p>la tasa de aceptación es:</p>
<div class="sourceCode" id="cb555"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb555-1"><a href="09-calculo-bayes.html#cb555-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(thetaRS)[<span class="dv">1</span>]<span class="sc">/</span><span class="dv">10000</span></span></code></pre></div>
<pre><code>## [1] 0.2447</code></pre>
<p>y dibujamos el gráfico de contorno con la muestra obtenida:</p>
<div class="sourceCode" id="cb557"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb557-1"><a href="09-calculo-bayes.html#cb557-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(betabinexch, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">8</span>, <span class="sc">-</span><span class="fl">4.5</span>, <span class="dv">3</span>, <span class="fl">16.5</span>), cancermortality,</span>
<span id="cb557-2"><a href="09-calculo-bayes.html#cb557-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;logit eta&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;log K&quot;</span>)</span>
<span id="cb557-3"><a href="09-calculo-bayes.html#cb557-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(thetaRS[, <span class="dv">1</span>], thetaRS[, <span class="dv">2</span>])</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-320-1.svg" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="muestreo-por-importancia" class="section level2 hasAnchor" number="8.13">
<h2><span class="header-section-number">8.13</span> Muestreo por importancia<a href="09-calculo-bayes.html#muestreo-por-importancia" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suponga que queremos calcular el siguiente valor esperado posterior:
<span class="math display">\[E(h(\theta)|y)=\frac{\int h(\theta)g(\theta)f(y|\theta)d\theta}{\int g(\theta)f(y|\theta)d\theta}\]</span></p>
<p>en el caso en donde no se puede obtener una muestra directa de la distribución posterior y usar Monte Carlo por ejemplo. Usemos la densidad propuesta <span class="math inline">\(p(\theta)\)</span> que aproxima la posterior:</p>
<p><span class="math display">\[\begin{align*}
E(h(\theta)|y)&amp;=\frac{\int h(\theta)\frac{g(\theta)f(y|\theta)}{p(\theta)}p(\theta)d\theta}{\int \frac{g(\theta)f(y|\theta)}{p(\theta)}p(\theta)d\theta}\\
&amp;=\frac{\int h(\theta)w(\theta)p(\theta)d\theta}{\int w(\theta)p(\theta)d\theta}
\end{align*}\]</span></p>
<p>donde <span class="math inline">\(w(\theta)=\frac{g(\theta)f(y|\theta)}{p(\theta)}\)</span>. Si <span class="math inline">\(\theta^1,\ldots,\theta^{m}\sim p(\theta)\)</span> entonces el estimador de muestreo por importancia de la media posterior es:
<span class="math display">\[\bar h_{IS}=\frac{\sum_{j=1}^mh(\theta^j)w(\theta^j)}{\sum_{j=1}^mw(\theta^j)}\]</span>
con error estándar:
<span class="math display">\[se_{\bar h_{IS}}=\frac{\sqrt{\sum_{j=1}^m((h(\theta^j)-\bar h_{IS})w(\theta^j))^2}}{\sum_{j=1}^mw(\theta^j)}\]</span>
Nota: al igual que en el método anterior, la escogencia de <span class="math inline">\(p(\theta)\)</span> se basa en su facilidad de muestreo y en la acotación por arriba de los pesos <span class="math inline">\(w(\theta)\)</span>.</p>
<p>Ahora implementamos el algoritmo en el ejemplo (buena parte es una repetición del anterior), usando como propuesta la misma distribución t multivariada. Además graficamos un histograma de los pesos para comprobar que están acotados (en este caso por 1).</p>
<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb558-1"><a href="09-calculo-bayes.html#cb558-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb558-2"><a href="09-calculo-bayes.html#cb558-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb558-3"><a href="09-calculo-bayes.html#cb558-3" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">rmt</span>(n, <span class="at">mean =</span> <span class="fu">c</span>(tpar<span class="sc">$</span>m), <span class="at">S =</span> tpar<span class="sc">$</span>var, <span class="at">df =</span> tpar<span class="sc">$</span>df)</span>
<span id="cb558-4"><a href="09-calculo-bayes.html#cb558-4" aria-hidden="true" tabindex="-1"></a>lf <span class="ot">&lt;-</span> <span class="fu">map_dbl</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>, <span class="sc">~</span><span class="fu">betabinexch</span>(theta[., ], cancermortality))</span>
<span id="cb558-5"><a href="09-calculo-bayes.html#cb558-5" aria-hidden="true" tabindex="-1"></a>lp <span class="ot">&lt;-</span> <span class="fu">dmt</span>(theta, <span class="at">mean =</span> <span class="fu">c</span>(tpar<span class="sc">$</span>m), <span class="at">S =</span> tpar<span class="sc">$</span>var, <span class="at">df =</span> tpar<span class="sc">$</span>df,</span>
<span id="cb558-6"><a href="09-calculo-bayes.html#cb558-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">log =</span> <span class="cn">TRUE</span>)</span>
<span id="cb558-7"><a href="09-calculo-bayes.html#cb558-7" aria-hidden="true" tabindex="-1"></a>md <span class="ot">&lt;-</span> <span class="fu">max</span>(lf <span class="sc">-</span> lp)</span>
<span id="cb558-8"><a href="09-calculo-bayes.html#cb558-8" aria-hidden="true" tabindex="-1"></a>wt <span class="ot">&lt;-</span> <span class="fu">exp</span>(lf <span class="sc">-</span> lp <span class="sc">-</span> md)</span>
<span id="cb558-9"><a href="09-calculo-bayes.html#cb558-9" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(wt)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-321-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>y calculamos el valor esperado de <span class="math inline">\(\log K\)</span> usando los pesos obtenidos del paso anterior:</p>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb559-1"><a href="09-calculo-bayes.html#cb559-1" aria-hidden="true" tabindex="-1"></a>est <span class="ot">&lt;-</span> <span class="fu">sum</span>(wt <span class="sc">*</span> theta[, <span class="dv">2</span>])<span class="sc">/</span><span class="fu">sum</span>(wt)</span>
<span id="cb559-2"><a href="09-calculo-bayes.html#cb559-2" aria-hidden="true" tabindex="-1"></a>SEest <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((theta[, <span class="dv">2</span>] <span class="sc">-</span> est)<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> wt<span class="sc">^</span><span class="dv">2</span>))<span class="sc">/</span><span class="fu">sum</span>(wt)</span>
<span id="cb559-3"><a href="09-calculo-bayes.html#cb559-3" aria-hidden="true" tabindex="-1"></a><span class="fu">show</span>(<span class="fu">c</span>(est, SEest))</span></code></pre></div>
<pre><code>## [1] 7.92445868 0.01905786</code></pre>
</div>
<div id="remuestreo-por-importancia" class="section level2 hasAnchor" number="8.14">
<h2><span class="header-section-number">8.14</span> Remuestreo por importancia<a href="09-calculo-bayes.html#remuestreo-por-importancia" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Al igual que en el caso anterior simulamos <span class="math inline">\(\theta^1,\ldots,\theta^m\sim p(\theta)\)</span> y calculamos los pesos <span class="math inline">\(\{w(\theta^j)=g(\theta^j|y)/p(\theta^j)\}\)</span>. Los pesos se convierten a probabilidades según:
<span class="math display">\[p^j=\frac{w(\theta^j)}{\sum_{k=1}^mw(\theta^k)}\]</span>
Tomamos una nueva muestra <span class="math inline">\(\theta^{*1},\ldots,\theta^{*m}\sim \{p^k\}\)</span> es decir se obtiene una nueva muestra con reemplazo a partir de la muestra original <span class="math inline">\(\theta^1,\ldots,\theta^m\)</span> con pesos <span class="math inline">\(\{p^k\}\)</span> (muestra bootstrap ponderada). A este método se le llama remuestreo por importancia.</p>
<p>Siguiendo con el ejemplo:</p>
<div class="sourceCode" id="cb561"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb561-1"><a href="09-calculo-bayes.html#cb561-1" aria-hidden="true" tabindex="-1"></a>probs <span class="ot">&lt;-</span> wt<span class="sc">/</span><span class="fu">sum</span>(wt)</span>
<span id="cb561-2"><a href="09-calculo-bayes.html#cb561-2" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>n, <span class="at">size =</span> n, <span class="at">prob =</span> probs, <span class="at">replace =</span> T)</span>
<span id="cb561-3"><a href="09-calculo-bayes.html#cb561-3" aria-hidden="true" tabindex="-1"></a>thetaSIR <span class="ot">&lt;-</span> theta[indices, ]</span></code></pre></div>
<p>y los intervalos de predicción al 95% para <span class="math inline">\(\text{logit}(\eta)\)</span> y <span class="math inline">\(log K\)</span> son:</p>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb562-1"><a href="09-calculo-bayes.html#cb562-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(thetaSIR[, <span class="dv">1</span>], <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##      2.5%     97.5% 
## -7.342559 -6.155018</code></pre>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb564-1"><a href="09-calculo-bayes.html#cb564-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(thetaSIR[, <span class="dv">2</span>], <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##      2.5%     97.5% 
##  5.587915 11.190022</code></pre>
</div>
<div id="algoritmo-de-metropolis-hastings" class="section level2 hasAnchor" number="8.15">
<h2><span class="header-section-number">8.15</span> Algoritmo de Metropolis-Hastings<a href="09-calculo-bayes.html#algoritmo-de-metropolis-hastings" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Muestreo por cadenas de Markov-Monte Carlo (MCMC): algoritmos que definen una cadena de Markov irreducible y aperiódica cuya densidad estacionaria es la densidad posterior de interés.</p>
<p>Simplificamos la notación de la densidad posterior <span class="math inline">\(g(\theta|y)\)</span> usando <span class="math inline">\(g(\theta)\)</span>. Seleccionamos un valor inicial del algoritmo <span class="math inline">\(\theta^0\)</span> y procedemos con el</p>
<p>Algoritmo</p>
<ul>
<li>Simule un candidato <span class="math inline">\(\theta^*\sim p(\theta^*|\theta^{t-1})\)</span> (densidad propuesta).</li>
<li>Calcule:
<span class="math display">\[R=\frac{g(\theta^*)p(\theta^{t-1}|\theta^*)}{g(\theta^{t-1})p(\theta^*|\theta^{t-1})}\]</span></li>
<li>Calcule la probabilidad de aceptación <span class="math inline">\(P=\min \{R,1\}\)</span>.</li>
<li>Acepte la propuesta <span class="math inline">\(\theta^{t}=\theta^*\)</span> con probabilidad P, en caso contrario <span class="math inline">\(\theta^t=\theta^{t-1}\)</span>.</li>
</ul>
<p>Nota: bajo ciertas condiciones de regularidad sobre la probabilidad propuesta:
<span class="math display">\[\theta^n \stackrel{d}{\longrightarrow} M\sim g(\theta)\]</span>
cuando <span class="math inline">\(n\rightarrow \infty\)</span>.</p>
<p>Escogencias de la densidad propuesta:
- Metropolis-Hastings independiente:
<span class="math display">\[p(\theta^*|\theta^{t-1})=p(\theta^*)\]</span>
- Metropolis-Hastings con caminata aleatoria:
<span class="math display">\[p(\theta^*|\theta^{t-1})=h(\theta^*-\theta^{t-1})\]</span>
donde <span class="math inline">\(h\)</span> es una función simétrica alrededor del origen. En este caso es fácil verificar que:
<span class="math display">\[R=\frac{g(\theta^*)}{g(\theta^{t-1})}\]</span>
Nota: las implementaciones de Metropolis-Hastings dentro del paquete LearnBayes tienen las siguientes particularidades:</p>
<ul>
<li><p>La función <em>indepmetrop</em> contiene una propuesta que es normal multivariada con media <span class="math inline">\(\mu\)</span> y varianza <span class="math inline">\(V\)</span> (modelo independiente). Los parámetros de la propuesta se debe escoger de manera que <span class="math inline">\(g/p\)</span> se acotado, especialmente en las colas.</p></li>
<li><p>La función <em>rwmetrop</em> contiene una propuesta de la siguiente forma:
<span class="math display">\[\theta^*=\theta^{t-1}+\sigma Z\]</span>
donde <span class="math inline">\(Z\)</span> es una normal multivariada con media 0 y matriz de varianza <span class="math inline">\(V\)</span>. Además <span class="math inline">\(\sigma\)</span> es un parámetro de escala positivo.</p></li>
</ul>
</div>
<div id="algoritmo-de-gibbs" class="section level2 hasAnchor" number="8.16">
<h2><span class="header-section-number">8.16</span> Algoritmo de Gibbs<a href="09-calculo-bayes.html#algoritmo-de-gibbs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suponga que el parámetro de interés es <span class="math inline">\(\theta=(\theta_1,\ldots,\theta_p)\)</span> y que podemos obtener muestras de manera secuencial a partir de las siguientes distribuciones condicionales (dado un valor inicial <span class="math inline">\(\theta^0\)</span> y <span class="math inline">\(t=1,\ldots,n\)</span>):</p>
<p><span class="math display">\[\begin{align*}
\theta_1^t&amp;\sim [\theta_1|\theta_2^{t-1},\ldots,\theta_p^{t-1},\text{datos}]\\
\theta_2^t&amp;\sim [\theta_2|\theta_1^t,\theta_3^{t-1},\ldots,\theta_p^{t-1},\text{datos}]\\
\vdots &amp; \qquad \vdots\\
\theta_p^t&amp;\sim [\theta_p|\theta_1^t,\ldots,\theta_{p-1}^t,\text{datos}]
\end{align*}\]</span></p>
<p>Bajo condiciones bastante generales se puede comprobar que <span class="math inline">\(\theta^t\)</span> converge a una muestra de la distribución conjunta posterior de <span class="math inline">\(\theta\)</span>.</p>
<p>Nota: cuando en alguna de las condicionales anteriores no se puede obtener muestras de manera directa, entonces se puede sustituir el muestreo por un paso del algoritmo de Metropolis-Hastings. Así está implementado en la función <em>gibbs</em> del paquete LearnBayes.</p>
<div id="diagnósticos-de-convergencia-de-mcmc" class="section level3 hasAnchor" number="8.16.1">
<h3><span class="header-section-number">8.16.1</span> Diagnósticos de convergencia de MCMC<a href="09-calculo-bayes.html#diagnósticos-de-convergencia-de-mcmc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Tasa de aceptación.</li>
<li>Gráficos de traza (traceplots): gráfico de <span class="math inline">\((t,\theta^t)\)</span>. Por la naturaleza secuencial de los algoritmos de MH y Gibbs, los primeros valores de la cadena no representan normalmente una muestra confiable de la distribución posterior, por lo que generalmente se desecha un porcentaje inicial de la muestra (periodo de quema o burn-in period).</li>
<li>Por construcción, uno esperaría que el nivel de autocorrelación de las cadenas sea bajo. Al igual que en el análisis de residuos de regresión, uno puede construir un ACF de las cadenas y esperar autocorrelación baja y convergente a 0.</li>
</ul>
</div>
</div>
<div id="ejemplos" class="section level2 hasAnchor" number="8.17">
<h2><span class="header-section-number">8.17</span> Ejemplos<a href="09-calculo-bayes.html#ejemplos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="datos-agrupados-bajo-una-población-normal" class="section level3 hasAnchor" number="8.17.1">
<h3><span class="header-section-number">8.17.1</span> Datos agrupados bajo una población normal<a href="09-calculo-bayes.html#datos-agrupados-bajo-una-población-normal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suponga que observamos los siguientes datos agrupados:</p>
<table>
<thead>
<tr class="header">
<th>Altura (pulgadas)</th>
<th>Frecuencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Menos de 66</td>
<td>14</td>
</tr>
<tr class="even">
<td>Entre 66 y 68</td>
<td>30</td>
</tr>
<tr class="odd">
<td>Entre 68 y 70</td>
<td>49</td>
</tr>
<tr class="even">
<td>Entre 70 y 72</td>
<td>70</td>
</tr>
<tr class="odd">
<td>Entre 72 y 74</td>
<td>33</td>
</tr>
<tr class="even">
<td>Más de 74</td>
<td>15</td>
</tr>
</tbody>
</table>
<p>Si asumimos que las alturas son normales con media <span class="math inline">\(\mu\)</span> y desviación estándar <span class="math inline">\(\sigma\)</span>, podemos asumir una verosimilitud multinomial para los datos agrupados:
<span class="math display">\[\begin{align*}
L(\mu,\sigma)&amp;\propto \Phi(66,\mu,\sigma)^{14}(\Phi(68,\mu,\sigma)-\Phi(66,\mu,\sigma))^{30} \\
&amp;\times  (\Phi(70,\mu,\sigma)-\Phi(68,\mu,\sigma))^{49} (\Phi(72,\mu,\sigma)-\Phi(70,\mu,\sigma))^{70}\\
&amp;\times  (\Phi(74,\mu,\sigma)-\Phi(72,\mu,\sigma))^{33} (1-\Phi(74,\mu,\sigma))^{15}
\end{align*}\]</span></p>
<p>y asumimos una previa no informativa para <span class="math inline">\((\mu,\sigma)\sim \frac 1 \sigma\)</span>. Como <span class="math inline">\(\sigma&gt;0\)</span> entonces usamos la transformación <span class="math inline">\(\lambda=\log (\sigma)\)</span>.</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb566-1"><a href="09-calculo-bayes.html#cb566-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">int.lo =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="cn">Inf</span>, <span class="fu">seq</span>(<span class="dv">66</span>, <span class="dv">74</span>, <span class="at">by =</span> <span class="dv">2</span>)), <span class="at">int.hi =</span> <span class="fu">c</span>(<span class="fu">seq</span>(<span class="dv">66</span>,</span>
<span id="cb566-2"><a href="09-calculo-bayes.html#cb566-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">74</span>, <span class="at">by =</span> <span class="dv">2</span>), <span class="cn">Inf</span>), <span class="at">f =</span> <span class="fu">c</span>(<span class="dv">14</span>, <span class="dv">30</span>, <span class="dv">49</span>, <span class="dv">70</span>, <span class="dv">33</span>, <span class="dv">15</span>))</span></code></pre></div>
<p>es una estructura de los datos agrupados. La log-densidad posterior de los datos sería:</p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="09-calculo-bayes.html#cb567-1" aria-hidden="true" tabindex="-1"></a>groupeddatapost <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, data) {</span>
<span id="cb567-2"><a href="09-calculo-bayes.html#cb567-2" aria-hidden="true" tabindex="-1"></a>    dj <span class="ot">&lt;-</span> <span class="cf">function</span>(f, int.lo, int.hi, mu, sigma) f <span class="sc">*</span></span>
<span id="cb567-3"><a href="09-calculo-bayes.html#cb567-3" aria-hidden="true" tabindex="-1"></a>        <span class="fu">log</span>(<span class="fu">pnorm</span>(int.hi, mu, sigma) <span class="sc">-</span> <span class="fu">pnorm</span>(int.lo,</span>
<span id="cb567-4"><a href="09-calculo-bayes.html#cb567-4" aria-hidden="true" tabindex="-1"></a>            mu, sigma))</span>
<span id="cb567-5"><a href="09-calculo-bayes.html#cb567-5" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> theta[<span class="dv">1</span>]</span>
<span id="cb567-6"><a href="09-calculo-bayes.html#cb567-6" aria-hidden="true" tabindex="-1"></a>    sigma <span class="ot">&lt;-</span> <span class="fu">exp</span>(theta[<span class="dv">2</span>])</span>
<span id="cb567-7"><a href="09-calculo-bayes.html#cb567-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>(<span class="fu">dj</span>(data<span class="sc">$</span>f, data<span class="sc">$</span>int.lo, data<span class="sc">$</span>int.hi, mu, sigma))</span>
<span id="cb567-8"><a href="09-calculo-bayes.html#cb567-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Usamos el método de Laplace para encontrar una aproximación de los parámetros de la previa bajo Metropolis-Hastings:</p>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb568-1"><a href="09-calculo-bayes.html#cb568-1" aria-hidden="true" tabindex="-1"></a>start <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">70</span>, <span class="dv">1</span>)</span>
<span id="cb568-2"><a href="09-calculo-bayes.html#cb568-2" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">laplace</span>(groupeddatapost, start, d)</span>
<span id="cb568-3"><a href="09-calculo-bayes.html#cb568-3" aria-hidden="true" tabindex="-1"></a>fit</span></code></pre></div>
<pre><code>## $mode
## [1] 70.169880  0.973644
## 
## $var
##              [,1]         [,2]
## [1,] 3.534713e-02 3.520776e-05
## [2,] 3.520776e-05 3.146470e-03
## 
## $int
## [1] -350.6305
## 
## $converge
## [1] TRUE</code></pre>
<p>la escogencia del valor inicial se basa en los datos artificiales en la página 126 del <span class="citation">(Albert et al. 2009)</span>. De esta forma definimos los parámetros de la propuesta como:</p>
<div class="sourceCode" id="cb570"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb570-1"><a href="09-calculo-bayes.html#cb570-1" aria-hidden="true" tabindex="-1"></a>proposal <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">var =</span> fit<span class="sc">$</span>var, <span class="at">scale =</span> <span class="dv">2</span>)</span></code></pre></div>
<p>y ajustamos la versión bajo caminata aleatoria de un Metropolis-Hastings (MH):</p>
<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb571-1"><a href="09-calculo-bayes.html#cb571-1" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">rwmetrop</span>(groupeddatapost, proposal, start,</span>
<span id="cb571-2"><a href="09-calculo-bayes.html#cb571-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">10000</span>, d)</span></code></pre></div>
<p>con una tasa de aceptación:</p>
<div class="sourceCode" id="cb572"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb572-1"><a href="09-calculo-bayes.html#cb572-1" aria-hidden="true" tabindex="-1"></a>fit2<span class="sc">$</span>accept</span></code></pre></div>
<pre><code>## [1] 0.2956</code></pre>
<p>Algunas estadísticas de la distribución posterior de <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\log \sigma\)</span>:</p>
<div class="sourceCode" id="cb574"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb574-1"><a href="09-calculo-bayes.html#cb574-1" aria-hidden="true" tabindex="-1"></a>post.means <span class="ot">&lt;-</span> <span class="fu">apply</span>(fit2<span class="sc">$</span>par, <span class="dv">2</span>, mean)</span>
<span id="cb574-2"><a href="09-calculo-bayes.html#cb574-2" aria-hidden="true" tabindex="-1"></a>post.sds <span class="ot">&lt;-</span> <span class="fu">apply</span>(fit2<span class="sc">$</span>par, <span class="dv">2</span>, sd)</span>
<span id="cb574-3"><a href="09-calculo-bayes.html#cb574-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(post.means, post.sds)</span></code></pre></div>
<pre><code>##      post.means   post.sds
## [1,] 70.1596677 0.19072746
## [2,]  0.9799831 0.05389768</code></pre>
<p>esto se puede comparar con los estimadores de la aproximación de Laplace:</p>
<div class="sourceCode" id="cb576"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb576-1"><a href="09-calculo-bayes.html#cb576-1" aria-hidden="true" tabindex="-1"></a>modal.sds <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(fit<span class="sc">$</span>var))</span>
<span id="cb576-2"><a href="09-calculo-bayes.html#cb576-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="fu">c</span>(fit<span class="sc">$</span>mode), modal.sds)</span></code></pre></div>
<pre><code>##                 modal.sds
## [1,] 70.169880 0.18800834
## [2,]  0.973644 0.05609341</code></pre>
<p>También podemos graficar la densidad posterior junto con la muestra generada por el MH, usando una muestra de burn-in de 5000:</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb578-1"><a href="09-calculo-bayes.html#cb578-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(groupeddatapost, <span class="fu">c</span>(<span class="dv">69</span>, <span class="dv">71</span>, <span class="fl">0.6</span>, <span class="fl">1.3</span>), d,</span>
<span id="cb578-2"><a href="09-calculo-bayes.html#cb578-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;mu&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;log sigma&quot;</span>)</span>
<span id="cb578-3"><a href="09-calculo-bayes.html#cb578-3" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(fit2<span class="sc">$</span>par[<span class="dv">5001</span><span class="sc">:</span><span class="dv">10000</span>, <span class="dv">1</span>], fit2<span class="sc">$</span>par[<span class="dv">5001</span><span class="sc">:</span><span class="dv">10000</span>,</span>
<span id="cb578-4"><a href="09-calculo-bayes.html#cb578-4" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span>])</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-333-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>Los traceplots del MCMC los graficamos a través del paquete <em>coda</em> junto con el paquete <em>bayesplot</em>:</p>
<div class="sourceCode" id="cb579"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb579-1"><a href="09-calculo-bayes.html#cb579-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(coda)</span>
<span id="cb579-2"><a href="09-calculo-bayes.html#cb579-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bayesplot)</span>
<span id="cb579-3"><a href="09-calculo-bayes.html#cb579-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dimnames</span>(fit2<span class="sc">$</span>par)[[<span class="dv">2</span>]] <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;log sigma&quot;</span>)</span>
<span id="cb579-4"><a href="09-calculo-bayes.html#cb579-4" aria-hidden="true" tabindex="-1"></a>obj_mcmc <span class="ot">&lt;-</span> <span class="fu">mcmc</span>(fit2<span class="sc">$</span>par[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5000</span>), ])</span>
<span id="cb579-5"><a href="09-calculo-bayes.html#cb579-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_trace</span>(obj_mcmc)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-334-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>Los gráficos de autocorrelación empíricos se pueden generar con:</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb580-1"><a href="09-calculo-bayes.html#cb580-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_acf</span>(obj_mcmc)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-335-1.svg" width="100%" style="display: block; margin: auto;" />
y funciones de densidad estimadas con intervalos de predicción al 95% para algunos de los parámetros:</p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb581-1"><a href="09-calculo-bayes.html#cb581-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_areas</span>(obj_mcmc, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;mu&quot;</span>), <span class="at">prob =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-336-1.svg" width="100%" style="display: block; margin: auto;" />
### Datos con outliers</p>
<p>Suponga <span class="math inline">\(y_1,\ldots,y_n\sim \text{Cauchy}(\mu,\sigma)\)</span>:
<span class="math display">\[f(y|\mu,\sigma)=\frac{1}{\pi\sigma(1+z^2)}\]</span>
donde <span class="math inline">\(z=\frac{y-\mu}{\sigma}\)</span>. Con una previa no informativa <span class="math inline">\(g(\mu,\sigma)\propto 1/\sigma\)</span> y transformando <span class="math inline">\(\lambda = \log \sigma\)</span> se puede comprobar que la log-densidad posterior es:
<span class="math display">\[\log g(\mu,\lambda|\text{datos}) = \sum_{i=1}^n\left[-\lambda-\log\left(1+\exp(-2\lambda)(y_i-\mu)^2\right)\right]\]</span></p>
<p>y la implementación de la log-posterior usando la distribución t de Student como generador de la distribución Cauchy:</p>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb582-1"><a href="09-calculo-bayes.html#cb582-1" aria-hidden="true" tabindex="-1"></a>cauchyerrorpost <span class="ot">&lt;-</span> <span class="cf">function</span>(theta, data) {</span>
<span id="cb582-2"><a href="09-calculo-bayes.html#cb582-2" aria-hidden="true" tabindex="-1"></a>    logf <span class="ot">&lt;-</span> <span class="cf">function</span>(data, theta) <span class="fu">log</span>(<span class="fu">dt</span>((data <span class="sc">-</span> theta[<span class="dv">1</span>])<span class="sc">/</span><span class="fu">exp</span>(theta[<span class="dv">2</span>]),</span>
<span id="cb582-3"><a href="09-calculo-bayes.html#cb582-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">df =</span> <span class="dv">1</span>)<span class="sc">/</span><span class="fu">exp</span>(theta[<span class="dv">2</span>]))</span>
<span id="cb582-4"><a href="09-calculo-bayes.html#cb582-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">sum</span>(<span class="fu">logf</span>(data, theta)))</span>
<span id="cb582-5"><a href="09-calculo-bayes.html#cb582-5" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Los datos provienen de la base <em>darwin</em> con 15 diferencias entre alturas de plantas según Fisher (1960). La media y log-desviación estándar empíricos de los datos son:</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="09-calculo-bayes.html#cb583-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(darwin)</span>
<span id="cb583-2"><a href="09-calculo-bayes.html#cb583-2" aria-hidden="true" tabindex="-1"></a>data_darwin <span class="ot">&lt;-</span> darwin<span class="sc">$</span>difference</span>
<span id="cb583-3"><a href="09-calculo-bayes.html#cb583-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(data_darwin)</span></code></pre></div>
<pre><code>## [1] NA</code></pre>
<div class="sourceCode" id="cb585"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb585-1"><a href="09-calculo-bayes.html#cb585-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="fu">sd</span>(data_darwin))</span></code></pre></div>
<pre><code>## [1] NA</code></pre>
<p>y usamos estos valores como valores iniciales dentro de la aproximación de Laplace:</p>
<div class="sourceCode" id="cb587"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb587-1"><a href="09-calculo-bayes.html#cb587-1" aria-hidden="true" tabindex="-1"></a>fitlaplace <span class="ot">&lt;-</span> <span class="fu">laplace</span>(cauchyerrorpost, <span class="fu">c</span>(<span class="fl">21.6</span>, <span class="fl">3.6</span>),</span>
<span id="cb587-2"><a href="09-calculo-bayes.html#cb587-2" aria-hidden="true" tabindex="-1"></a>    data_darwin)</span></code></pre></div>
<pre><code>## Error in solve.default(fit$hessian): Lapack routine dgesv: system is exactly singular: U[1,1] = 0</code></pre>
<div class="sourceCode" id="cb589"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb589-1"><a href="09-calculo-bayes.html#cb589-1" aria-hidden="true" tabindex="-1"></a>fitlaplace</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;fitlaplace&#39; not found</code></pre>
<p>y usamos lo anterior como insumo para generar tres escenarios de MCMC:</p>
<ul>
<li>Metropolis-Hastings con caminata aleatoria:</li>
</ul>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="09-calculo-bayes.html#cb591-1" aria-hidden="true" tabindex="-1"></a>proposal <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">var =</span> fitlaplace<span class="sc">$</span>var, <span class="at">scale =</span> <span class="fl">2.5</span>)</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;fitlaplace&#39; not found</code></pre>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="09-calculo-bayes.html#cb593-1" aria-hidden="true" tabindex="-1"></a>start <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">20</span>, <span class="dv">3</span>)</span>
<span id="cb593-2"><a href="09-calculo-bayes.html#cb593-2" aria-hidden="true" tabindex="-1"></a>E1 <span class="ot">&lt;-</span> <span class="fu">rwmetrop</span>(cauchyerrorpost, proposal, start, <span class="dv">50000</span>,</span>
<span id="cb593-3"><a href="09-calculo-bayes.html#cb593-3" aria-hidden="true" tabindex="-1"></a>    data_darwin)</span>
<span id="cb593-4"><a href="09-calculo-bayes.html#cb593-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(cauchyerrorpost, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">60</span>, <span class="dv">1</span>, <span class="fl">4.5</span>), data_darwin,</span>
<span id="cb593-5"><a href="09-calculo-bayes.html#cb593-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;mu&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;log sigma&quot;</span>)</span>
<span id="cb593-6"><a href="09-calculo-bayes.html#cb593-6" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(E1<span class="sc">$</span>par[, <span class="dv">1</span>], E1<span class="sc">$</span>par[, <span class="dv">2</span>])</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-340-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<ul>
<li>Metropolis-Hastings independiente:</li>
</ul>
<div class="sourceCode" id="cb594"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb594-1"><a href="09-calculo-bayes.html#cb594-1" aria-hidden="true" tabindex="-1"></a>proposal2 <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">var =</span> fitlaplace<span class="sc">$</span>var, <span class="at">mu =</span> <span class="fu">t</span>(fitlaplace<span class="sc">$</span>mode))</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;fitlaplace&#39; not found</code></pre>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb596-1"><a href="09-calculo-bayes.html#cb596-1" aria-hidden="true" tabindex="-1"></a>E2 <span class="ot">&lt;-</span> <span class="fu">indepmetrop</span>(cauchyerrorpost, proposal2, start,</span>
<span id="cb596-2"><a href="09-calculo-bayes.html#cb596-2" aria-hidden="true" tabindex="-1"></a>    <span class="dv">50000</span>, data_darwin)</span></code></pre></div>
<pre><code>## Error in matrix(proposal$mu): object &#39;proposal2&#39; not found</code></pre>
<div class="sourceCode" id="cb598"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb598-1"><a href="09-calculo-bayes.html#cb598-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(cauchyerrorpost, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">60</span>, <span class="dv">1</span>, <span class="fl">4.5</span>), data_darwin,</span>
<span id="cb598-2"><a href="09-calculo-bayes.html#cb598-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;mu&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;log sigma&quot;</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-341-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb599-1"><a href="09-calculo-bayes.html#cb599-1" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(E2<span class="sc">$</span>par[, <span class="dv">1</span>], E2<span class="sc">$</span>par[, <span class="dv">2</span>])</span></code></pre></div>
<pre><code>## Error in points(E2$par[, 1], E2$par[, 2]): object &#39;E2&#39; not found</code></pre>
<ul>
<li>Muestreo de Gibbs:</li>
</ul>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb601-1"><a href="09-calculo-bayes.html#cb601-1" aria-hidden="true" tabindex="-1"></a>E3 <span class="ot">&lt;-</span> <span class="fu">gibbs</span>(cauchyerrorpost, start, <span class="dv">50000</span>, <span class="fu">c</span>(<span class="dv">12</span>, <span class="fl">0.75</span>),</span>
<span id="cb601-2"><a href="09-calculo-bayes.html#cb601-2" aria-hidden="true" tabindex="-1"></a>    data_darwin)</span>
<span id="cb601-3"><a href="09-calculo-bayes.html#cb601-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mycontour</span>(cauchyerrorpost, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="dv">60</span>, <span class="dv">1</span>, <span class="fl">4.5</span>), data_darwin,</span>
<span id="cb601-4"><a href="09-calculo-bayes.html#cb601-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;mu&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;log sigma&quot;</span>)</span>
<span id="cb601-5"><a href="09-calculo-bayes.html#cb601-5" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(E3<span class="sc">$</span>par[, <span class="dv">1</span>], E3<span class="sc">$</span>par[, <span class="dv">2</span>])</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-342-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>Comparemos el estimador bayesiano e intervalos de predicción al 95% para la media <span class="math inline">\(\mu\)</span>:</p>
<div class="sourceCode" id="cb602"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb602-1"><a href="09-calculo-bayes.html#cb602-1" aria-hidden="true" tabindex="-1"></a>Resultados <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">rbind</span>(<span class="fu">c</span>(<span class="fu">mean</span>(E1<span class="sc">$</span>par[, <span class="dv">1</span>]),</span>
<span id="cb602-2"><a href="09-calculo-bayes.html#cb602-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">quantile</span>(E1<span class="sc">$</span>par[, <span class="dv">1</span>], <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>)),</span>
<span id="cb602-3"><a href="09-calculo-bayes.html#cb602-3" aria-hidden="true" tabindex="-1"></a>    E1<span class="sc">$</span>accept), <span class="fu">c</span>(<span class="fu">mean</span>(E2<span class="sc">$</span>par[, <span class="dv">1</span>]), <span class="fu">quantile</span>(E2<span class="sc">$</span>par[,</span>
<span id="cb602-4"><a href="09-calculo-bayes.html#cb602-4" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span>], <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>)), E2<span class="sc">$</span>accept), <span class="fu">c</span>(<span class="fu">mean</span>(E3<span class="sc">$</span>par[,</span>
<span id="cb602-5"><a href="09-calculo-bayes.html#cb602-5" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span>]), <span class="fu">quantile</span>(E3<span class="sc">$</span>par[, <span class="dv">1</span>], <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>)),</span>
<span id="cb602-6"><a href="09-calculo-bayes.html#cb602-6" aria-hidden="true" tabindex="-1"></a>    <span class="cn">NA</span>)))</span></code></pre></div>
<pre><code>## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;mean&#39;: object &#39;E2&#39; not found</code></pre>
<div class="sourceCode" id="cb604"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb604-1"><a href="09-calculo-bayes.html#cb604-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(Resultados) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Media&quot;</span>, <span class="st">&quot;Q1&quot;</span>, <span class="st">&quot;Q3&quot;</span>, <span class="st">&quot;Accept&quot;</span>)</span></code></pre></div>
<pre><code>## Error in colnames(Resultados) &lt;- c(&quot;Media&quot;, &quot;Q1&quot;, &quot;Q3&quot;, &quot;Accept&quot;): object &#39;Resultados&#39; not found</code></pre>
<div class="sourceCode" id="cb606"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb606-1"><a href="09-calculo-bayes.html#cb606-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(Resultados) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;MH-RW&quot;</span>, <span class="st">&quot;MH-Indep&quot;</span>, <span class="st">&quot;Gibbs&quot;</span>)</span></code></pre></div>
<pre><code>## Error in rownames(Resultados) &lt;- c(&quot;MH-RW&quot;, &quot;MH-Indep&quot;, &quot;Gibbs&quot;): object &#39;Resultados&#39; not found</code></pre>
<div class="sourceCode" id="cb608"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb608-1"><a href="09-calculo-bayes.html#cb608-1" aria-hidden="true" tabindex="-1"></a>Resultados <span class="ot">&lt;-</span> Resultados <span class="sc">%&gt;%</span></span>
<span id="cb608-2"><a href="09-calculo-bayes.html#cb608-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">Ancho =</span> Q3 <span class="sc">-</span> Q1)</span></code></pre></div>
<pre><code>## Error in mutate(., Ancho = Q3 - Q1): object &#39;Resultados&#39; not found</code></pre>
<div class="sourceCode" id="cb610"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb610-1"><a href="09-calculo-bayes.html#cb610-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(knitr)</span>
<span id="cb610-2"><a href="09-calculo-bayes.html#cb610-2" aria-hidden="true" tabindex="-1"></a><span class="fu">kable</span>(Resultados)</span></code></pre></div>
<pre><code>## Error in kable(Resultados): object &#39;Resultados&#39; not found</code></pre>
<p>En el caso del algoritmo de Gibbs, cada uno de los pasos tiene una tasa de aceptación de MH en este caso:</p>
<div class="sourceCode" id="cb612"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb612-1"><a href="09-calculo-bayes.html#cb612-1" aria-hidden="true" tabindex="-1"></a>E3<span class="sc">$</span>accept</span></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]    1    1</code></pre>
<p>También podemos incluir histogramas para las muestras posteriores de ambos parámetros. Para el MH independiente (burn-in=5000):</p>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb614-1"><a href="09-calculo-bayes.html#cb614-1" aria-hidden="true" tabindex="-1"></a><span class="fu">color_scheme_set</span>(<span class="st">&quot;green&quot;</span>)</span>
<span id="cb614-2"><a href="09-calculo-bayes.html#cb614-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dimnames</span>(E2<span class="sc">$</span>par)[[<span class="dv">2</span>]] <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;log sigma&quot;</span>)</span></code></pre></div>
<pre><code>## Error in dimnames(E2$par)[[2]] &lt;- c(&quot;mu&quot;, &quot;log sigma&quot;): object &#39;E2&#39; not found</code></pre>
<div class="sourceCode" id="cb616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb616-1"><a href="09-calculo-bayes.html#cb616-1" aria-hidden="true" tabindex="-1"></a>obj_mcmc2 <span class="ot">&lt;-</span> <span class="fu">mcmc</span>(E2<span class="sc">$</span>par[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5000</span>), ])</span></code></pre></div>
<pre><code>## Error in mcmc(E2$par[-c(1:5000), ]): object &#39;E2&#39; not found</code></pre>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb618-1"><a href="09-calculo-bayes.html#cb618-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_hist</span>(obj_mcmc2, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;log sigma&quot;</span>))</span></code></pre></div>
<pre><code>## Error in posterior::is_draws(x): object &#39;obj_mcmc2&#39; not found</code></pre>
<p>y los gráficos de autocorrelación respectivos:</p>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb620-1"><a href="09-calculo-bayes.html#cb620-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_acf_bar</span>(obj_mcmc2, <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;log sigma&quot;</span>))</span></code></pre></div>
<pre><code>## Error in posterior::is_draws(x): object &#39;obj_mcmc2&#39; not found</code></pre>
</div>
</div>
<div id="ejercicios-6" class="section level2 hasAnchor" number="8.18">
<h2><span class="header-section-number">8.18</span> Ejercicios<a href="09-calculo-bayes.html#ejercicios-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Del libro <span class="citation">(Albert et al. 2009)</span>
<ul>
<li>Capítulo 5: 1, 2, 4, 5.</li>
<li>Capítulo 6: 3, 5, 6, 10.</li>
</ul></li>
</ul>

<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
Albert, Jim, Robert Gentleman, Giovanni Parmigiani, and Kurt Hornik. 2009. <em>Bayesian Computation with <span>R</span></em>. <em>Bayesian Computation with R</em>. <span>New York, NY</span>: <span>Springer New York</span>. <a href="https://doi.org/10.1007/978-0-387-92298-0">https://doi.org/10.1007/978-0-387-92298-0</a>.
</div>
<div class="csl-entry">
Cavanaugh, Joseph E., and Andrew A. Neath. 2019. <span>“The <span>Akaike</span> Information Criterion: <span>Background</span>, Derivation, Properties, Application, Interpretation, and Refinements.”</span> <em>WIREs Computational Statistics</em> 11 (3): e1460. <a href="https://doi.org/10.1002/wics.1460">https://doi.org/10.1002/wics.1460</a>.
</div>
<div class="csl-entry">
Efron, B. 1979. <span>“Bootstrap <span>Methods</span>: <span>Another Look</span> at the <span>Jackknife</span>.”</span> <em>The Annals of Statistics</em> 7 (1): 1–26. <a href="https://doi.org/10.1214/aos/1176344552">https://doi.org/10.1214/aos/1176344552</a>.
</div>
<div class="csl-entry">
Hall, Peter. 1987. <span>“On <span>Kullback</span>-<span>Leibler Loss</span> and <span>Density Estimation</span>.”</span> <em>The Annals of Statistics</em> 15 (4): 1491–1519. <a href="https://doi.org/10.1214/aos/1176350606">https://doi.org/10.1214/aos/1176350606</a>.
</div>
<div class="csl-entry">
Härdle, Wolfgang, Axel Werwatz, Marlene Müller, and Stefan Sperlich. 2004. <em>Nonparametric and <span>Semiparametric Models</span></em>. <span>Berlin, Heidelberg</span>: <span>Springer Berlin Heidelberg</span>. <a href="https://doi.org/10.1007/978-3-642-17146-8">https://doi.org/10.1007/978-3-642-17146-8</a>.
</div>
<div class="csl-entry">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em>The <span>Elements</span> of <span>Statistical Learning</span>: <span>Data</span> Mining, <span>Inference</span>, and <span>Prediction</span></em>. <span>New York</span>: <span>Springer</span>. <a href="https://doi.org/10.1007/978-0-387-84858-7">https://doi.org/10.1007/978-0-387-84858-7</a>.
</div>
<div class="csl-entry">
Husson, Francois, Sebastien Le, and Jérôme Pagès. 2017. <em>Exploratory <span>Multivariate Analysis</span> by <span>Example Using R</span></em>. <span>CRC Press</span>.
</div>
<div class="csl-entry">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An <span>Introduction</span> to <span>Statistical Learning</span></em>. Vol. 103. <span>New York, NY</span>: <span>Springer New York</span>. <a href="https://doi.org/10.1007/978-1-4614-7138-7">https://doi.org/10.1007/978-1-4614-7138-7</a>.
</div>
<div class="csl-entry">
Quenouille, M. H. 1949. <span>“Approximate <span>Tests</span> of <span>Correlation</span> in <span>Time</span>-<span>Series</span>.”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 11 (1): 68–84. <a href="https://doi.org/10.1111/j.2517-6161.1949.tb00023.x">https://doi.org/10.1111/j.2517-6161.1949.tb00023.x</a>.
</div>
<div class="csl-entry">
Stone, M. 1977. <span>“An <span>Asymptotic Equivalence</span> of <span>Choice</span> of <span>Model</span> by <span>Cross</span>-<span>Validation</span> and <span>Akaike</span>’s <span>Criterion</span>.”</span> <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 39 (1): 44–47.
</div>
<div class="csl-entry">
Wasserman, Larry. 2006. <em>All of <span>Nonparametric Statistics</span></em>. <em>All of Nonparametric Statistics</em>. <span>New York, NY</span>: <span>Springer New York</span>. <a href="https://doi.org/10.1007/0-387-30623-4">https://doi.org/10.1007/0-387-30623-4</a>.
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="08-clasificacion.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica/edit/master/09-calculo-bayes.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica/blob/master/09-calculo-bayes.Rmd",
"text": null
},
"download": ["Notas-Curso-Estadistica.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"toc_depth": 5
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
