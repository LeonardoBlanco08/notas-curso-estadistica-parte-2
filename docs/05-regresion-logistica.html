<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 5 Regresión Logística | Notas Curso de Estadística II</title>
  <meta name="description" content="Capítulo 5 Regresión Logística | Notas Curso de Estadística II" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 5 Regresión Logística | Notas Curso de Estadística II" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 5 Regresión Logística | Notas Curso de Estadística II" />
  
  
  

<meta name="author" content="Maikol Solís Chacón y Luis Barboza Chinchilla" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="04-metodos-lineares-regresion.html"/>
<link rel="next" href="06-seleccion-de-variables.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso de Estadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html"><i class="fa fa-check"></i><b>2</b> Estimación no-paramétrica de densidades</a>
<ul>
<li class="chapter" data-level="2.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#histograma"><i class="fa fa-check"></i><b>2.1</b> Histograma</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#construcción-estadística"><i class="fa fa-check"></i><b>2.1.1</b> Construcción Estadística</a></li>
<li class="chapter" data-level="2.1.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#construcción-probabilística"><i class="fa fa-check"></i><b>2.1.2</b> Construcción probabilística</a></li>
<li class="chapter" data-level="2.1.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas"><i class="fa fa-check"></i><b>2.1.3</b> Propiedades estadísticas</a></li>
<li class="chapter" data-level="2.1.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas-1"><i class="fa fa-check"></i><b>2.1.4</b> Propiedades estadísticas</a></li>
<li class="chapter" data-level="2.1.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#sesgo"><i class="fa fa-check"></i><b>2.1.5</b> Sesgo</a></li>
<li class="chapter" data-level="2.1.6" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#varianza"><i class="fa fa-check"></i><b>2.1.6</b> Varianza</a></li>
<li class="chapter" data-level="2.1.7" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio"><i class="fa fa-check"></i><b>2.1.7</b> Error cuadrático medio</a></li>
<li class="chapter" data-level="2.1.8" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio-integrado"><i class="fa fa-check"></i><b>2.1.8</b> Error cuadrático medio integrado</a></li>
<li class="chapter" data-level="2.1.9" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo-para-el-histograma"><i class="fa fa-check"></i><b>2.1.9</b> Ancho de banda óptimo para el histograma</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#estimación-de-densidades-basada-en-kernels."><i class="fa fa-check"></i><b>2.2</b> Estimación de densidades basada en kernels.</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#primera-construcción"><i class="fa fa-check"></i><b>2.2.1</b> Primera construcción</a></li>
<li class="chapter" data-level="2.2.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#otra-construcción"><i class="fa fa-check"></i><b>2.2.2</b> Otra construcción</a></li>
<li class="chapter" data-level="2.2.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#propiedades-estadísticas-2"><i class="fa fa-check"></i><b>2.2.3</b> Propiedades Estadísticas</a></li>
<li class="chapter" data-level="2.2.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#sesgo-1"><i class="fa fa-check"></i><b>2.2.4</b> Sesgo</a></li>
<li class="chapter" data-level="2.2.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#error-cuadrático-medio-y-error-cuadrático-medio-integrado"><i class="fa fa-check"></i><b>2.2.5</b> Error cuadrático medio y Error cuadrático medio integrado</a></li>
<li class="chapter" data-level="2.2.6" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo"><i class="fa fa-check"></i><b>2.2.6</b> Ancho de banda óptimo</a></li>
<li class="chapter" data-level="2.2.7" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#intervalos-de-confianza-para-estimadores-de-densidad-no-paramétricos"><i class="fa fa-check"></i><b>2.2.7</b> Intervalos de confianza para estimadores de densidad no paramétricos</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#laboratorio"><i class="fa fa-check"></i><b>2.3</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#efecto-de-distintos-kernels-en-la-estimación"><i class="fa fa-check"></i><b>2.3.1</b> Efecto de distintos Kernels en la estimación</a></li>
<li class="chapter" data-level="2.3.2" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#efecto-del-ancho-de-banda-en-la-estimación"><i class="fa fa-check"></i><b>2.3.2</b> Efecto del ancho de banda en la estimación</a></li>
<li class="chapter" data-level="2.3.3" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ancho-de-banda-óptimo-1"><i class="fa fa-check"></i><b>2.3.3</b> Ancho de banda óptimo</a></li>
<li class="chapter" data-level="2.3.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#validación-cruzada-1"><i class="fa fa-check"></i><b>2.3.4</b> Validación cruzada</a></li>
<li class="chapter" data-level="2.3.5" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#temas-adicionales"><i class="fa fa-check"></i><b>2.3.5</b> Temas adicionales</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="01-estimacion-densidades-no-parametricas.html"><a href="01-estimacion-densidades-no-parametricas.html#ejercicios"><i class="fa fa-check"></i><b>2.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html"><i class="fa fa-check"></i><b>3</b> Jackknife y Bootstrap</a>
<ul>
<li class="chapter" data-level="3.1" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#caso-concreto"><i class="fa fa-check"></i><b>3.1</b> Caso concreto</a></li>
<li class="chapter" data-level="3.2" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#jackknife"><i class="fa fa-check"></i><b>3.2</b> Jackknife</a></li>
<li class="chapter" data-level="3.3" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#bootstrap"><i class="fa fa-check"></i><b>3.3</b> Bootstrap</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>3.3.1</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="3.3.2" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#resumiendo"><i class="fa fa-check"></i><b>3.3.2</b> Resumiendo</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="02-jacknife-bootstrap.html"><a href="02-jacknife-bootstrap.html#ejercicios-1"><i class="fa fa-check"></i><b>3.4</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html"><i class="fa fa-check"></i><b>4</b> Métodos lineales de regresión</a>
<ul>
<li class="chapter" data-level="4.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#introducción-al-aprendizaje-estadístico."><i class="fa fa-check"></i><b>4.1</b> Introducción al Aprendizaje Estadístico.</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#formas-de-estimar-f"><i class="fa fa-check"></i><b>4.1.1</b> Formas de estimar <span class="math inline">\(f\)</span></a></li>
<li class="chapter" data-level="4.1.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#medidas-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>4.1.2</b> Medidas de bondad de ajuste</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#regresión-lineal"><i class="fa fa-check"></i><b>4.2</b> Regresión lineal</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#forma-matricial"><i class="fa fa-check"></i><b>4.2.1</b> Forma matricial</a></li>
<li class="chapter" data-level="4.2.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-1"><i class="fa fa-check"></i><b>4.2.2</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#propiedades-estadísticas-3"><i class="fa fa-check"></i><b>4.3</b> Propiedades estadísticas</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#prueba-t"><i class="fa fa-check"></i><b>4.3.1</b> Prueba <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="4.3.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#prueba-f"><i class="fa fa-check"></i><b>4.3.2</b> Prueba <span class="math inline">\(F\)</span></a></li>
<li class="chapter" data-level="4.3.3" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-2"><i class="fa fa-check"></i><b>4.3.3</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#medida-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>4.4</b> Medida de bondad de ajuste</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-3"><i class="fa fa-check"></i><b>4.4.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#predicción"><i class="fa fa-check"></i><b>4.5</b> Predicción</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-4"><i class="fa fa-check"></i><b>4.5.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#interacciones"><i class="fa fa-check"></i><b>4.6</b> Interacciones</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#laboratorio-5"><i class="fa fa-check"></i><b>4.6.1</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#supuestos"><i class="fa fa-check"></i><b>4.7</b> Supuestos</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#chequeos-básicos-de-las-hipótesis-de-regresión-lineal"><i class="fa fa-check"></i><b>4.7.1</b> Chequeos básicos de las hipótesis de regresión lineal</a></li>
<li class="chapter" data-level="4.7.2" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#otros-chequeos-importantes"><i class="fa fa-check"></i><b>4.7.2</b> Otros chequeos importantes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="04-metodos-lineares-regresion.html"><a href="04-metodos-lineares-regresion.html#ejercicios-2"><i class="fa fa-check"></i><b>4.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html"><i class="fa fa-check"></i><b>5</b> Regresión Logística</a>
<ul>
<li class="chapter" data-level="5.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#preliminares"><i class="fa fa-check"></i><b>5.1</b> Preliminares</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#oportunidad-relativa-odds-ratio"><i class="fa fa-check"></i><b>5.1.1</b> Oportunidad relativa (Odds Ratio)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#máxima-verosimilitud"><i class="fa fa-check"></i><b>5.2</b> Máxima verosimilitud</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#resultados-adicionales"><i class="fa fa-check"></i><b>5.2.1</b> Resultados adicionales</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#diágnosticos-del-modelo"><i class="fa fa-check"></i><b>5.3</b> Diágnosticos del modelo</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#supuesto-de-linealidad"><i class="fa fa-check"></i><b>5.3.1</b> Supuesto de linealidad</a></li>
<li class="chapter" data-level="5.3.2" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#valores-de-gran-influencia"><i class="fa fa-check"></i><b>5.3.2</b> Valores de gran influencia</a></li>
<li class="chapter" data-level="5.3.3" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#multicolinealidad-1"><i class="fa fa-check"></i><b>5.3.3</b> Multicolinealidad</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#predicción-y-poder-de-clasificación"><i class="fa fa-check"></i><b>5.4</b> Predicción y poder de clasificación</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#curva-roc"><i class="fa fa-check"></i><b>5.4.1</b> Curva ROC</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="05-regresion-logistica.html"><a href="05-regresion-logistica.html#ejercicios-3"><i class="fa fa-check"></i><b>5.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html"><i class="fa fa-check"></i><b>6</b> Métodos de selección de variables y regularización</a>
<ul>
<li class="chapter" data-level="6.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#estimación-del-error-de-prueba"><i class="fa fa-check"></i><b>6.1</b> Estimación del error de prueba</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#técnica-de-conjunto-de-validación"><i class="fa fa-check"></i><b>6.1.1</b> Técnica de conjunto de validación</a></li>
<li class="chapter" data-level="6.1.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-leave-one-out-loocv"><i class="fa fa-check"></i><b>6.1.2</b> Validación cruzada “Leave-One-Out” (LOOCV)</a></li>
<li class="chapter" data-level="6.1.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-k-veces"><i class="fa fa-check"></i><b>6.1.3</b> Validación cruzada <span class="math inline">\(k-\)</span>veces</a></li>
<li class="chapter" data-level="6.1.4" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#validación-cruzada-para-clasificación"><i class="fa fa-check"></i><b>6.1.4</b> Validación cruzada para clasificación</a></li>
<li class="chapter" data-level="6.1.5" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#otras-medidas-de-error-de-prueba"><i class="fa fa-check"></i><b>6.1.5</b> Otras medidas de error de prueba</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-variables"><i class="fa fa-check"></i><b>6.2</b> Selección de variables</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-del-mejor-subconjunto."><i class="fa fa-check"></i><b>6.2.1</b> Selección del mejor subconjunto.</a></li>
<li class="chapter" data-level="6.2.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-modelos-hacia-adelante-forward-stepwise-selection"><i class="fa fa-check"></i><b>6.2.2</b> Selección de modelos hacia adelante (<strong>Forward Stepwise Selection</strong>)</a></li>
<li class="chapter" data-level="6.2.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#selección-de-modelos-hacia-atrás-backward-stepwise-selection"><i class="fa fa-check"></i><b>6.2.3</b> Selección de modelos hacia atrás (<strong>Backward Stepwise Selection</strong>)</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#métodos-de-regularización"><i class="fa fa-check"></i><b>6.3</b> Métodos de regularización</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-ridge"><i class="fa fa-check"></i><b>6.3.1</b> Regresión Ridge</a></li>
<li class="chapter" data-level="6.3.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-lasso"><i class="fa fa-check"></i><b>6.3.2</b> Regresión Lasso</a></li>
<li class="chapter" data-level="6.3.3" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#explicación-gráfica"><i class="fa fa-check"></i><b>6.3.3</b> Explicación gráfica</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#laboratorio-6"><i class="fa fa-check"></i><b>6.4</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#cross-validation"><i class="fa fa-check"></i><b>6.4.1</b> Cross-Validation</a></li>
<li class="chapter" data-level="6.4.2" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#regresión-lasso-1"><i class="fa fa-check"></i><b>6.4.2</b> Regresión Lasso</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="06-seleccion-de-variables.html"><a href="06-seleccion-de-variables.html#ejercicios-4"><i class="fa fa-check"></i><b>6.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="08-clasificacion.html"><a href="08-clasificacion.html"><i class="fa fa-check"></i><b>7</b> Otros Clasificadores</a>
<ul>
<li class="chapter" data-level="7.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#clasificador-bayesiano"><i class="fa fa-check"></i><b>7.1</b> Clasificador Bayesiano</a></li>
<li class="chapter" data-level="7.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#método-de-k-vecinos-más-cercanos-knn"><i class="fa fa-check"></i><b>7.2</b> Método de k vecinos más cercanos (KNN)</a></li>
<li class="chapter" data-level="7.3" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante"><i class="fa fa-check"></i><b>7.3</b> Análisis Discriminante</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-lineal"><i class="fa fa-check"></i><b>7.3.1</b> Análisis discriminante lineal</a></li>
<li class="chapter" data-level="7.3.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-cuadrático"><i class="fa fa-check"></i><b>7.3.2</b> Análisis discriminante cuadrático</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="08-clasificacion.html"><a href="08-clasificacion.html#laboratorio-7"><i class="fa fa-check"></i><b>7.4</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="08-clasificacion.html"><a href="08-clasificacion.html#clasificador-logístico"><i class="fa fa-check"></i><b>7.4.1</b> Clasificador logístico</a></li>
<li class="chapter" data-level="7.4.2" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-lineal-1"><i class="fa fa-check"></i><b>7.4.2</b> Análisis Discriminante Lineal</a></li>
<li class="chapter" data-level="7.4.3" data-path="08-clasificacion.html"><a href="08-clasificacion.html#análisis-discriminante-cuadrático-1"><i class="fa fa-check"></i><b>7.4.3</b> Análisis Discriminante Cuadrático</a></li>
<li class="chapter" data-level="7.4.4" data-path="08-clasificacion.html"><a href="08-clasificacion.html#k-vecinos-más-cercanos"><i class="fa fa-check"></i><b>7.4.4</b> K vecinos más cercanos</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="08-clasificacion.html"><a href="08-clasificacion.html#ejercicios-5"><i class="fa fa-check"></i><b>7.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html"><i class="fa fa-check"></i><b>8</b> Análisis en componentes principales</a>
<ul>
<li class="chapter" data-level="8.1" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#representación-gráfica"><i class="fa fa-check"></i><b>8.1</b> Representación gráfica</a></li>
<li class="chapter" data-level="8.2" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#aprendizaje-no-supervisado"><i class="fa fa-check"></i><b>8.2</b> Aprendizaje no-supervisado</a></li>
<li class="chapter" data-level="8.3" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#primer-componente-principal"><i class="fa fa-check"></i><b>8.3</b> Primer componente principal</a></li>
<li class="chapter" data-level="8.4" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#segunda-componente-principal"><i class="fa fa-check"></i><b>8.4</b> Segunda componente principal</a></li>
<li class="chapter" data-level="8.5" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#circulo-de-correlaciones"><i class="fa fa-check"></i><b>8.5</b> Circulo de correlaciones</a></li>
<li class="chapter" data-level="8.6" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#volvamos-a-nuestro-ejemplo"><i class="fa fa-check"></i><b>8.6</b> Volvamos a nuestro ejemplo</a></li>
<li class="chapter" data-level="8.7" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#cuántos-componentes-usar"><i class="fa fa-check"></i><b>8.7</b> ¿Cuántos componentes usar?</a></li>
<li class="chapter" data-level="8.8" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#laboratorio-8"><i class="fa fa-check"></i><b>8.8</b> Laboratorio</a></li>
<li class="chapter" data-level="8.9" data-path="07-componentes-principales.html"><a href="07-componentes-principales.html#ejercicios-6"><i class="fa fa-check"></i><b>8.9</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html"><i class="fa fa-check"></i><b>9</b> Cálculo Bayesiano Computacional</a>
<ul>
<li class="chapter" data-level="9.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#repaso-de-estadística-bayesiana"><i class="fa fa-check"></i><b>9.1</b> Repaso de Estadística Bayesiana</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#modelo-de-un-parámetro"><i class="fa fa-check"></i><b>9.1.1</b> Modelo de un parámetro</a></li>
<li class="chapter" data-level="9.1.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#modelo-de-más-de-un-parámetro"><i class="fa fa-check"></i><b>9.1.2</b> Modelo de más de un parámetro</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#motivación-cálculo-de-integrales"><i class="fa fa-check"></i><b>9.2</b> Motivación: Cálculo de Integrales</a></li>
<li class="chapter" data-level="9.3" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejemplo-base-modelo-beta-binomial."><i class="fa fa-check"></i><b>9.3</b> Ejemplo base: modelo beta-binomial.</a></li>
<li class="chapter" data-level="9.4" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#aproximación-de-laplace"><i class="fa fa-check"></i><b>9.4</b> Aproximación de Laplace</a></li>
<li class="chapter" data-level="9.5" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#simulación"><i class="fa fa-check"></i><b>9.5</b> Simulación</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#simulación-monte-carlo"><i class="fa fa-check"></i><b>9.5.1</b> Simulación Monte Carlo</a></li>
<li class="chapter" data-level="9.5.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#muestreo-por-rechazo"><i class="fa fa-check"></i><b>9.5.2</b> Muestreo por rechazo</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#muestreo-por-importancia"><i class="fa fa-check"></i><b>9.6</b> Muestreo por importancia</a></li>
<li class="chapter" data-level="9.7" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#remuestreo-por-importancia"><i class="fa fa-check"></i><b>9.7</b> Remuestreo por importancia</a></li>
<li class="chapter" data-level="9.8" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#métodos-monte-carlo"><i class="fa fa-check"></i><b>9.8</b> Métodos Monte Carlo</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejemplo-del-viajero-con-una-moneda"><i class="fa fa-check"></i><b>9.8.1</b> Ejemplo del viajero con una moneda</a></li>
<li class="chapter" data-level="9.8.2" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#cadenas-de-markov"><i class="fa fa-check"></i><b>9.8.2</b> Cadenas de Markov</a></li>
<li class="chapter" data-level="9.8.3" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#el-algoritmo-de-metropolis-hasting"><i class="fa fa-check"></i><b>9.8.3</b> El algoritmo de Metropolis-Hasting</a></li>
<li class="chapter" data-level="9.8.4" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#por-qué-el-algoritmo-de-metropolis-hasting-funciona"><i class="fa fa-check"></i><b>9.8.4</b> ¿Por qué el algoritmo de Metropolis Hasting funciona?</a></li>
<li class="chapter" data-level="9.8.5" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#extensión-al-caso-del-viajero"><i class="fa fa-check"></i><b>9.8.5</b> Extensión al caso del viajero</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#el-problema-del-viajero-en-un-plano"><i class="fa fa-check"></i><b>9.9</b> El problema del viajero en un plano</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#muestreo-de-gibbs"><i class="fa fa-check"></i><b>9.9.1</b> Muestreo de Gibbs</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejemplo-reales"><i class="fa fa-check"></i><b>9.10</b> Ejemplo reales</a>
<ul>
<li class="chapter" data-level="9.10.1" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#datos-agrupados-bajo-una-población-normal"><i class="fa fa-check"></i><b>9.10.1</b> Datos agrupados bajo una población normal</a></li>
</ul></li>
<li class="chapter" data-level="9.11" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#uso-de-jags"><i class="fa fa-check"></i><b>9.11</b> Uso de JAGS</a></li>
<li class="chapter" data-level="9.12" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#uso-de-stan"><i class="fa fa-check"></i><b>9.12</b> Uso de STAN</a></li>
<li class="chapter" data-level="9.13" data-path="09-calculo-bayes.html"><a href="09-calculo-bayes.html#ejercicios-7"><i class="fa fa-check"></i><b>9.13</b> Ejercicios</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notas Curso de Estadística II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regresión-logística" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Capítulo 5</span> Regresión Logística<a href="05-regresion-logistica.html#regresión-logística" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="preliminares" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Preliminares<a href="05-regresion-logistica.html#preliminares" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Asuma que la variable dependiente <span class="math inline">\(Y\)</span> solo contiene valores 0 o 1 y queremos hacer la regresión:</p>
<p><span class="math display">\[\begin{equation*}
Y = \beta_{0} +\beta_{1} X_{1} + \cdots + \beta_{p} X_{p} + \varepsilon.
\end{equation*}\]</span></p>
<p>El problema es que <span class="math inline">\(\mathbb{E}\left[Y | \boldsymbol{X}\right] = \mathbb{P}\left(Y=1\vert \boldsymbol{X}\right)\)</span> y se debe cumplir que</p>
<p><span class="math display">\[\begin{equation*}
0\leq \mathbb{E}\left[Y | \boldsymbol{X}\right]\leq 1.
\end{equation*}\]</span></p>
<p>pero el rango de <span class="math inline">\(\beta_{0} +\beta_{1} X_{1} + \cdots + \beta_{p} X_{p}\)</span> es todo <span class="math inline">\(\mathbb{R}\)</span>.</p>
<p>Solución: Cambiar <span class="math inline">\(Y\)</span> por <span class="math inline">\(g(Y)\in [0,1]\)</span>, donde:</p>
<p><span class="math display">\[\begin{equation*}
g(X) = \frac{1}{1+e^{-(\beta_{0} +\beta_{1} X_{1} + \cdots + \beta_{p} X_{p})}}
\end{equation*}\]</span></p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="05-regresion-logistica.html#cb240-1" aria-hidden="true" tabindex="-1"></a>titanic <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;data/titanic.csv&quot;</span>)</span>
<span id="cb240-2"><a href="05-regresion-logistica.html#cb240-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(titanic)</span></code></pre></div>
<pre><code>##   PassengerId       Survived          Pclass          Name          
##  Min.   :  1.0   Min.   :0.0000   Min.   :1.000   Length:891        
##  1st Qu.:223.5   1st Qu.:0.0000   1st Qu.:2.000   Class :character  
##  Median :446.0   Median :0.0000   Median :3.000   Mode  :character  
##  Mean   :446.0   Mean   :0.3838   Mean   :2.309                     
##  3rd Qu.:668.5   3rd Qu.:1.0000   3rd Qu.:3.000                     
##  Max.   :891.0   Max.   :1.0000   Max.   :3.000                     
##                                                                     
##      Sex                 Age            SibSp           Parch       
##  Length:891         Min.   : 0.42   Min.   :0.000   Min.   :0.0000  
##  Class :character   1st Qu.:20.12   1st Qu.:0.000   1st Qu.:0.0000  
##  Mode  :character   Median :28.00   Median :0.000   Median :0.0000  
##                     Mean   :29.70   Mean   :0.523   Mean   :0.3816  
##                     3rd Qu.:38.00   3rd Qu.:1.000   3rd Qu.:0.0000  
##                     Max.   :80.00   Max.   :8.000   Max.   :6.0000  
##                     NA&#39;s   :177                                     
##     Ticket               Fare           Cabin             Embarked        
##  Length:891         Min.   :  0.00   Length:891         Length:891        
##  Class :character   1st Qu.:  7.91   Class :character   Class :character  
##  Mode  :character   Median : 14.45   Mode  :character   Mode  :character  
##                     Mean   : 32.20                                        
##                     3rd Qu.: 31.00                                        
##                     Max.   :512.33                                        
## </code></pre>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="05-regresion-logistica.html#cb242-1" aria-hidden="true" tabindex="-1"></a>titanic <span class="ot">&lt;-</span> titanic <span class="sc">%&gt;%</span></span>
<span id="cb242-2"><a href="05-regresion-logistica.html#cb242-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(Survived, Fare, Age) <span class="sc">%&gt;%</span></span>
<span id="cb242-3"><a href="05-regresion-logistica.html#cb242-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">drop_na</span>()</span></code></pre></div>
<pre><code>## Error in select(., Survived, Fare, Age): unused arguments (Survived, Fare, Age)</code></pre>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="05-regresion-logistica.html#cb244-1" aria-hidden="true" tabindex="-1"></a>fit_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Survived <span class="sc">~</span> Fare <span class="sc">+</span> Age, <span class="at">data =</span> titanic)</span></code></pre></div>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="05-regresion-logistica.html#cb245-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggiraphExtra)</span>
<span id="cb245-2"><a href="05-regresion-logistica.html#cb245-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggPredict</span>(fit_lm) <span class="sc">+</span> <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">16</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-183-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>En lugar de esto, definamos el siguiente modelo</p>
<p><span class="math display">\[\begin{equation*}
Y \sim Bernoulli (g_{\beta}(\boldsymbol{X}))
\end{equation*}\]</span></p>
<p>con <span class="math inline">\(g_{\beta}(\boldsymbol{X}) = \mathbb{P}\left(Y=1 \vert \boldsymbol{X}\right)\)</span>.</p>
<p>En <code>R</code> usaremos la función <code>glm</code></p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="05-regresion-logistica.html#cb246-1" aria-hidden="true" tabindex="-1"></a>fit_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(Survived <span class="sc">~</span> Fare <span class="sc">+</span> Age, <span class="at">data =</span> titanic,</span>
<span id="cb246-2"><a href="05-regresion-logistica.html#cb246-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb246-3"><a href="05-regresion-logistica.html#cb246-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_glm)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Survived ~ Fare + Age, family = &quot;binomial&quot;, data = titanic)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.7605  -0.9232  -0.8214   1.2362   1.7820  
## 
## Coefficients:
##              Estimate Std. Error z value        Pr(&gt;|z|)    
## (Intercept) -0.417055   0.185976  -2.243         0.02493 *  
## Fare         0.017258   0.002617   6.596 0.0000000000423 ***
## Age         -0.017578   0.005666  -3.103         0.00192 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 964.52  on 713  degrees of freedom
## Residual deviance: 891.34  on 711  degrees of freedom
##   (177 observations deleted due to missingness)
## AIC: 897.34
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="05-regresion-logistica.html#cb248-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggPredict</span>(fit_glm) <span class="sc">+</span> <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">16</span>)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-185-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p><strong>Nota:</strong> Existen otros tipos de regresión y estas se definen a través del parámetro <code>family</code>. En este curso solo nos enfocaremos en el parámetro <code>family="binomial"</code>.</p>
<div id="oportunidad-relativa-odds-ratio" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Oportunidad relativa (Odds Ratio)<a href="05-regresion-logistica.html#oportunidad-relativa-odds-ratio" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Defina la oportunidad relativa:</p>
<p><span class="math display">\[\begin{equation*}
O(X) = \frac{g(X)}{1-g(X)} = e^{\beta_{0} +\beta_{1} X_{1} + \cdots + \beta_{p} X_{p}}.
\end{equation*}\]</span></p>
<p>como la razón de la probabilidad de obtener un 1 con respecto a la de obtener un 0.</p>
<p>Por ejemplo, suponga que <span class="math inline">\(\mathbb{P}\left(Y=1\vert \boldsymbol{X}\right) = g(\boldsymbol{X}) = 0.8\)</span> es la probabilidad de pagar la tarjeta de crédito y <span class="math inline">\(1-g(\boldsymbol{X}) = 0.2\)</span> es la probabilidad de no pagar.</p>
<p>Entonces la oportunidad relativa de pagar la tarjeta es <span class="math inline">\(O(X) = \frac{0.8}{0.2} = \frac{4}{1}\)</span>, lo que se interpreta como que es 4 veces más probable de pagar que no pagar.</p>
</div>
</div>
<div id="máxima-verosimilitud" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Máxima verosimilitud<a href="05-regresion-logistica.html#máxima-verosimilitud" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los valores de <span class="math inline">\(\beta\)</span> se pueden encontrar por máxima verosimilitud.</p>
<p>Defina <span class="math inline">\(p_{\beta}(\boldsymbol{X}) = \mathbb{P}\left(Y=1\vert \boldsymbol{X}\right)\)</span>.</p>
<p>La verosimilitud es (donde asumimos sin pérdida de generalidad que <span class="math inline">\(p(\boldsymbol{X}):=p_{\beta}(\boldsymbol{X})\)</span>):</p>
<p><span class="math display">\[
L\left(\beta\right)=\prod_{i=1}^{n} p\left(\boldsymbol{X}_{i}\right)^{Y_{i}}\left(1-p\left(\boldsymbol{X}_{i}\right)\right)^{1-Y_{i}}
\]</span></p>
<p><span class="math display">\[\begin{align*}
\ell\left(\beta\right)
&amp;=\sum_{i=1}^{n} Y_{i} \log p\left(\boldsymbol{X}_{i}\right)+\left(1-Y_{i}\right) \log \left(1-p\left(\boldsymbol{X}_{i}\right)\right) \\
&amp;=\sum_{i=1}^{n} \log \left(1-p\left(\boldsymbol{X}_{i}\right)\right)+\sum_{i=1}^{n} Y_{i} \log \frac{p\left(\boldsymbol{X}_{i}\right)}{1-p\left(\boldsymbol{X}_{i}\right)} \\
&amp;=\sum_{i=1}^{n} \log \left(1-p\left(\boldsymbol{X}_{i}\right)\right)+\sum_{i=1}^{n} Y_{i}\left(\boldsymbol{X}_{i} \cdot \beta\right) \\
&amp;=\sum_{i=1}^{n}-\log \left(1+e^{\boldsymbol{X}_{i} \cdot \beta}\right)+\sum_{i=1}^{n} Y_{i}\left(\boldsymbol{X}_{i} \cdot \beta\right)
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
\frac{\partial \ell}{\partial \beta}
&amp;=-\sum_{i=1}^{n} \frac{1}{1+e^{\boldsymbol{X}_{i} \cdot \beta}} e^{\boldsymbol{X}_{i} \cdot \beta} \boldsymbol{X}_{i}+\sum_{i=1}^{n} Y_{i} \boldsymbol{X}_{i} \\
&amp;=\sum_{i=1}^{n}\left(Y_{i}-p\left(\boldsymbol{X}_{i}\right)\right) \boldsymbol{X}_{i} \\
&amp;= X^{\top}(Y-p(\boldsymbol{X}))
\end{align*}\]</span></p>
<p><strong>Solución:</strong> Algoritmo de Netwon-Raphson.</p>
<div class="exercise">
<p><span id="exr:unnamed-chunk-186" class="exercise"><strong>Ejercicio 5.1  </strong></span>Muestre que</p>
<p><span class="math display">\[\begin{equation*}
\frac{\partial^{2} \ell}{\partial \beta^{2}} = -\boldsymbol{X}^{\top}W\boldsymbol{X}
\end{equation*}\]</span></p>
<p>donde <span class="math inline">\(W_\beta = \mathrm{diag}\{p(\boldsymbol{X}_{i})(1-p(X_{i}))\}\)</span>.</p>
</div>
<p>El algoritmo de Netwon-Raphson usa el hecho que</p>
<p><span class="math display">\[\begin{equation*}
\beta^{(t)} = \beta ^{(t-1)} - \left(  \frac{\partial^{2} \ell}{\partial \beta^{2}}\right)^{-1} \frac{\partial \ell}{\partial \beta}  \Bigg\vert_{\beta ^{(t-1)}}
\end{equation*}\]</span></p>
<div class="exercise">
<p><span id="exr:unnamed-chunk-187" class="exercise"><strong>Ejercicio 5.2  </strong></span>Muestre que</p>
<p><span class="math display">\[\begin{equation*}
\beta^{(t)} = \left( X^{\top}W_\beta X \right)^{-1}X^{\top}Z_{\beta},
\end{equation*}\]</span></p>
<p>donde <span class="math inline">\(Z_{\beta} = Z\beta + W^{-1}_{\beta} (Y-p(X))\)</span> y <span class="math inline">\(\beta=\beta^{(t-1)}\)</span>.</p>
</div>
<p>A esta técnica se le conoce como <strong>mínimos cuadrados ponderados e iterados</strong> o en inglés <strong>Iteratively Re-Weighted Least Squares</strong> (IRLS).</p>
<!-- Se comienza con \(\beta^{(0)}\) cualquiera y se va iterando \(\beta^{(1)}, \beta^{(2)}, \ldots\) hasta encontrar la convergencia.  -->
<!-- Para cada \(t\) se resueelve el problema  -->
<!-- \begin{equation*} -->
<!-- \beta ^{t} = \operatorname{argmin}_{\beta} (Z-X\beta)^{\top}W(Z-X\beta). -->
<!-- \end{equation*} -->
<div id="resultados-adicionales" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Resultados adicionales<a href="05-regresion-logistica.html#resultados-adicionales" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La suma al cuadrado de los residuos estandarizados se convierte en el estadístico de pearson:</p>
<p><span class="math display">\[\begin{align*}
\chi^{2}=\sum_{i=1}^{n} \frac{\left(Y_{i}-\hat{p}(X_{i})\right)^{2}}{\hat{p}(X_{i})}
\end{align*}\]</span></p>
<p>la cual es una aproximación cuadrática de la devianza (Curso pasado).</p>
<p><span class="math display">\[\begin{equation*}
D = -2 \ell(\hat{\beta})
\end{equation*}\]</span></p>
<p>Además tenemos los resultados que</p>
<ul>
<li><span class="math inline">\(\hat{\beta} \xrightarrow{\mathbb{P}} \beta\)</span></li>
<li><span class="math inline">\(\hat{\beta} \xrightarrow{\mathcal{D}} \mathcal{N}\left(\beta,(X^{\top}WX)^{-1}\right)\)</span> (Prueba de Wald)</li>
<li>Se pueden comparar un modelo completo con un reducido a través de pruebas asintóticas LRT:
<span class="math display">\[\begin{equation*}
D_c -D_r \stackrel{H_0}{\sim} =\chi^{2}_{df_{c}-df_r}.
\end{equation*}\]</span></li>
</ul>
</div>
</div>
<div id="diágnosticos-del-modelo" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Diágnosticos del modelo<a href="05-regresion-logistica.html#diágnosticos-del-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Advertencia</strong>: La función <code>glm</code> no tiene un equivalente de <code>plot</code> como en los modelos lineales. De esta forma, si se aplica <code>plot</code> a un objeto <code>glm</code> solo generará los mismos chequeos que el capítulo anterior. Sin embargo estos podrían estar equivocados si no se leen con cuidado.</p>
<div id="supuesto-de-linealidad" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Supuesto de linealidad<a href="05-regresion-logistica.html#supuesto-de-linealidad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Este supuesto debe ser chequeado con la función logit de las respuestas.</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="05-regresion-logistica.html#cb249-1" aria-hidden="true" tabindex="-1"></a>fit_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(Survived <span class="sc">~</span> Fare <span class="sc">+</span> Age, <span class="at">data =</span> titanic,</span>
<span id="cb249-2"><a href="05-regresion-logistica.html#cb249-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb249-3"><a href="05-regresion-logistica.html#cb249-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_glm)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Survived ~ Fare + Age, family = &quot;binomial&quot;, data = titanic)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.7605  -0.9232  -0.8214   1.2362   1.7820  
## 
## Coefficients:
##              Estimate Std. Error z value        Pr(&gt;|z|)    
## (Intercept) -0.417055   0.185976  -2.243         0.02493 *  
## Fare         0.017258   0.002617   6.596 0.0000000000423 ***
## Age         -0.017578   0.005666  -3.103         0.00192 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 964.52  on 713  degrees of freedom
## Residual deviance: 891.34  on 711  degrees of freedom
##   (177 observations deleted due to missingness)
## AIC: 897.34
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="05-regresion-logistica.html#cb251-1" aria-hidden="true" tabindex="-1"></a>probs <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_glm, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb251-2"><a href="05-regresion-logistica.html#cb251-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb251-3"><a href="05-regresion-logistica.html#cb251-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> titanic <span class="sc">%&gt;%</span></span>
<span id="cb251-4"><a href="05-regresion-logistica.html#cb251-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(Fare, Age) <span class="sc">%&gt;%</span></span>
<span id="cb251-5"><a href="05-regresion-logistica.html#cb251-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">logit =</span> <span class="fu">qlogis</span>(probs)) <span class="sc">%&gt;%</span></span>
<span id="cb251-6"><a href="05-regresion-logistica.html#cb251-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_longer</span>(<span class="at">names_to =</span> <span class="st">&quot;predictores&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;valores.predictores&quot;</span>,</span>
<span id="cb251-7"><a href="05-regresion-logistica.html#cb251-7" aria-hidden="true" tabindex="-1"></a>        <span class="sc">-</span>logit)</span></code></pre></div>
<pre><code>## Error in select(., Fare, Age): unused arguments (Fare, Age)</code></pre>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="05-regresion-logistica.html#cb253-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(valores.predictores, logit)) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.5</span>,</span>
<span id="cb253-2"><a href="05-regresion-logistica.html#cb253-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>) <span class="sc">+</span></span>
<span id="cb253-3"><a href="05-regresion-logistica.html#cb253-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span>predictores, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>)</span></code></pre></div>
<pre><code>## Error in `ggplot()`:
## !   You&#39;re passing a function as global data.
##   Have you misspelled the `data` argument in `ggplot()`</code></pre>
</div>
<div id="valores-de-gran-influencia" class="section level3 hasAnchor" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Valores de gran influencia<a href="05-regresion-logistica.html#valores-de-gran-influencia" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="05-regresion-logistica.html#cb255-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb255-2"><a href="05-regresion-logistica.html#cb255-2" aria-hidden="true" tabindex="-1"></a>fit_data <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">augment</span>(fit_glm) <span class="sc">%&gt;%</span></span>
<span id="cb255-3"><a href="05-regresion-logistica.html#cb255-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">indice =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">n</span>())</span>
<span id="cb255-4"><a href="05-regresion-logistica.html#cb255-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb255-5"><a href="05-regresion-logistica.html#cb255-5" aria-hidden="true" tabindex="-1"></a>fit_data <span class="sc">%&gt;%</span></span>
<span id="cb255-6"><a href="05-regresion-logistica.html#cb255-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">top_n</span>(<span class="dv">3</span>, .cooksd)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 11
##   .rownames Survived  Fare   Age .fitted .resid .std.resid    .hat .sigma
##   &lt;chr&gt;        &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
## 1 28               0  263     19    3.79  -2.76      -2.77 0.00862   1.12
## 2 119              0  248.    24    3.43  -2.63      -2.65 0.0103    1.12
## 3 439              0  263     64    3.00  -2.47      -2.49 0.0171    1.12
## # ... with 2 more variables: .cooksd &lt;dbl&gt;, indice &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="05-regresion-logistica.html#cb257-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(fit_data, <span class="fu">aes</span>(indice, .std.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> <span class="fu">as.factor</span>(Survived)),</span>
<span id="cb257-2"><a href="05-regresion-logistica.html#cb257-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span> <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/unnamed-chunk-192-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="05-regresion-logistica.html#cb258-1" aria-hidden="true" tabindex="-1"></a>fit_data <span class="sc">%&gt;%</span></span>
<span id="cb258-2"><a href="05-regresion-logistica.html#cb258-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(<span class="fu">abs</span>(.std.resid) <span class="sc">&gt;</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## # A tibble: 0 x 11
## # ... with 11 variables: .rownames &lt;chr&gt;, Survived &lt;int&gt;, Fare &lt;dbl&gt;,
## #   Age &lt;dbl&gt;, .fitted &lt;dbl&gt;, .resid &lt;dbl&gt;, .std.resid &lt;dbl&gt;, .hat &lt;dbl&gt;,
## #   .sigma &lt;dbl&gt;, .cooksd &lt;dbl&gt;, indice &lt;int&gt;</code></pre>
</div>
<div id="multicolinealidad-1" class="section level3 hasAnchor" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> Multicolinealidad<a href="05-regresion-logistica.html#multicolinealidad-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="05-regresion-logistica.html#cb260-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">vif</span>(fit_glm)</span></code></pre></div>
<pre><code>##     Fare      Age 
## 1.033878 1.033878</code></pre>
</div>
</div>
<div id="predicción-y-poder-de-clasificación" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Predicción y poder de clasificación<a href="05-regresion-logistica.html#predicción-y-poder-de-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La capacidad predictiva de un modelo de clasificación como el de regresión logística se debe medir conforme a la naturaleza de la variable dependiente. Primero recordemos que el modelo predictivo en este caso estaría definido por:</p>
<p><span class="math display">\[\begin{equation*}
\hat{p}(X)=\frac{1}{1+e^{-(\hat{\beta}_{0}+\hat{\beta}_{1} X_{1}+\cdots+\hat{\beta}_{p} X_{p})}}
\end{equation*}\]</span></p>
<p>donde los <span class="math inline">\(\beta\)</span>’s son estimados usando IRLS.</p>
<p>Ahora imaginemos que tenemos un conjunto de datos nuevo <span class="math inline">\((X^{*}_{1},\ldots,X^{*}_{p})\)</span> y queremos ver que tipo de respuesta <span class="math inline">\(Y^{*}\)</span> obtenemos (0 o 1) para este conjunto de datos.</p>
<p>Obviamente nuestro modelo puede equivocarse y darnos una respuesta errónea. Por ejemplo digamos que en el caso del <code>titanic</code> uno esperaría que personas más jóvenes y que hayan pagado más por su tiquete tengan mayor probabilidad de sobrevivencia.</p>
<p>Entonces tenemos realmente 4 opciones</p>
<table>
<colgroup>
<col width="20%" />
<col width="37%" />
<col width="36%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center"><strong>Modelo = 0</strong></th>
<th align="center"><strong>Modelo = 1</strong></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Real = 0</strong></td>
<td align="center">Verdaderos Negativos. (TN)</td>
<td align="center">Falsos Positivos (FP)</td>
<td align="center"><span class="math inline">\(N\)</span></td>
</tr>
<tr class="even">
<td align="center"><strong>Real = 1</strong></td>
<td align="center">Falsos Negativos (FN)</td>
<td align="center">Verdaderos Positivos (TP)</td>
<td align="center"><span class="math inline">\(P\)</span></td>
</tr>
<tr class="odd">
<td align="center">Total</td>
<td align="center"><span class="math inline">\(N^{\star}\)</span></td>
<td align="center"><span class="math inline">\(P^{\star}\)</span></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="05-regresion-logistica.html#cb262-1" aria-hidden="true" tabindex="-1"></a>predict_numeric <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_glm, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb262-2"><a href="05-regresion-logistica.html#cb262-2" aria-hidden="true" tabindex="-1"></a>predict_01 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(predict_numeric <span class="sc">&gt;=</span> <span class="fl">0.5</span>)</span>
<span id="cb262-3"><a href="05-regresion-logistica.html#cb262-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb262-4"><a href="05-regresion-logistica.html#cb262-4" aria-hidden="true" tabindex="-1"></a>matriz_confusion <span class="ot">&lt;-</span> <span class="fu">table</span>(titanic<span class="sc">$</span>Survived, predict_01)</span></code></pre></div>
<pre><code>## Error in table(titanic$Survived, predict_01): all arguments must have the same length</code></pre>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="05-regresion-logistica.html#cb264-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(matriz_confusion) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;N&quot;</span>, <span class="st">&quot;P&quot;</span>)</span></code></pre></div>
<pre><code>## Error in colnames(matriz_confusion) &lt;- c(&quot;N&quot;, &quot;P&quot;): object &#39;matriz_confusion&#39; not found</code></pre>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="05-regresion-logistica.html#cb266-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(matriz_confusion) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;N&quot;</span>, <span class="st">&quot;P&quot;</span>)</span></code></pre></div>
<pre><code>## Error in rownames(matriz_confusion) &lt;- c(&quot;N&quot;, &quot;P&quot;): object &#39;matriz_confusion&#39; not found</code></pre>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="05-regresion-logistica.html#cb268-1" aria-hidden="true" tabindex="-1"></a>matriz_confusion</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;matriz_confusion&#39; not found</code></pre>
<p>Noten que se utilizó un umbral de .5 como separador de que un evento genera un 1 o un 0 a nivel de predicción. Para entender la siguiente tabla vamos a definir los siguientes términos:</p>
<dl>
<dt>Exactitud (Accuracy)</dt>
<dd>
Es la tasa de que un individuo esté bien identificado por el modelo de clasificación <span class="math inline">\((TP+TN)/(TP+TN+FN+FP)\)</span>.
</dd>
<dt>Precisión</dt>
<dd>
Es la tasa de elementos identificados como 1 de forma correcta con respecto a los que fueron identificados con un valor de 1 <span class="math inline">\(Precisión = TP/P^\star\)</span>
</dd>
<dt>Sensibilidad (Exhaustividad)</dt>
<dd>
Es la tasa de elementos identificados como 1 de forma correcta con respecto a los que realmente son 1. <span class="math inline">\(Sensibilidad = TP/P\)</span>
</dd>
<dt>F-Score</dt>
<dd>
Es la media armónica entre la precisión y la sensibilidad. <span class="math inline">\(F-Score = 2\times(Sensibilidad * Precisión)/(Sensibilidad + Precisión)\)</span>
</dd>
<dt>Especificidad</dt>
<dd>
Es la tasa de elementos identificados correctamente como 0 que realmente estaban etiquetados como 0.
</dd>
</dl>
<p>Entonces esto nos da las siguientes posibilidades.</p>
<table>
<colgroup>
<col width="20%" />
<col width="36%" />
<col width="42%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Tipo</th>
<th align="left">Cálculo</th>
<th align="left">Sinónimos</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Sensibilidad</td>
<td align="left"><span class="math inline">\(TP/P\)</span></td>
<td align="left">1 - Error tipo II, Poder, Exhaustividad, Exhaustividad.</td>
</tr>
<tr class="even">
<td align="left">Especificidad</td>
<td align="left"><span class="math inline">\(TN/N\)</span></td>
<td align="left">1- Error tipo I.</td>
</tr>
<tr class="odd">
<td align="left">Valor de Predicción Positivos</td>
<td align="left"><span class="math inline">\(TP/P^{\star}\)</span></td>
<td align="left">Positive predicted values (PPV), Precisión.</td>
</tr>
<tr class="even">
<td align="left">Valor de Predicción Negativos</td>
<td align="left"><span class="math inline">\(TN/N^{\star}\)</span></td>
<td align="left">Negative predicted values (NPV)</td>
</tr>
<tr class="odd">
<td align="left">F-Score</td>
<td align="left"><span class="math inline">\(\frac{2(TP/P^{\star} \times TP/P )}{(TP/P^{\star} + TP/P )}\)</span></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p><strong>Nota:</strong></p>
<ul>
<li>La sensibilidad y especificidad son buenos indicadores cuando los datos son simétricos (igual número de FP y FN).</li>
<li>El F-Score ayuda cuando los datos son asimétricos. El valor mayor de este valor es 1 indicado una precisión y exhaustividad perfectas.</li>
<li>La sensibilidad nos permite describir la capacidad de categorizar los verdaderos positivos de forma correcta.</li>
<li>En cambio, la especificidad lo hace para los verdaderos negativos.</li>
<li>La precisión o PPV nos permite describir la capacidad del modelo de predecir verdaderos positivos.</li>
<li>El NPV predice la capacidad del modelo de predecir los verdaderos negativos.</li>
</ul>
<p>En un modelo se debe entender que significa cada uno de estos valores para entender los resultados.</p>
<ul>
<li><strong>Sensibilidad</strong> es importante si la ocurrencia de <strong>falsos negativos</strong> es inaceptable. Supongamos que alguien tiene VIH y el examen le da negativo. En este caso es inaceptable el resultado, por lo que la prueba debe tener un alto valor de sensibilidad.</li>
<li><strong>Especificidad</strong> es importante para si la ocurrencia de <strong>falsos positivos</strong> es inaceptable. Es decir, supongamos que una persona tiene un tumor benigno y un examen lo clasifica como maligno. La persona sana, se declara enferma y debe pasar por un proceso de quimioterapia. La alta especificidad baja la probabildiad que esto ocurra.</li>
<li><strong>PPV</strong> es importante si se quiere estar más seguro de los <strong>verdaderos positivos</strong>. Por ejemplo detectar <strong>spam</strong> en correos electrónicos.</li>
<li><strong>NPV</strong> es impotante si se desea predecir correctamente los <strong>verdaderos negativos</strong>. Por ejemplo, se está tratando una población con una droga experimental y se quiere saber cuál será la proporción de personas que se curaran de la enfermedad.</li>
</ul>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="05-regresion-logistica.html#cb270-1" aria-hidden="true" tabindex="-1"></a>(TN <span class="ot">&lt;-</span> matriz_confusion[<span class="st">&quot;N&quot;</span>, <span class="st">&quot;N&quot;</span>])</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;matriz_confusion&#39; not found</code></pre>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="05-regresion-logistica.html#cb272-1" aria-hidden="true" tabindex="-1"></a>(TP <span class="ot">&lt;-</span> matriz_confusion[<span class="st">&quot;P&quot;</span>, <span class="st">&quot;P&quot;</span>])</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;matriz_confusion&#39; not found</code></pre>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="05-regresion-logistica.html#cb274-1" aria-hidden="true" tabindex="-1"></a>(FP <span class="ot">&lt;-</span> matriz_confusion[<span class="st">&quot;N&quot;</span>, <span class="st">&quot;P&quot;</span>])</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;matriz_confusion&#39; not found</code></pre>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="05-regresion-logistica.html#cb276-1" aria-hidden="true" tabindex="-1"></a>(FN <span class="ot">&lt;-</span> matriz_confusion[<span class="st">&quot;P&quot;</span>, <span class="st">&quot;N&quot;</span>])</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;matriz_confusion&#39; not found</code></pre>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="05-regresion-logistica.html#cb278-1" aria-hidden="true" tabindex="-1"></a>(exactitud <span class="ot">&lt;-</span> (TP <span class="sc">+</span> TN)<span class="sc">/</span>(TP <span class="sc">+</span> TN <span class="sc">+</span> FP <span class="sc">+</span> FN))</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;TP&#39; not found</code></pre>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="05-regresion-logistica.html#cb280-1" aria-hidden="true" tabindex="-1"></a>(precision <span class="ot">&lt;-</span> TP<span class="sc">/</span>(TP <span class="sc">+</span> FP))</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;TP&#39; not found</code></pre>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="05-regresion-logistica.html#cb282-1" aria-hidden="true" tabindex="-1"></a>(sensibilidad <span class="ot">&lt;-</span> TP<span class="sc">/</span>(TP <span class="sc">+</span> FN))</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;TP&#39; not found</code></pre>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="05-regresion-logistica.html#cb284-1" aria-hidden="true" tabindex="-1"></a>(F_score <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (precision <span class="sc">*</span> sensibilidad)<span class="sc">/</span>(precision <span class="sc">+</span></span>
<span id="cb284-2"><a href="05-regresion-logistica.html#cb284-2" aria-hidden="true" tabindex="-1"></a>    sensibilidad))</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;sensibilidad&#39; not found</code></pre>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="05-regresion-logistica.html#cb286-1" aria-hidden="true" tabindex="-1"></a>(especificidad <span class="ot">&lt;-</span> TN<span class="sc">/</span>(TN <span class="sc">+</span> FP))</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;TN&#39; not found</code></pre>
<div id="curva-roc" class="section level3 hasAnchor" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Curva ROC<a href="05-regresion-logistica.html#curva-roc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Un excelente clasificador debería detectar correctamente los <strong>verdaderos positivos (TP)</strong> e ignorar los <strong>falsos positivos (FP)</strong>. Puesto de otra forma, si el clasificador es malo, los <strong>verdaderos positivos</strong> serían indistingibles de los <strong>falsos positivos</strong>.</p>
<p>La curva ROC (Receiver Operation Curve) grafica la Tasa Falsos Positivos vs Sensibilidad del modelo. Y el estadístico AUC mide el área bajo la curva ROC.</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="05-regresion-logistica.html#cb288-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ROCR)</span>
<span id="cb288-2"><a href="05-regresion-logistica.html#cb288-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb288-3"><a href="05-regresion-logistica.html#cb288-3" aria-hidden="true" tabindex="-1"></a>logist.pred.ROCR <span class="ot">&lt;-</span> <span class="fu">prediction</span>(predict_numeric, titanic<span class="sc">$</span>Survived)</span></code></pre></div>
<pre><code>## Error in prediction(predict_numeric, titanic$Survived): Number of predictions in each run must be equal to the number of labels for each run.</code></pre>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="05-regresion-logistica.html#cb290-1" aria-hidden="true" tabindex="-1"></a>logist.perf <span class="ot">&lt;-</span> <span class="fu">performance</span>(logist.pred.ROCR, <span class="st">&quot;tpr&quot;</span>,</span>
<span id="cb290-2"><a href="05-regresion-logistica.html#cb290-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;fpr&quot;</span>)</span></code></pre></div>
<pre><code>## Error in performance(logist.pred.ROCR, &quot;tpr&quot;, &quot;fpr&quot;): object &#39;logist.pred.ROCR&#39; not found</code></pre>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="05-regresion-logistica.html#cb292-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(logist.perf)</span></code></pre></div>
<pre><code>## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;plot&#39;: object &#39;logist.perf&#39; not found</code></pre>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="05-regresion-logistica.html#cb294-1" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<pre><code>## Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): plot.new has not been called yet</code></pre>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="05-regresion-logistica.html#cb296-1" aria-hidden="true" tabindex="-1"></a>auc <span class="ot">&lt;-</span> <span class="fu">performance</span>(logist.pred.ROCR, <span class="at">measure =</span> <span class="st">&quot;auc&quot;</span>)</span></code></pre></div>
<pre><code>## Error in performance(logist.pred.ROCR, measure = &quot;auc&quot;): object &#39;logist.pred.ROCR&#39; not found</code></pre>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="05-regresion-logistica.html#cb298-1" aria-hidden="true" tabindex="-1"></a>auc<span class="sc">@</span>y.values</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;auc&#39; not found</code></pre>
<p><strong>Nota:</strong></p>
<p>Hasta este momento estamos verificando el poder de clasificación del modelo con los mismos datos que usamos para ajustarlo. Es decir, le estamos diciendo al modelo que compruebe la veracidad de la clasificación que ya se hizo previamente.</p>
<p>Esto es incorrecto, ya que el modelo ya sabe “las respuestas” y no estamos midiendo su poder de clasificación sino más bien su capacidad predictiva dentro del conjunto de entrenamiento.</p>
<p>Para resolver esto, debemos tomar otra muestra de prueba (<strong>training</strong>) que nos diga si el ajuste que hicimos es correcto.</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="05-regresion-logistica.html#cb300-1" aria-hidden="true" tabindex="-1"></a>titanic<span class="sc">$</span>id <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(titanic)</span>
<span id="cb300-2"><a href="05-regresion-logistica.html#cb300-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb300-3"><a href="05-regresion-logistica.html#cb300-3" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> titanic <span class="sc">%&gt;%</span></span>
<span id="cb300-4"><a href="05-regresion-logistica.html#cb300-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sample_frac</span>(<span class="fl">0.75</span>)</span>
<span id="cb300-5"><a href="05-regresion-logistica.html#cb300-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb300-6"><a href="05-regresion-logistica.html#cb300-6" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> titanic <span class="sc">%&gt;%</span></span>
<span id="cb300-7"><a href="05-regresion-logistica.html#cb300-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">anti_join</span>(train, <span class="at">by =</span> <span class="st">&quot;id&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="05-regresion-logistica.html#cb301-1" aria-hidden="true" tabindex="-1"></a>fit_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(Survived <span class="sc">~</span> Fare <span class="sc">+</span> Age, <span class="at">data =</span> train,</span>
<span id="cb301-2"><a href="05-regresion-logistica.html#cb301-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="05-regresion-logistica.html#cb302-1" aria-hidden="true" tabindex="-1"></a>predict_numeric <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_glm, <span class="at">newdata =</span> test,</span>
<span id="cb302-2"><a href="05-regresion-logistica.html#cb302-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb302-3"><a href="05-regresion-logistica.html#cb302-3" aria-hidden="true" tabindex="-1"></a>predict_01 <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(predict_numeric <span class="sc">&gt;=</span> <span class="fl">0.5</span>)</span>
<span id="cb302-4"><a href="05-regresion-logistica.html#cb302-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb302-5"><a href="05-regresion-logistica.html#cb302-5" aria-hidden="true" tabindex="-1"></a>matriz_confusion <span class="ot">&lt;-</span> <span class="fu">table</span>(test<span class="sc">$</span>Survived, predict_01)</span>
<span id="cb302-6"><a href="05-regresion-logistica.html#cb302-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb302-7"><a href="05-regresion-logistica.html#cb302-7" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(matriz_confusion) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;N&quot;</span>, <span class="st">&quot;P&quot;</span>)</span>
<span id="cb302-8"><a href="05-regresion-logistica.html#cb302-8" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(matriz_confusion) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;N&quot;</span>, <span class="st">&quot;P&quot;</span>)</span>
<span id="cb302-9"><a href="05-regresion-logistica.html#cb302-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb302-10"><a href="05-regresion-logistica.html#cb302-10" aria-hidden="true" tabindex="-1"></a>matriz_confusion</span></code></pre></div>
<pre><code>##    predict_01
##      N  P
##   N 83  8
##   P 60 21</code></pre>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="05-regresion-logistica.html#cb304-1" aria-hidden="true" tabindex="-1"></a>(TN <span class="ot">&lt;-</span> matriz_confusion[<span class="st">&quot;N&quot;</span>, <span class="st">&quot;N&quot;</span>])</span></code></pre></div>
<pre><code>## [1] 83</code></pre>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="05-regresion-logistica.html#cb306-1" aria-hidden="true" tabindex="-1"></a>(TP <span class="ot">&lt;-</span> matriz_confusion[<span class="st">&quot;P&quot;</span>, <span class="st">&quot;P&quot;</span>])</span></code></pre></div>
<pre><code>## [1] 21</code></pre>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="05-regresion-logistica.html#cb308-1" aria-hidden="true" tabindex="-1"></a>(FP <span class="ot">&lt;-</span> matriz_confusion[<span class="st">&quot;N&quot;</span>, <span class="st">&quot;P&quot;</span>])</span></code></pre></div>
<pre><code>## [1] 8</code></pre>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="05-regresion-logistica.html#cb310-1" aria-hidden="true" tabindex="-1"></a>(FN <span class="ot">&lt;-</span> matriz_confusion[<span class="st">&quot;P&quot;</span>, <span class="st">&quot;N&quot;</span>])</span></code></pre></div>
<pre><code>## [1] 60</code></pre>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="05-regresion-logistica.html#cb312-1" aria-hidden="true" tabindex="-1"></a>(exactitud <span class="ot">&lt;-</span> (TP <span class="sc">+</span> TN)<span class="sc">/</span>(TP <span class="sc">+</span> TN <span class="sc">+</span> FP <span class="sc">+</span> FN))</span></code></pre></div>
<pre><code>## [1] 0.6046512</code></pre>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="05-regresion-logistica.html#cb314-1" aria-hidden="true" tabindex="-1"></a>(precision <span class="ot">&lt;-</span> TP<span class="sc">/</span>(TP <span class="sc">+</span> FP))</span></code></pre></div>
<pre><code>## [1] 0.7241379</code></pre>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="05-regresion-logistica.html#cb316-1" aria-hidden="true" tabindex="-1"></a>(sensibilidad <span class="ot">&lt;-</span> TP<span class="sc">/</span>(TP <span class="sc">+</span> FN))</span></code></pre></div>
<pre><code>## [1] 0.2592593</code></pre>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="05-regresion-logistica.html#cb318-1" aria-hidden="true" tabindex="-1"></a>(F_score <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (precision <span class="sc">*</span> sensibilidad)<span class="sc">/</span>(precision <span class="sc">+</span></span>
<span id="cb318-2"><a href="05-regresion-logistica.html#cb318-2" aria-hidden="true" tabindex="-1"></a>    sensibilidad))</span></code></pre></div>
<pre><code>## [1] 0.3818182</code></pre>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="05-regresion-logistica.html#cb320-1" aria-hidden="true" tabindex="-1"></a>(especificidad <span class="ot">&lt;-</span> TN<span class="sc">/</span>(TN <span class="sc">+</span> FP))</span></code></pre></div>
<pre><code>## [1] 0.9120879</code></pre>
<p>Por defecto, la probabilidad para crear la matrix de confusión es 0.5. Si empezamos a variar esa probabilidad en el rango de 0 a 1, obtenemos la curva ROC.</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="05-regresion-logistica.html#cb322-1" aria-hidden="true" tabindex="-1"></a>logist.pred.ROCR <span class="ot">&lt;-</span> <span class="fu">prediction</span>(predict_numeric, test<span class="sc">$</span>Survived)</span></code></pre></div>
<pre><code>## Error: &#39;predictions&#39; contains NA.</code></pre>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="05-regresion-logistica.html#cb324-1" aria-hidden="true" tabindex="-1"></a>logist.perf <span class="ot">&lt;-</span> <span class="fu">performance</span>(logist.pred.ROCR, <span class="st">&quot;tpr&quot;</span>,</span>
<span id="cb324-2"><a href="05-regresion-logistica.html#cb324-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;fpr&quot;</span>)</span></code></pre></div>
<pre><code>## Error in performance(logist.pred.ROCR, &quot;tpr&quot;, &quot;fpr&quot;): object &#39;logist.pred.ROCR&#39; not found</code></pre>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="05-regresion-logistica.html#cb326-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(logist.perf)</span></code></pre></div>
<pre><code>## Error in h(simpleError(msg, call)): error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;plot&#39;: object &#39;logist.perf&#39; not found</code></pre>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="05-regresion-logistica.html#cb328-1" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<pre><code>## Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...): plot.new has not been called yet</code></pre>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="05-regresion-logistica.html#cb330-1" aria-hidden="true" tabindex="-1"></a>auc <span class="ot">&lt;-</span> <span class="fu">performance</span>(logist.pred.ROCR, <span class="at">measure =</span> <span class="st">&quot;auc&quot;</span>)</span></code></pre></div>
<pre><code>## Error in performance(logist.pred.ROCR, measure = &quot;auc&quot;): object &#39;logist.pred.ROCR&#39; not found</code></pre>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="05-regresion-logistica.html#cb332-1" aria-hidden="true" tabindex="-1"></a>auc<span class="sc">@</span>y.values</span></code></pre></div>
<pre><code>## Error in eval(expr, envir, enclos): object &#39;auc&#39; not found</code></pre>
</div>
</div>
<div id="ejercicios-3" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Ejercicios<a href="05-regresion-logistica.html#ejercicios-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Del libro <span class="citation">(James et al. 2013)</span>:
<ul>
<li>Capítulo 4: 1, 6, 10, 11. (En esta sección no vimos LDA, QDA ni k-vecinos más cercanos, así que ignoren esas partes y concentrense en hacer los análisis correctos para regresión logística).</li>
</ul></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="04-metodos-lineares-regresion.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="06-seleccion-de-variables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica/edit/master/05-regresion-logistica.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica/blob/master/05-regresion-logistica.Rmd",
"text": null
},
"download": ["Notas-Curso-Estadistica.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"toc_depth": 5
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
