\babel@toc {spanish}{}\relax 
\contentsline {chapter}{\numberline {1}Introducción}{9}{chapter.1}%
\contentsline {chapter}{\numberline {2}Estimación no-paramétrica de densidades}{11}{chapter.2}%
\contentsline {section}{\numberline {2.1}Histograma}{11}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Construcción Estadística}{11}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Construcción probabilística}{13}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Propiedades estadísticas}{13}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}Propiedades estadísticas}{13}{subsection.2.1.4}%
\contentsline {subsection}{\numberline {2.1.5}Sesgo}{14}{subsection.2.1.5}%
\contentsline {subsection}{\numberline {2.1.6}Varianza}{15}{subsection.2.1.6}%
\contentsline {subsection}{\numberline {2.1.7}Error cuadrático medio}{15}{subsection.2.1.7}%
\contentsline {subsection}{\numberline {2.1.8}Error cuadrático medio integrado}{17}{subsection.2.1.8}%
\contentsline {subsection}{\numberline {2.1.9}Ancho de banda óptimo para el histograma}{18}{subsection.2.1.9}%
\contentsline {section}{\numberline {2.2}Estimación de densidades basada en kernels.}{22}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Primera construcción}{22}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Otra construcción}{23}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Propiedades Estadísticas}{27}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Sesgo}{28}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}Error cuadrático medio y Error cuadrático medio integrado}{30}{subsection.2.2.5}%
\contentsline {subsection}{\numberline {2.2.6}Ancho de banda óptimo}{31}{subsection.2.2.6}%
\contentsline {subsubsection}{\numberline {2.2.6.1}Referencia normal}{32}{subsubsection.2.2.6.1}%
\contentsline {subsubsection}{\numberline {2.2.6.2}Validación Cruzada}{34}{subsubsection.2.2.6.2}%
\contentsline {subsection}{\numberline {2.2.7}Intervalos de confianza para estimadores de densidad no paramétricos}{36}{subsection.2.2.7}%
\contentsline {section}{\numberline {2.3}Laboratorio}{37}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Efecto de distintos Kernels en la estimación}{38}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Efecto del ancho de banda en la estimación}{41}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Ancho de banda óptimo}{47}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}Validación cruzada}{51}{subsection.2.3.4}%
\contentsline {subsection}{\numberline {2.3.5}Temas adicionales}{53}{subsection.2.3.5}%
\contentsline {section}{\numberline {2.4}Ejercicios}{60}{section.2.4}%
\contentsline {chapter}{\numberline {3}Jackknife y Bootstrap}{61}{chapter.3}%
\contentsline {section}{\numberline {3.1}Caso concreto}{61}{section.3.1}%
\contentsline {section}{\numberline {3.2}Jackknife}{62}{section.3.2}%
\contentsline {section}{\numberline {3.3}Bootstrap}{67}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Intervalos de confianza}{72}{subsection.3.3.1}%
\contentsline {subsubsection}{\numberline {3.3.1.1}Intervalo Normal}{72}{subsubsection.3.3.1.1}%
\contentsline {subsubsection}{\numberline {3.3.1.2}Intervalo pivotal}{72}{subsubsection.3.3.1.2}%
\contentsline {subsubsection}{\numberline {3.3.1.3}Intervalo pivotal studentizado}{74}{subsubsection.3.3.1.3}%
\contentsline {subsection}{\numberline {3.3.2}Resumiendo}{76}{subsection.3.3.2}%
\contentsline {section}{\numberline {3.4}Ejercicios}{76}{section.3.4}%
\contentsline {chapter}{\numberline {4}Métodos lineales de regresión}{79}{chapter.4}%
\contentsline {section}{\numberline {4.1}Introducción al Aprendizaje Estadístico.}{79}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Formas de estimar \(f\)}{80}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Medidas de bondad de ajuste}{81}{subsection.4.1.2}%
\contentsline {section}{\numberline {4.2}Regresión lineal}{82}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Forma matricial}{82}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Laboratorio}{85}{subsection.4.2.2}%
\contentsline {section}{\numberline {4.3}Propiedades estadísticas}{92}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Prueba \(t\)}{94}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Prueba \(F\)}{94}{subsection.4.3.2}%
\contentsline {subsection}{\numberline {4.3.3}Laboratorio}{96}{subsection.4.3.3}%
\contentsline {section}{\numberline {4.4}Medida de bondad de ajuste}{99}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Laboratorio}{100}{subsection.4.4.1}%
\contentsline {subsubsection}{\numberline {4.4.1.1}\(R^2\)}{101}{subsubsection.4.4.1.1}%
\contentsline {subsubsection}{\numberline {4.4.1.2}\(R^2\) ajustado}{101}{subsubsection.4.4.1.2}%
\contentsline {subsubsection}{\numberline {4.4.1.3}\texttt {summary}}{101}{subsubsection.4.4.1.3}%
\contentsline {section}{\numberline {4.5}Predicción}{102}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}Laboratorio}{103}{subsection.4.5.1}%
\contentsline {subsubsection}{\numberline {4.5.1.1}Ajuste de la regresión sin intervalos de confianza}{104}{subsubsection.4.5.1.1}%
\contentsline {subsubsection}{\numberline {4.5.1.2}Ajuste de la regresión con intervalos de confianza}{105}{subsubsection.4.5.1.2}%
\contentsline {subsubsection}{\numberline {4.5.1.3}Ajuste de la regresión con intervalos de confianza y predicción}{106}{subsubsection.4.5.1.3}%
\contentsline {section}{\numberline {4.6}Interacciones}{110}{section.4.6}%
\contentsline {subsection}{\numberline {4.6.1}Laboratorio}{111}{subsection.4.6.1}%
\contentsline {section}{\numberline {4.7}Supuestos}{115}{section.4.7}%
\contentsline {subsection}{\numberline {4.7.1}Chequeos básicos de las hipótesis de regresión lineal}{116}{subsection.4.7.1}%
\contentsline {subsubsection}{\numberline {4.7.1.1}Linealidad, Errores con esperanza nula, Homocedasticidad}{116}{subsubsection.4.7.1.1}%
\contentsline {subsubsection}{\numberline {4.7.1.2}Independencia de los errores}{121}{subsubsection.4.7.1.2}%
\contentsline {subsubsection}{\numberline {4.7.1.3}Normalidad de los errores}{125}{subsubsection.4.7.1.3}%
\contentsline {subsubsection}{\numberline {4.7.1.4}Multicolinealidad}{129}{subsubsection.4.7.1.4}%
\contentsline {subsection}{\numberline {4.7.2}Otros chequeos importantes}{132}{subsection.4.7.2}%
\contentsline {subsubsection}{\numberline {4.7.2.1}Puntos extremos}{132}{subsubsection.4.7.2.1}%
\contentsline {subsubsection}{\numberline {4.7.2.2}Puntos de apalancamiento (leverage)}{135}{subsubsection.4.7.2.2}%
\contentsline {paragraph}{Distancia de Cook.}{135}{section*.2}%
\contentsline {section}{\numberline {4.8}Ejercicios}{154}{section.4.8}%
\contentsline {chapter}{\numberline {5}Regresión Logística}{155}{chapter.5}%
\contentsline {section}{\numberline {5.1}Preliminares}{155}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Oportunidad relativa (Odds Ratio)}{159}{subsection.5.1.1}%
\contentsline {section}{\numberline {5.2}Máxima verosimilitud}{159}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Resultados adicionales}{161}{subsection.5.2.1}%
\contentsline {section}{\numberline {5.3}Diágnosticos del modelo}{161}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Supuesto de linealidad}{161}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}Valores de gran influencia}{163}{subsection.5.3.2}%
\contentsline {subsection}{\numberline {5.3.3}Multicolinealidad}{164}{subsection.5.3.3}%
\contentsline {section}{\numberline {5.4}Predicción y poder de clasificación}{164}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Curva ROC}{168}{subsection.5.4.1}%
\contentsline {section}{\numberline {5.5}Ejercicios}{172}{section.5.5}%
\contentsline {chapter}{\numberline {6}Métodos de selección de variables y regularización}{173}{chapter.6}%
\contentsline {section}{\numberline {6.1}Estimación del error de prueba}{173}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Técnica de conjunto de validación}{173}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Validación cruzada ``Leave-One-Out'' (LOOCV)}{174}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Validación cruzada \(k-\)veces}{175}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}Validación cruzada para clasificación}{175}{subsection.6.1.4}%
\contentsline {subsection}{\numberline {6.1.5}Otras medidas de error de prueba}{176}{subsection.6.1.5}%
\contentsline {subsubsection}{\numberline {6.1.5.1}\(R^2\) ajustado}{176}{subsubsection.6.1.5.1}%
\contentsline {subsubsection}{\numberline {6.1.5.2}\(C_p\) de Mallows}{176}{subsubsection.6.1.5.2}%
\contentsline {subsubsection}{\numberline {6.1.5.3}Estimador de máxima verosimilitud (MLE)}{176}{subsubsection.6.1.5.3}%
\contentsline {subsubsection}{\numberline {6.1.5.4}Akaike Information Criterion (AIC).}{176}{subsubsection.6.1.5.4}%
\contentsline {subsubsection}{\numberline {6.1.5.5}\(C_p\) de Mallows}{177}{subsubsection.6.1.5.5}%
\contentsline {subsubsection}{\numberline {6.1.5.6}Estimador de máxima verosimilitud (MLE)}{178}{subsubsection.6.1.5.6}%
\contentsline {subsubsection}{\numberline {6.1.5.7}Akaike Information Criterion (AIC).}{179}{subsubsection.6.1.5.7}%
\contentsline {subsubsection}{\numberline {6.1.5.8}Bayesian Information Criterion (BIC)}{179}{subsubsection.6.1.5.8}%
\contentsline {subsubsection}{\numberline {6.1.5.9}Notas adicionales}{180}{subsubsection.6.1.5.9}%
\contentsline {section}{\numberline {6.2}Selección de variables}{181}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Selección del mejor subconjunto.}{181}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Selección de modelos hacia adelante (\textbf {Forward Stepwise Selection})}{183}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}Selección de modelos hacia atrás (\textbf {Backward Stepwise Selection})}{183}{subsection.6.2.3}%
\contentsline {section}{\numberline {6.3}Métodos de regularización}{184}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Regresión Ridge}{184}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}Regresión Lasso}{185}{subsection.6.3.2}%
\contentsline {subsection}{\numberline {6.3.3}Explicación gráfica}{186}{subsection.6.3.3}%
\contentsline {section}{\numberline {6.4}Laboratorio}{187}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}Cross-Validation}{187}{subsection.6.4.1}%
\contentsline {subsubsection}{\numberline {6.4.1.1}Leave-one-out Cross Validation (LOOCV)}{187}{subsubsection.6.4.1.1}%
\contentsline {subsubsection}{\numberline {6.4.1.2}K-Fold Cross Validation}{189}{subsubsection.6.4.1.2}%
\contentsline {subsection}{\numberline {6.4.2}Selección de variables}{190}{subsection.6.4.2}%
\contentsline {subsubsection}{\numberline {6.4.2.1}Análisis exploratorio}{190}{subsubsection.6.4.2.1}%
\contentsline {subsubsection}{\numberline {6.4.2.2}Regresión forward y backward}{200}{subsubsection.6.4.2.2}%
\contentsline {subsubsection}{\numberline {6.4.2.3}Regresión Ridge}{207}{subsubsection.6.4.2.3}%
\contentsline {subsection}{\numberline {6.4.3}Regresión Lasso}{216}{subsection.6.4.3}%
\contentsline {section}{\numberline {6.5}Ejercicios}{219}{section.6.5}%
\contentsline {chapter}{\numberline {7}Otros Clasificadores}{221}{chapter.7}%
\contentsline {section}{\numberline {7.1}Clasificador Bayesiano}{221}{section.7.1}%
\contentsline {section}{\numberline {7.2}Método de k vecinos más cercanos (KNN)}{222}{section.7.2}%
\contentsline {section}{\numberline {7.3}Análisis Discriminante}{223}{section.7.3}%
\contentsline {subsection}{\numberline {7.3.1}Análisis discriminante lineal}{225}{subsection.7.3.1}%
\contentsline {subsubsection}{\numberline {7.3.1.1}Caso p=1}{225}{subsubsection.7.3.1.1}%
\contentsline {subsubsection}{\numberline {7.3.1.2}Caso p\textgreater 1}{225}{subsubsection.7.3.1.2}%
\contentsline {subsection}{\numberline {7.3.2}Análisis discriminante cuadrático}{226}{subsection.7.3.2}%
\contentsline {section}{\numberline {7.4}Laboratorio}{227}{section.7.4}%
\contentsline {subsection}{\numberline {7.4.1}Clasificador logístico}{231}{subsection.7.4.1}%
\contentsline {subsection}{\numberline {7.4.2}Análisis Discriminante Lineal}{234}{subsection.7.4.2}%
\contentsline {subsection}{\numberline {7.4.3}Análisis Discriminante Cuadrático}{236}{subsection.7.4.3}%
\contentsline {subsection}{\numberline {7.4.4}K vecinos más cercanos}{237}{subsection.7.4.4}%
\contentsline {section}{\numberline {7.5}Ejercicios}{252}{section.7.5}%
\contentsline {chapter}{\numberline {8}Análisis en componentes principales}{253}{chapter.8}%
\contentsline {section}{\numberline {8.1}Representación gráfica}{253}{section.8.1}%
\contentsline {section}{\numberline {8.2}Aprendizaje no-supervisado}{254}{section.8.2}%
\contentsline {section}{\numberline {8.3}Primer componente principal}{255}{section.8.3}%
\contentsline {section}{\numberline {8.4}Segunda componente principal}{257}{section.8.4}%
\contentsline {section}{\numberline {8.5}Circulo de correlaciones}{258}{section.8.5}%
\contentsline {section}{\numberline {8.6}Volvamos a nuestro ejemplo}{258}{section.8.6}%
\contentsline {section}{\numberline {8.7}¿Cuántos componentes usar?}{260}{section.8.7}%
\contentsline {section}{\numberline {8.8}Laboratorio}{262}{section.8.8}%
\contentsline {section}{\numberline {8.9}Ejercicios}{265}{section.8.9}%
\contentsline {chapter}{\numberline {9}Cálculo Bayesiano Computacional}{267}{chapter.9}%
\contentsline {section}{\numberline {9.1}Repaso de Estadística Bayesiana}{267}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}Modelo de un parámetro}{267}{subsection.9.1.1}%
\contentsline {subsection}{\numberline {9.1.2}Modelo de más de un parámetro}{272}{subsection.9.1.2}%
\contentsline {section}{\numberline {9.2}Motivación: Cálculo de Integrales}{275}{section.9.2}%
\contentsline {section}{\numberline {9.3}Ejemplo base: modelo beta-binomial.}{275}{section.9.3}%
\contentsline {section}{\numberline {9.4}Aproximación de Laplace}{279}{section.9.4}%
\contentsline {section}{\numberline {9.5}Simulación}{283}{section.9.5}%
\contentsline {subsection}{\numberline {9.5.1}Simulación Monte Carlo}{283}{subsection.9.5.1}%
\contentsline {subsection}{\numberline {9.5.2}Muestreo por rechazo}{283}{subsection.9.5.2}%
\contentsline {section}{\numberline {9.6}Muestreo por importancia}{286}{section.9.6}%
\contentsline {section}{\numberline {9.7}Remuestreo por importancia}{288}{section.9.7}%
\contentsline {section}{\numberline {9.8}Algoritmo de Metropolis-Hastings}{289}{section.9.8}%
\contentsline {section}{\numberline {9.9}Algoritmo de Gibbs}{290}{section.9.9}%
\contentsline {subsection}{\numberline {9.9.1}Diagnósticos de convergencia de MCMC}{291}{subsection.9.9.1}%
\contentsline {section}{\numberline {9.10}Ejemplos}{291}{section.9.10}%
\contentsline {subsection}{\numberline {9.10.1}Datos agrupados bajo una población normal}{291}{subsection.9.10.1}%
\contentsline {subsection}{\numberline {9.10.2}Datos con outliers}{297}{subsection.9.10.2}%
\contentsline {section}{\numberline {9.11}Ejercicios}{302}{section.9.11}%
